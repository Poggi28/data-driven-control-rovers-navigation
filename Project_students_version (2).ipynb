{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kph1lruSgPWp"
   },
   "outputs": [],
   "source": [
    "import rps.robotarium as robotarium\n",
    "from rps.utilities.transformations import *\n",
    "from rps.utilities.barrier_certificates import *\n",
    "from rps.utilities.misc import *\n",
    "from rps.utilities.controllers import *\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzioni introduttive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eszwfUCygPWs"
   },
   "outputs": [],
   "source": [
    "#Defining the input axes\n",
    "# Note: the boundaries for the control actions are the actuation constraints imposed by the physics of the robots\n",
    "\n",
    "control_space_size = 3  # Three possible inputs for each control axis\n",
    "\n",
    "'''Lo spazio di controllo è discretizzato su 3 possibili valori, che rappresentano le velocità di movimento del robot su un determinato asse, dato che il robot può muoversi solo sul piano\n",
    "x-y (non può muoversi in altezza), rappresentano una velocità positiva, negativa o nulla su quel determinato asse. Dal punto di vista del codice ciò è codificato come:\n",
    "-0.5 -> velocità lungo la direzione negativa dell'asse\n",
    "0 -> nessuna velocità lungo l'asse\n",
    "+0.5-> velocità lungo la direzione positiva dell'asse\n",
    "\n",
    "\n",
    "Definiamo quindi lo spazio di controllo come un array di 3 elementi, che rappresentano i possibili valori che può assumere un asse di controllo, sia per l'asse delle x che per l'asse delle y'''\n",
    "U_space_1 = np.array(np.linspace((-0.5),(0.5),control_space_size)) \n",
    "U_space_2 = np.array(np.linspace((-0.5),(0.5),control_space_size))\n",
    "\n",
    "\n",
    "time_step = 0.033 # Robotarium time-step (from the documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonostante per il controllo data driven non sia necessario conoscere il modello del sistema, è necessario conoscerlo per simularlo, la funzione $\\bold{model\\_step}$ è utilizzata\n",
    "semplicemente per calcolare il prossimo stato del robot, dato lo stato attuale e l'azione che si vuole compiere, in questo caso l'azione è rappresentata da un vettore di velocità come\n",
    "spiegato precedentemente. $\\\\$\n",
    "La funzione $\\bold{my\\_logpdf}$ calcola il valore della pdf di una gaussiana multivariata, dato un punto $(x,y)$, la media e la covarianza della gaussiana. In questo caso specifico la covarianza\n",
    "è fissata, come si può vedere successivamente nel codice, al valore: $$covar = np.diag(v), dove v = np.array([0.02, 0.02], dtype=np.float32)$$\n",
    "\n",
    "Questo significa che la gaussiana è isotropa con varianza $0.02$ su entrambi gli assi, ovvero la covarianza è definibile come:\n",
    "\n",
    "$$\\sum = \\sigma^2I$$ \n",
    "\n",
    "$I$ rappresenta la matrice identità, mentre $\\sigma$ è la varianza scalare.\n",
    "\n",
    "Per quanto riguarda la modellazione dell'ostacolo, l'isotropia della gaussiana implica che la varianza della distribuzione è la stessa su entrambi gli assi. Ciò significa che l'ostacolo è da considerare sferico, con la stessa estensione in tutte le direzioni, o probabilmente un quadrato (per tale motivo, successivamente, si fa anche l'assunzione che la visualizzazione degli ostacoli come dei rettangoli sia un mero artificio di visualizzazione, piuttosto che una rappresentazione fidata dell'ostacolo dato il tipo di modellazione scelta). In questo caso la funzione è utilizzata per calcolare la distanza tra il punto $(x,y)$, che rappresenta lo stato attuale del robot, e un generico ostacolo.\n",
    "\n",
    "[Riferimento: isotropia della gaussiana](https://magic-with-latents.github.io/latent/posts/ddpms/part2/#:~:text=Isotropic%20Gaussian,-An%20isotropic%20Gaussian&text=(4)%20represents%20a%20diagonal%20matrix,Gaussian%20is%20circular%20or%20spherical)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs a \"model\" step using the documented dynamics\n",
    "# Note: from the viewpoint of the controller the dynamics is not necesarily known\n",
    "def model_step(x,velocities,time_step):\n",
    "    poses = np.zeros((2,1))\n",
    "    # Update pose of the robots\n",
    "    poses[0] = x[0] + time_step*velocities[0]\n",
    "    poses[1] = x[1] + time_step*velocities[1]\n",
    "    return(poses)\n",
    "\n",
    "# Get the value of a Gaussian pf at a given point *****?\n",
    "# This function is used to evaluate the pf at a given point (x,y) given the mean and covariance of the Gaussian \n",
    "def my_logpdf(x, u, covar):\n",
    "    k = len(x)  # dimension\n",
    "    a = np.transpose(x - u)\n",
    "    b = np.linalg.inv(covar)\n",
    "    c = x - u\n",
    "    d = np.matmul(a, b)\n",
    "    e = np.matmul(d, c)\n",
    "    numer = np.exp(-0.5 * e)\n",
    "    f = (2 * np.pi)**k\n",
    "    g = np.linalg.det(covar)\n",
    "    denom = np.sqrt(f * g)\n",
    "    pdf = numer / denom\n",
    "    return pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP0\n",
    "Prima di introdurre ulteriormente il codice, per supporto all'analisi del codice e delle scelte progettuali già fatte all'interno del codice fornito, e quelle compiute dal gruppo, si fa riferimento alla formalizzazione del problema di controllo effettuato nella relazione in allegato al codice del progetto. In particolare si riporta la formula semplificata la per la risoluzione del $\\bold {FOC}$ nel caso in cui la $q_{0:N}$ è uniforme:\n",
    "$${p^{(u)}_{k|k-1}}^* = \\frac{exp(\\mathbb{E_{p_{k+1|k}^{(x)}}}[ln(p_{k+1|k}^{(x)})+ \\overline c_{k}(X_k)])}{\\sum_{u_k}exp(\\mathbb{E_{p_{k+1|k}^{(x)}}}[ln(p_{k+1|k}^{(x)})+ \\overline c_{k}(X_k)])} \\space \\space \\bold{(1)}$$\n",
    "e ci riconduciamo al caso greedy in cui:\n",
    "$$\\overline c_{k}(X_k) = c_k(X_k)$$\n",
    "ovvero il cost-to-go è semplicemente il costo instantaneo.\n",
    "Inoltre indichiamo, per semplicità di notazione\n",
    "$$\\mathbb{E_{p_{k+1|k}^{(x)}}}[ln(p_{k+1|k}^{(x)})] = p_{k+1|k}^{(x)}.entropy()\\space \\space\\bold{(2)}$$\n",
    "e infine:\n",
    "$$\\mathbb{E_{p_{k+1|k}^{(x)}}}[c_{k}(X_k)] \\space \\space \\bold{(3)}$$\n",
    "così da poter meglio esplicitare le scelte progettuali del seguito.\n",
    "Si fa notare inoltre, che per allinearci con le variabili del codice, parleremo di:\n",
    "$$f = {p_{k+1|k}^{(x)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW7iQ2FfgPWv"
   },
   "outputs": [],
   "source": [
    "##### WP0: formalize the control problem #####\n",
    "\n",
    "# Task: reverse engineer the cost function used by the robots. What is the problem formulation? \n",
    "#      Is the one below a good cost for the task? Create a heatmap to visualize the cost \n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar) # Questo dipende dalle gaussiane mediate negli ostacoli,\n",
    "        # come se avessimo che più ci avviciniamo all'ostacolo più aumenti il posto\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa funzione calcola il costo dello stato attuale, passato come parametro, rispetto al goal point e agli ostacoli, anche questi passati come parametri, di conseguenza è una funzione\n",
    "generica che può essere utilizzata per calcolare il costo per qualsiasi enviroment limitato al caso robotarium (in cui lo spazio di task può andare da $-1.5$ a $1.5$ per l'asse $x$ \n",
    "e da $-1$ a $1$ per l'asse $y$). Definendo:\n",
    "$$f(x)=\\frac{1}{(2\\pi)^k|covar|} e^{\\frac{-(x-u)^T{covar}^{-1}(x-u)}{2}}$$\n",
    "come il contributo del singolo ostacolo al costo e\n",
    "$$c_0=\\sum_{obst}20f(x_{obst})$$\n",
    "come il contributo di tutti gli ostacoli al costo, esso è esprimile come somma di tre macro termini:\n",
    "$$C(x_k)=[30((x_k-x_d)^2+(y_k-y_d)^2)]_\\bold{(I)}+{c_o}_\\bold{(II)}+10*(\\frac{e^{-0.5({\\frac{(x_k-(-1.5))}{0.02}})^2}}{0.02\\sqrt{2\\pi}}+\\frac{e^{-0.5({\\frac{(x_k-1.5)}{0.02}})^2}}{0.02\\sqrt{2\\pi}}+\\frac{e^{-0.5({\\frac{(y_k-1)}{0.02}})^2}}{0.02\\sqrt{2\\pi}}+\\frac{e^{-0.5({\\frac{(y_k-(-1))}{0.02}})^2}}{0.02\\sqrt{2\\pi}})_\\bold{(III)}$$\n",
    "- Il primo rappresenta la distanza euclidea quadratica dal goal point ($\\bold{(I)}$)\n",
    "- Il secondo rappresenta la distanza dagli ostacoli, come anticipato precedentemtente, la dimensione della gaussiana è hard-coded all'interno del codice, e serve a modellare il tipo di ostacolo che viene\n",
    "gestito nell'ambiente robotarium ($\\bold{(II)}$)\n",
    "- Il terzo rappresenta la distanza dai bordi dell'ambiente robotarium, in particolare è una somma di quattro gaussiane centrate nei bordi dell'ambiente. A differenza del termine gaussiano per gli ostacoli\n",
    "essa è monodimensionale e con valori soltanto in prossimità dei bordi, l'unico scopo è evitare che il robot esca dall'environment, ma può avvicinarsi tranquillamente ai bordi ($\\bold{(III)}$)\n",
    "\n",
    "\n",
    "Il costo fornito racchiude in se stesso alcuni degli elementi chiave del problema di controllo, ovvero:\n",
    "- il raggiungimento dell'obiettivo\n",
    "- l'evitamento degli ostacoli\n",
    "- l'evitamento dell'uscita dai bordi dell'ambiente\n",
    "\n",
    "tutto ciò che è necessario per la risoluzione del problema di controllo. Nonostante ciò, da una breve analisi sui termini del costo, è possibile commentare alcuni aspetti critici per cui il robot potrebbe non comportarsi in maniera ottimale, in particolare:\n",
    "- se l'ostacolo è molto vicino al goal point, il robot potrebbe non raggiungere mai il goal point, in quanto nell'intorno dell'ostacolo il costo è comunque alto, \n",
    "    il che può portare il robot a scegliere di non avvicinarsi all'ostacolo e di conseguenza al goal point;\n",
    "- se uno o più ostacoli sono posti nei pressi delle pareti del robotarium, e il robot è posizionato tra le pareti e gli ostacoli, il robot potrebbe decidere di non avvicinarsi agli ostacoli,\n",
    "    ma piuttosto di avvicinarsi alle pareti, in quanto il costo è più basso, e di conseguenza potrebbe rimanere intrappolato tra ostacoli e pareti o addirittura andare fuori dall'ambiente descritto\n",
    "    dal robotarium;\n",
    "- potrebbe capitare che, a causa dell'allineamento del robot rispetto al goal point, in caso di presenza di ostacolo tra il robot e il goal point, il robot continui a militare nell'\n",
    "intorno dell'ostacolo poichè il costo assume valori simili in entrambe le direzioni ortogonali all'asse di congiunzione, e il robot potrebbe continuare a scegliere direzioni opposte in passi\n",
    "successivi dell'algoritmo, senza mai superare l'ostacolo. \n",
    "\n",
    "Date queste considerazioni, è possibile affermare che il costo fornito, potrebbe essere migliorato, in particolare, verrà proposto un nuovo costo in seguito, come richiesto da work package\n",
    "successivi nel progetto (vedere WP5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP1: fill-in the code for the function below.\n",
    "#         The function needs to return the optimal action sampled from the optimal policy.\n",
    "#         The action is used in the simulation loop #####\n",
    "\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "\n",
    "                '''\n",
    "                Il calcolo della policy descritta nel markdown (1) è valutata per ogni possibile azione, e per questo motivo, è necessario ciclare su tutte le possibili azioni, che in questo caso sono le possibili\n",
    "                combinazioni di velocità lungo l'asse x e lungo l'asse y, 9 in totale.\n",
    "                '''\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                '''\n",
    "                Queste tre righe di codice servono per modellare i sensori rumorosi del sistema, in particolare, la funzione model_step calcola il prossimo stato del robot a cui viene iniettato del rumore gaussiano\n",
    "                con media nulla e covarianza fissata.\n",
    "                '''\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                \n",
    "                '''\n",
    "                Queste due righe di codice servono per campionare la gaussiana dello stato che modella il rumore, in modo da ottenere un numero di campioni pari a N_samples (in questo caso pari a 20). Rappresentano\n",
    "                20 stati diversi in cui il robot potrebbe trovarsi. \n",
    "                \n",
    "                '''\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost(next_sample[k,:],goal_points,obs_points)/N_samples\n",
    "                '''\n",
    "                Queste tre righe invece, servono a computare il costo dello stato successivo, espresso come valore atteso, indicato nella formula (1) nel markdown nella cella precedente. In particolare, il costo\n",
    "                viene calcolato come somma dei costi di ogni campione, diviso il numero di campioni, andando ad ottenere, in questo modo, il valore atteso del costo, che come abbiamo visto dal markdown è calcolato\n",
    "                su f.\n",
    "                '''\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())\n",
    "                '''\n",
    "                Come descritto nel markdown, la policy è ottenibile dalla formula (1), in particolare abbiamo al numeratore l'esponenziale della somma di due termini: il valore atteso del costo (3) e l'entropia della policy (2)\n",
    "                '''\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        \n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "      \n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        \n",
    "        '''\n",
    "        Riprendendo ancora una volta la formula (3) nel markdown, al denominatore abbiamo la normalizzazione della policy, quindi la policy ottima, da cui campionare l'azione, è ottenuta come il rapporto tra il numeratore\n",
    "        calcolato precedentemente e il normalizzatore della stessa.\n",
    "        '''\n",
    "\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        '''\n",
    "        Infine, a partire dall'indice campionato, è possibile ottenere l'azione ottima corrispondente.\n",
    "        '''\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa funzione $\\bold{plot\\_heatmap}$, richiesta dal WP1, serve per visualizzare il costo dello stato in funzione della posizione del robot, discretizzata come una griglia 100 x 100, degli ostacoli, dal goal point e dei muri, in particolare\n",
    "mentre ostacoli e goal point sono passati come parametri, è stato scelto di effettuare un hard-coding dei muri perchè stiamo risolvendo un problema nell'ambiente robotarium, dove questi parametri non sono modificabili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_heatmap(goal_points,obs_points):\n",
    "    plt.figure(figsize=(9,6))\n",
    "    x_min = -1.6\n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    '''\n",
    "    La scelta di plottare la funzione costo su un range maggiore rispetto ai limiti de robotarium è dovuta al fatto che, in questo modo, è possibile comprendere meglio quali sono i limiti effettivi del robotarium.\n",
    "    '''\n",
    "    x_range = np.linspace(x_min,x_max,100)\n",
    "    y_range = np.linspace(y_min,y_max,100)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    Z = np.zeros((100,100))\n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            Z[i,j] = state_cost(np.array([X[i,j],Y[i,j]]),goal_points,obs_points)\n",
    "    plt.pcolormesh(X,Y,Z)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(goal_points[0],goal_points[1],c='r')\n",
    "    plt.scatter(obs_points[0,:],obs_points[1,:],c='k')\n",
    "    plt.title('Cost function')\n",
    "\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "\n",
    "    robotarium_border = patches.Rectangle((-1.5, -1), 1.5-(-1.5), 1-(-1), linewidth=1, edgecolor='black', facecolor='none') \n",
    "    '''\n",
    "    Questo rettangolo rappresenta il confine del robotarium\n",
    "    '''\n",
    "    hand_position_robotarium = patches.Rectangle((-1.4, -0.9), 1.4-(-1.4), 0.9-(-0.9), linewidth=1, edgecolor='red', facecolor='none')\n",
    "    '''\n",
    "    Questo rettangolo rappresenta il confine della safe zone del robotarium considerando il problema dell'hand-position, di questo problema ne parleremo più avanti nel WP5, nella cella\n",
    "    TODO INSERIRE NUMERO CELLA, e quindi è possibile ignorarlo per il momento.\n",
    "    Inoltre è ampiamente descritto anche nella relazione del progetto in allegato al codice.\n",
    "    '''\n",
    "    plt.gca().add_patch(robotarium_border)\n",
    "    plt.gca().add_patch(hand_position_robotarium)\n",
    "    \n",
    "    for i in range(obs_points.shape[1]):\n",
    "        obstacle_square = patches.Rectangle((obs_points[0,i]-0.175, obs_points[1,i]-0.175), 0.35, 0.35, linewidth=1, edgecolor='b', facecolor='none',alpha=0.5)\n",
    "        '''\n",
    "        Questo rettangolo rappresenta l'ostacolo, in particolare, è stato scelto di rappresentare l'ostacolo come un quadrato di lato 0.35, la scelta di ciò deriva da alcune considerazioni\n",
    "        ed esperimenti effettuati nell'ambiente robotarium reale, in particolare si rimanda sempre al WP5, per una spiegazione dettagliata\n",
    "        TODO INSERIRE NUMERO CELLA\n",
    "        '''\n",
    "        hand_position_obstacle = patches.Rectangle((obs_points[0,i]-0.225, obs_points[1,i]-0.225), 0.45, 0.45, linewidth=1, edgecolor='r', facecolor='none',alpha=0.5)\n",
    "        '''\n",
    "        Analogamente ai bordi del robotarium, abbiamo dei quadrati, di lato maggiore rispetto all'ostacolo, in questo modo è possibile rappresentare la safe zone dell'ostacolo, considerando\n",
    "        anche in questo caso il problema dell'hand position, si rimanda alla spiegazione di questo fenomeno nel WP5, TODO INSERIRE NUMERO CELLA\n",
    "        '''\n",
    "\n",
    "        plt.gca().add_patch(obstacle_square)\n",
    "        plt.gca().add_patch(hand_position_obstacle)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa funzione $\\bold{plot\\_3d\\_heatmap}$, ha le stesse funzioni della heatmap precedente, ma in un ambiente 3D in cui è possibile vedere in maniera più chiara, la funzione di costo scelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_3d_heatmap(goal_points, obs_points): \n",
    "    x_min = -1.6 \n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "   \n",
    "    x_range = np.linspace(x_min, x_max, 100) \n",
    "    y_range = np.linspace(y_min, y_max, 100) \n",
    "    X, Y = np.meshgrid(x_range, y_range) \n",
    "    Z = np.zeros((100, 100)) \n",
    "    for i in range(100): \n",
    "        for j in range(100): \n",
    "            Z[i, j] = state_cost(np.array([X[i, j], Y[i, j]]), goal_points, obs_points) \n",
    "    fig = plt.figure(figsize=(15,10)) \n",
    "    ax = fig.add_subplot(111, projection='3d') \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7) \n",
    "    ax.set_xlabel('X') \n",
    "    ax.set_ylabel('Y') \n",
    "    ax.set_zlabel('Cost') \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point') \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  \n",
    "    \n",
    "    \n",
    "    for i in range(obs_points.shape[1]):\n",
    "        obs_x = [obs_points[0, i] - 0.175, obs_points[0, i] - 0.175, obs_points[0, i] + 0.175, obs_points[0, i] + 0.175, obs_points[0, i] - 0.175]\n",
    "        obs_y = [obs_points[1, i] - 0.175, obs_points[1, i] + 0.175, obs_points[1, i] + 0.175, obs_points[1, i] - 0.175, obs_points[1, i] - 0.175]\n",
    "        ax.plot(obs_x, obs_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "        obs_x_hand_position = [obs_points[0, i] - 0.275, obs_points[0, i] - 0.275, obs_points[0, i] + 0.275, obs_points[0, i] + 0.275, obs_points[0, i] - 0.275]\n",
    "        obs_y_hand_position = [obs_points[1, i] - 0.275, obs_points[1, i] + 0.275, obs_points[1, i] + 0.275, obs_points[1, i] - 0.275, obs_points[1, i] - 0.275]\n",
    "        ax.plot(obs_x_hand_position, obs_y_hand_position, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    \n",
    "    robotarium_x_hand_position = [-1.4, -1.4, 1.4, 1.4, -1.4]\n",
    "    robotarium_y_hand_position = [-0.9, 0.9, 0.9, -0.9, -0.9]\n",
    "    ax.plot(robotarium_x_hand_position, robotarium_y_hand_position, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    '''\n",
    "    Unica sostanziale differenza rispetto al caso 2D, è qui non plottiamo anche i bordi effettivi del robotarium, poichè data la leggibilità maggiore del plot 3D è intuibile quali essi siano, però plottiamo\n",
    "    quelli della safe zone. Si fa notare inoltre, che plottare questo tipo di valori bidimensionali sul plot 3D è semplicemente una scelta di visualizzazione, in quanto, in realtà, gli ostacoli sono anch'essi tridimensionali,\n",
    "    come anche i bordi.\n",
    "    '''\n",
    "\n",
    "    ax.legend() \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa cella viene inizializzato l'enviroment del task di controllo, in particolar modo gli ostacoli e il goal point, in seguito vengono plottate le heatmap relative alla funzione di costo. Si fa inoltre notare, che grazie alla libreria matplotlib, è possibile visualizzare queste schede in una finestra separata (avviando la cella con il widget $qt$), altrimenti è possibile visualizzarli nel normale environment Jupiter non avviando nessuna delle due celle, o avviando ($inline$) nel caso si voglia resettare il tutto. L'uso di $qt$ non serve solamente a permettere l'interattività con i grafici 3D, ma anche per visualizzare in tempo reale la simulazione del robotarium e vedere come il robot si sposta nell'ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wy2b_CxogPWy"
   },
   "outputs": [],
   "source": [
    "# Define goal and obstacle points\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) # Da traccia\n",
    "# goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "plot_heatmap(goal_points,obs_points)\n",
    "plot_3d_heatmap(goal_points, obs_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dal plot si può notare come alcuni ostacoli dati dalla traccia sono mappati fuori dal confine del robotarium, ma si assume che la scelta è stata fatta per modellare ostacoli di dimensione differente, magari inferiore su quel punto specifico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WP2: Simulate (4 experiments) and visualize each robot's trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa cella viene effettuata la simulazione del robot, in particolare, per un singolo robot, vengono effettuati 4 esperimenti, in cui il robot parte da 4 posizioni diverse. \n",
    "Nello specifico, è stato fornito un set di condizioni iniziali di esempio, che sono state utilizzate per effettuare la simulazione.\n",
    "Innanzitutto viene inizializzato l'enviroment robotarium e creato il mapping tra il sistema unicycle del robot e il sistema single integrator. Tralasciamo la descrizione del modello unicycle, ampiamente descritta\n",
    "nella documentazione del robotarium, e ci concentriamo sul modello single integrator, che è quello che interessa per la simulazione, non è necessario conoscerlo per la risoluzione del problema di controllo. Successivamente\n",
    "viene effettuato un esperimento alla volta, il quale prevede:\n",
    "- il recupero della posa del robot (che nel caso del robotarium recupera la posizione della hand position del robot) a cui viene iniettato del rumore per simulare gli eventuali errori di misura del sensore di posizione del robot;\n",
    "- viene effettuato il passo di controllo attraverso la funzione $\\bold{Control\\_step}$ che restituirà l'azione ottima come descritto in precedenza;\n",
    "- viene effettuata la conversione dell'azione ottima in velocità del robot, attraverso la funzione $\\bold{si\\_to\\_uni\\_dyn}$;\n",
    "- vengono assegnate le velocità al robot;\n",
    "- viene effettuato il passo di simulazione.\n",
    "\n",
    "Per quanto riguarda le simulazioni, sono state lasciate le condizioni iniziali della traccia, nonostante nel report finale sono state infoltite e modificate per provare condizioni iniziali diverse e per avere maggiori simulazioni per la ricostruzione del costo del problema $\\bold{IOC}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come anche per alcune funzioni successive, si è deciso di rendere generalizzato il seguente script, per permettere di testare il codice su diversi scenari, e di conseguenza, renderlo una funzione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WsfTaVW4gPW0",
    "outputId": "40848e0e-6a4c-4ddc-b80e-b576acbbff2b"
   },
   "outputs": [],
   "source": [
    "\n",
    "def genericSimulation(initial_conditions,goal_points,obs_points):\n",
    "    # Instantiate Robotarium object\n",
    "    N = 1 #Amount of robots per simulation\n",
    "\n",
    "    N_experiment = len(initial_conditions)\n",
    "    # X_si is going to be two-dimensional state history\n",
    "    X_Si = [0]*N_experiment\n",
    "    # D_Xi is going to be two-dimensional inputs history\n",
    "    D_Xi = [0]*N_experiment\n",
    "\n",
    "    # This first for loop creates the initial conditions\n",
    "    for I in range(N_experiment):\n",
    "\n",
    "        X_si = []\n",
    "        D_xi = []\n",
    "\n",
    "        r = robotarium.Robotarium(number_of_robots=N, show_figure=True, initial_conditions=initial_conditions[I], sim_in_real_time=False)\n",
    "\n",
    "        # Create mapping from the control inputs to the actual velocity commands to the unicycle\n",
    "        # Note: this is a very practical situation (robots often provide transformation functions to low level commands)\n",
    "        si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion() #Converts single integrator inputs to unicycle inputs (low-level controller)\n",
    "        _, uni_to_si_states = create_si_to_uni_mapping()\n",
    "        \n",
    "        # define x initially\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        # Plotting Parameters\n",
    "        CM = np.random.rand(N+10,3) # Random Colors\n",
    "        goal_marker_size_m = 0.15\n",
    "        obs_marker_size_m = 0.15\n",
    "        marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "        marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "        font_size = determine_font_size(r,0.1)\n",
    "        line_width = 5\n",
    "\n",
    "        # Create Goal Point Markers\n",
    "        #Text with goal identification\n",
    "        goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "        #Plot text for caption\n",
    "        goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "        for ii in range(goal_points.shape[1])]\n",
    "        goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "        for ii in range(goal_points.shape[1])]\n",
    "\n",
    "        #Text with goal identification\n",
    "        obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "        #Plot text for caption\n",
    "        obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "        for ii in range(obs_points.shape[1])]\n",
    "        obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "        for ii in range(obs_points.shape[1])]\n",
    "\n",
    "        r.step()\n",
    "\n",
    "        # While the robot is away from the objective ...\n",
    "        while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N):\n",
    "\n",
    "            try:\n",
    "                # Get poses of agents\n",
    "                x = r.get_poses()\n",
    "                x_si = uni_to_si_states(x)\n",
    "\n",
    "                #Add to the dataset\n",
    "                X_si.append(x_si)\n",
    "\n",
    "                # The lines below define the pdf of the robot \n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "                x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "                # This is about plotting\n",
    "                for j in range(goal_points.shape[1]):\n",
    "                    goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "                for j in range(obs_points.shape[1]):\n",
    "                    obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "                # Task: compute the action from the policy. Call the variable dxi: \n",
    "                # this is the action sampled from the optimal solution to the control problem\n",
    "                dxi = Control_step(x_sample,U_space_1,U_space_2,goal_points,obs_points) \n",
    "                '''\n",
    "                Questa funzione è stata definita nel WP1, e rappresenta la policy ottima, che viene campionata per ottenere l'azione da eseguire.\n",
    "                '''\n",
    "                D_xi.append(dxi)\n",
    "\n",
    "                # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "                dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "                # Set the velocities inputs\n",
    "                r.set_velocities(np.arange(N), dxu)\n",
    "                # Iterate the simulation\n",
    "                r.step()\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        D_Xi[I] = D_xi\n",
    "        X_Si[I] = X_si\n",
    "\n",
    "        #Call at end of script to print debug information and for your script to run on the Robotarium server properly\n",
    "        r.call_at_scripts_end()\n",
    "\n",
    "        '''\n",
    "        Dato che grazie a matplotlib qt è possibile visualizzare la simulazione live, è stato aggiunto un ramo try except per bloccare forzatamente l'esperimento, in caso di non raggiungimento del goal point in tempi ragionevoli.\n",
    "        Inoltre si fa notare che, per gli esperimenti effettuati sul robotarium reale, il try except è stato sostituito con un timeout, in modo da non bloccare l'esperimento a mano, ma semplicemente farlo terminare dopo un tempo\n",
    "        ragionevole, facendo in modo che in caso di blocco del robot, l'esperimento finisca comunque.\n",
    "        '''\n",
    "    return X_Si,D_Xi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.4; 0.9; 0')),np.array(np.mat('0.2; 0.9; 0')),np.array(np.mat('1.2; -0.5; 0')),np.array(np.mat('-1; 0.9; 0'))] #Initial pose of the robots\n",
    "\n",
    "X_Si,D_Xi = genericSimulation(initial_conditions,goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ass2XqjRgPW3"
   },
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nelle prossime celle è stato effettuato un leggero refactoring del codice, per rendere il tutto delle funzioni. Questo perchè, in work package successivi, l'uso intensivo di queste funzionalità si è reso tale da portarci inevitabilmente a definire delle funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyRxll4KgPW5"
   },
   "outputs": [],
   "source": [
    "def prepareDataForPlotting(XX, UU):\n",
    "    #Prepare data for plotting\n",
    "    X = []\n",
    "    X_plot = []\n",
    "    U = []\n",
    "    U_plot = []\n",
    "\n",
    "    for i in range(len(XX)):\n",
    "        X.append(np.array(XX[i]))\n",
    "        X_plot.append(np.array(XX[i]))\n",
    "\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    X = np.reshape(X, (-1, 2))\n",
    "\n",
    "    U = []\n",
    "    for i in range(len(UU)):\n",
    "        U.append(np.array(UU[i]))\n",
    "        U_plot.append(np.array(UU[i]))\n",
    "\n",
    "    U = np.concatenate(U, axis=0)\n",
    "    U = np.reshape(U, (-1, 2))\n",
    "    return X, X_plot, U, U_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "PqEl3OXpgPW_",
    "outputId": "a710f7af-4b2e-486e-908b-063e24924946"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "\n",
    "def plotTrajectory(X_plot,obs_points,goal_points): \n",
    " \n",
    "    plt.figure(figsize=(9, 6)) \n",
    " \n",
    "    for i in range(len(X_plot)): \n",
    "        plt.plot(X_plot[i][:, 0], X_plot[i][:, 1], label=f'Traiettoria {i+1}') \n",
    "        plt.plot(X_plot[i][0, 0],X_plot[i][0, 1],'*',color='black',markersize=10) \n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)): \n",
    "        obstacle_square= plt.Rectangle((obs_points[0,i]-0.175,obs_points[1,i]-0.175), 0.35, 0.35, fc='red',ec=\"black\")\n",
    "        obstacle_hand_position = patches.Rectangle((obs_points[0,i]-0.225, obs_points[1,i]-0.225), 0.45, 0.45, linewidth=1, edgecolor='r', facecolor='none',alpha=0.5)\n",
    "\n",
    "        plt.gca().add_patch(obstacle_square)\n",
    "        plt.gca().add_patch(obstacle_hand_position) \n",
    "     \n",
    " \n",
    "    square= plt.Rectangle((goal_points[0,0]-0.175,goal_points[1,0]-0.175), 0.35, 0.35, fc='green',ec=\"black\") \n",
    "    plt.gca().add_patch(square) \n",
    "    plt.ylim(-1.1,1.1) \n",
    "    plt.xlim(-1.6,1.6) \n",
    "    plt.xlabel('X [m]') \n",
    "    plt.ylabel('Y [m]')\n",
    "    plt.title('Robot trajectories')\n",
    "    \n",
    "    robotarium_border = patches.Rectangle((-1.5, -1), 1.5-(-1.5), 1-(-1), linewidth=1, edgecolor='black', facecolor='none') \n",
    "    hand_position_robotarium = patches.Rectangle((-1.4, -0.9), 1.4-(-1.4), 0.9-(-0.9), linewidth=1, edgecolor='red', facecolor='none')\n",
    "  \n",
    "    plt.gca().add_patch(robotarium_border)\n",
    "    plt.gca().add_patch(hand_position_robotarium)\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' stata inoltre realizzato anche un plotting sulla mappa 3D del robot. Sappiamo che il robot non si muove in uno spazio tridimensionale, ma bidimensionale, ma avendo la funzione di costo è interessante capire come il robot segue la superficie della stessa. Purtroppo per problematiche del codice, a cui non siamo riusciti a porre rimedio, non è possibile vedere le traiettorie sulla superficie, e quindi è stato posto 0 sulla coordinata z. Il codice che prevede l'inizializzazione della coordinata z al valore del costo in quel punto serviva a questo scopo, ma purtroppo non siamo riusciti a risolvere questo problema di visualizzazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO CAMBIARE I NOMI DENTRO\n",
    "def plotTrajectory3D(X_plot,obs_points,goal_points): \n",
    "    x_min = -1.6  \n",
    "    x_max = 1.6 \n",
    "    y_min = -1.1 \n",
    "    y_max = 1.1 \n",
    "    x_range = np.linspace(x_min, x_max, 100)  \n",
    "    y_range = np.linspace(y_min, y_max, 100)  \n",
    "    X, Y = np.meshgrid(x_range, y_range)  \n",
    "    Z = np.zeros((100, 100))  \n",
    "    for i in range(100):  \n",
    "        for j in range(100):  \n",
    "            Z[i, j] = state_cost(np.array([X[i, j], Y[i, j]]), goal_points, obs_points)  \n",
    "    fig = plt.figure(figsize=(12,8))  \n",
    "    ax = fig.add_subplot(111, projection='3d', autoscale_on=True)  \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7)  \n",
    "    ax.set_xlabel('X')  \n",
    "    ax.set_ylabel('Y')  \n",
    "    ax.set_zlabel('Cost')  \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point')  \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)    \n",
    "    \n",
    "    original_list=[] \n",
    "    for i in range(len(X_plot)): \n",
    "        new_inner_list=[] \n",
    "        for j in range(len(X_plot[i])): \n",
    "            new_array_3d=np.append(X_plot[i][j],state_cost(X_plot[i][j],goal_points,obs_points)) \n",
    "            new_inner_list.append(new_array_3d) \n",
    "            \n",
    "        original_list.append(new_inner_list) \n",
    "    \n",
    "    for i in range(len(X_plot)): \n",
    "        original_array = np.array(original_list[i]) \n",
    "        plt.plot(original_array[:, 0], original_array[:, 1], 0,  label=f'Trajectory {i+1}') \n",
    "\n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        obs_x = [obs_points[0, i] - 0.15, obs_points[0, i] - 0.15, obs_points[0, i] + 0.15, obs_points[0, i] + 0.15, obs_points[0, i] - 0.15]\n",
    "        obs_y = [obs_points[1, i] - 0.15, obs_points[1, i] + 0.15, obs_points[1, i] + 0.15, obs_points[1, i] - 0.15, obs_points[1, i] - 0.15]\n",
    "        ax.plot(obs_x, obs_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "        # Add larger red square centered at obstacle points\n",
    "        obs_x_hand_position = [obs_points[0, i] - 0.25, obs_points[0, i] - 0.25, obs_points[0, i] + 0.25, obs_points[0, i] + 0.25, obs_points[0, i] - 0.25]\n",
    "        obs_y_hand_position = [obs_points[1, i] - 0.25, obs_points[1, i] + 0.25, obs_points[1, i] + 0.25, obs_points[1, i] - 0.25, obs_points[1, i] - 0.25]\n",
    "        ax.plot(obs_x_hand_position, obs_y_hand_position, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "\n",
    "    ax.legend() \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_plot, U, U_plot = prepareDataForPlotting(XX, UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si può notare dal plot, le simulazioni raggiungono l'obiettivo, nonostante ci sia un pò di rumorosità nel raggiungere l'obiettivo, soprattutto in prossimità del medesimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP3: Reverse engineer the features and visualize them #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le celle celle nel seguito, effettuano una parametrizzazione dell'ambiente robotarium come una griglia di punti. $\\\\$ Le feature proposte dal docente sono 16, la prima rappresenta la distanza rispetto al goal point, mentre le altre 15 rappresentano la distanza rispetto a dei punti fissi, che sono posizionati in maniera tale da cercare di\n",
    "ricoprire l'intero spazio di task. $\\\\$\n",
    "Questo set di feature, mappa in maniera fedele il costo dello stato relativo alla distanza dal goal point e dagli ostacoli, infatti ogni punto di feature è posizionato in un punto\n",
    "dell'ambiente e, in base al relativo peso, esso rappresentarà la distanza da eventuali ostacoli presenti in quell'area dell'ambiente. $\\\\$\n",
    "Data la natura del set di feature proposto, una prima analisi critica mette alla luce qualche problema: il numero di punti della griglia robotarium di riferimento sono in numero limitato.  $\\\\$\n",
    "Questa \"discretizzazione\" della griglia potrebbe portare a una perdita di informazione, in quanto non è detto che è possibile ricavare tutte le informazioni riguardanti il costo dello stato a causa del numero ridotto di simulazioni,\n",
    "e queste, anche se aumentassero in numero, potrebbero non coprire tutte le casistiche possibili. \n",
    "$\\\\$Per tale motivo una prima analisi critica porterebbe all'aumento del numero di punti della griglia robotarium, in modo da avere più informazioni\n",
    "riguardo il costo dello stato, e quindi avere una migliore approssimazione del costo dello stato. \n",
    "$\\\\$ Inoltre non è presente alcuna feature che mappi la presenza dei bordi del task, ciò preoccupa poichè il robot potrebbe decidere di uscire dai bordi sfruttando il costo stimato derivante da queste feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjLf-AbTgPXB"
   },
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XXOIr-DgPXD"
   },
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2))\n",
    "\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAi2q4NvgPXE"
   },
   "outputs": [],
   "source": [
    "##### WP4: using the previously defined features solve the inverse optimal control problem. \n",
    "#          Plot the estimated cost. \n",
    "#          Verify that the estimated cost allows the robot to complete the task #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di introdurre ulteriormente il codice, per supporto all'analisi dello stesso e delle scelte progettuali già fatte all'interno del codice fornito, e quelle compiute dal gruppo, si fa riferimento alla formalizzazione del problema di controllo inverso effettuato nella relazione in allegato al codice del progetto. In particolare, si riporta la formula semplificata la per la risoluzione dell'$\\bold {IOC}$ nel caso in cui la $q_{0:N}$ è uniforme:\n",
    "$$argmin_w\\{\\sum^M_{k=1}(\\mathbb{E_{p(x_k|\\hat x_{k-1},\\hat u_k)}}[w_k^Th(x_k)]+ln(\\sum_{u_k}exp(\\mathbb{E_{p(x_k|\\hat x_{k-1},u_k)}}[-ln(p(x_k|\\hat x_{k-1},u_k))+w_k^Th(x_k)])))\\} \\space \\space \\bold{(4)}$$\n",
    "\n",
    "Inoltre indichiamo, per semplicità di notazione\n",
    "$$exp(\\mathbb{E_{p(x_k|\\hat x_{k-1},u_k)}}[-ln(p(x_k|\\hat x_{k-1},u_k))]) = -p(x_k|\\hat x_{k-1},u_k).entropy()\\space \\space\\bold{(5)}$$\n",
    "e inoltre:\n",
    "$$\\mathbb{E_{p(x_k|\\hat x_{k-1},u_k)}}[w_k^Th(x_k)] \\space \\space \\bold{(6)}$$\n",
    "e infine:\n",
    "$$\\mathbb{E_{p(x_k|\\hat x_{k-1},\\hat u_k)}}[w_k^Th(x_k)] \\space \\space \\bold{(7)}$$\n",
    "così da poter meglio esplicitare le scelte progettuali del seguito.\n",
    "Ricordiamo che anche in questo caso, per mapping con le variabili del codice, consideriamo $$f = p(x_k|\\hat x_{k-1},u_k)$$ $$f\\_sampled = p(x_k|\\hat x_{k-1},\\hat u_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7shmt6xgPXF"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1\n",
    "w = cp.Variable((1,N_feature))\n",
    "constraints = [w >= 0]\n",
    "R = np.zeros((99,1))\n",
    "L = []\n",
    "\n",
    "f_expect = np.zeros((2,20))\n",
    "feature_sampled = np.zeros((N_feature,M))\n",
    "PF = np.zeros((control_space_size,control_space_size,M))\n",
    "\n",
    "for i in range(M):\n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size))\n",
    "    state = np.array(X[i,:]) #Get the state\n",
    "\n",
    "    x0 = state.reshape(-1,1)\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            next_sample = f.mean\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples)\n",
    "            feature_sample = np.zeros((N_feature,N_samples))\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1)\n",
    "\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy()))\n",
    "            '''\n",
    "            Questo riga rappresenta il termine (5) descritto nel markdown, in particolare rappresenta l'esponenziale dell'entropia cambiata di segno.\n",
    "            '''\n",
    "\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # N features x 9\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step)\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov)\n",
    "    next_samples_f1 = f1.rvs(N_samples)\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)\n",
    "\n",
    "    '''\n",
    "    Come specificato nel termine (7) del markdown, il valore atteso delle feature, in questo caso, è effettuato sulla f_sampled, in cui stato passato e azione sono stati recuperati dai dati reali delle traiettorie.\n",
    "    '''\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    tempPF = np.reshape(PF,(control_space_size**2,M)) # N features x 9\n",
    "\n",
    "    l =-(w @ feature_sampled[:,i])+cp.log_sum_exp(cp.reshape(w@features[:,:],(9,))+cp.log(tempPF[:,i]))\n",
    "    \n",
    "    '''\n",
    "    Ogni termine l, rappresenta il singolo termine della sommatoria (4) descritta nel markdown, in particolare, dato che il codice pre-esistente già calcolava il termine (5) e il termine (6), lo scopo di questa parte di codice\n",
    "    è quello di configurare le dimensionalità dei vari termini, effettuando un reshape della PF calcolata, portandola da una dimensionalità (N feature x 3 x 3), a una dimensionalità (N x 9) per essere gestita nella somma con il prodotto dei pesi con le features.\n",
    "    Inoltre, dato che stiamo risolvendo un problema di LSE tramite cvx, dobbiamo fornirgli in input il valore atteso del prodotto tra pesi e feature, e il valore atteso della f cambiata di segno, rappresentato dall'entropia,\n",
    "    ma dato che ci viene già fornito dal codice l'esponenziale dell'entropia, cambiata di segno, dobbiamo sommare il logaritmo di questa quantità in modo da riportarci nella forma originale del problema (4). Inoltre bisogna aggiungere il termine\n",
    "    (7) calcolato precendemente.\n",
    "    '''\n",
    "    \n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    L.append(l)\n",
    "\n",
    "    '''\n",
    "    Con queste linee di codice creiamo l'intera sommatoria su M esperimenti.\n",
    "    '''\n",
    "\n",
    "    # (iii) solve the problem \n",
    "objective = cp.Minimize(cp.sum(L))\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = False)\n",
    "\n",
    "'''\n",
    "Infine risolviamo il problema, facendo uso di cvx, minimizzando la sommatoria dei termini l, ottenendo i pesi w ottimi delle feature scelte.\n",
    "'''\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A termine dell'ottimizzazzione vengono visualizzati i pesi calcolati dal problema. $\\\\$ In questo caso particolare notiamo che i pesi relativi al mapping dello spazio assumono valori più alti, in segno negativo, più vicini sono\n",
    "agli ostacoli.$\\\\$ Ovviamente questo ha senso, poichè il costo, è combinazione lineare di queste feature cambiate di segno e pesate per i relativi pesi, e riesce a rappresentare in maniera fedele il costo dello stato, \n",
    "poichè è più alto in vicinanza dei punti in cui sono concentrati più ostacoli. $\\\\$ Inoltre anche il peso della feature che mappa la distanza dal goal point è negativo e di modulo alto, \n",
    "e questo ha senso in quanto il costo dello stato è tanto più alto quanto più il robot è lontano dal goal point. $\\\\$ Purtroppo non è presente alcun termine che mappi la presenza dei bordi del robotarium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EY1orFxPgPXH",
    "outputId": "24a7b313-560d-4e31-d3f1-49d9a25a0543"
   },
   "outputs": [],
   "source": [
    "# Show the values: critically discuss if these weights make sense\n",
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come descritto anche in precedenza, l'ottimizzazione è andata a buon fine e il valore dei pesi calcolati è ragionevole in relazione allo specifico task attuato.\n",
    "Il fatto che lo status sia optimal indica che l'ottmizzazione ha raggiunto con successo la soluzione ottimale, trovando il miglior valore possibile rispetto alla funzione obiettivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QgxBdrNgPXI",
    "outputId": "699171d0-3d2f-4195-af1c-fdbe5032e7af"
   },
   "outputs": [],
   "source": [
    "# Check the status of the optimization problem: did the optimization go well?\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Xs5LG7IgPXJ"
   },
   "outputs": [],
   "source": [
    "# Reformatting the original cost map (just for checking and plotting purposes)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "#obs_points = np.array(np.mat('0 0 0 0 0 0;0 0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0 0'))\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost(state,goal_points,obs_points)\n",
    "\n",
    "Coat_Map = pd.DataFrame(Cost_Map,index=list(X_axis),columns=Y_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXBeF23UgPXL"
   },
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nella successiva cella visualizzato il costo dello stato calcolato con i pesi ottenuti dall'ottimizzazione, ovvero il costo stimato. In particolare, è rappresentato come una heatmap analogamente a quanto accaduto\n",
    "per il costo definito nel problema di FOC. Inoltre, sono state anche disegnate delle linee tratteggiate che rappresentano i livelli di costo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "I7poUkevgPXM",
    "outputId": "e4e9bc4c-b6a7-422e-a08b-0fa3a0652535"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transpose the data array to rotate the heatmap\n",
    "data_rotated = np.transpose(Cost_Map)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting the pcolormesh for the data\n",
    "plt.pcolormesh(X_axis, Y_axis, data_rotated, cmap='viridis', alpha=0.92)\n",
    "plt.colorbar()\n",
    "\n",
    "# Define contour levels to create 6 regions\n",
    "contour_levels = np.linspace(data_rotated.min(), data_rotated.max(), 7)  \n",
    "\n",
    "# Get colors based on the viridis colormap for the given contour levels\n",
    "viridis_colors = plt.cm.viridis(np.linspace(0, 1, len(contour_levels)))\n",
    "\n",
    "for i, level in enumerate(contour_levels):\n",
    "    plt.contour(X_axis, Y_axis, data_rotated, levels=[level], colors=[viridis_colors[i]], linewidths=2.5, linestyles='dashed')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione ha la sintassi e il significato analogo a quella definita per il problema di $\\bold{FOC}$, con la sola differenza che il costo dello stato viene calcolato con i pesi ottenuti dall'ottimizzazione,\n",
    "e quindi il costo è quello stimato dal problema $\\bold{IOC}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIo_AnGpgPXT"
   },
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                '''\n",
    "                L'unica differenza è nella funzione di costo che viene interpellata\n",
    "                '''\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())\n",
    "\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        pf = pf/S2\n",
    "\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grazie al fatto che la simulazione è stata resa funzione, è possibile semplicemente chiamarla nel modo seguente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial_conditions = [np.array(np.mat('-1.4;0.9; 0')),np.array(np.mat('1;0.9; 0')),np.array(np.mat('1;-0.25; 0'))]\n",
    "\n",
    "X_Si,D_Xi = genericSimulation(initial_conditions,goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2gUBs9HgPXW"
   },
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine, ancora una volta come nel FOC, plottiamo i risultati degli esperimenti. $$\\\\$$ Effettivamente, per le condizioni iniziali scelte da traccia, il robot riesce a raggiungere il goal point,\n",
    "ma non è detto che questo accada sempre, infatti se si cambiano le condizioni iniziali, il robot potrebbe non raggiungere il goal point, inoltre, dato che non ci sono feature che mappino i muri, il robot a volte esce anche dai\n",
    "bordi. $$\\\\$$\n",
    "Proprio per tale motivo si è deciso di modellare una nuova funzione di costo e un nuovo set di feature, così come richiesto dal WP5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Sq2vsBLMgPXY",
    "outputId": "c6e65995-63e3-47ac-fb97-7d930abc5887"
   },
   "outputs": [],
   "source": [
    "X, X_plot, U, U_plot = prepareDataForPlotting(XX, UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine, prima di passare alla modellazione di una nuova funzione di costo e di un nuovo set di feature, viene visualizzato il set di feature utilizzato per il problema di IOC.\n",
    "In particolare, i punti caratteristici sono rappresentati come dei cerchi rossi, e la dimensione del cerchio è proporzionale al peso associato alla feature, in particolare, più il peso è alto, più il cerchio sarà grande. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "Xgg5hhMogPXQ",
    "outputId": "b8c54575-1e46-441a-991d-9561ed668256"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "newWeights=-weights[0][1:]\n",
    "weights_normalized = (newWeights - newWeights.min()) / (newWeights.max() - newWeights.min())\n",
    "weights_mapped = 100 + (weights_normalized * 900) \n",
    "\n",
    "\n",
    "plt.scatter(obs_points_f[0], obs_points_f[1], s=weights_mapped, c='red', marker='o')\n",
    "\n",
    "for i in range(len(newWeights)):\n",
    "    plt.text(obs_points_f[0, i], obs_points_f[1, i]-0.15, f'{-newWeights[i]:.2f}', fontsize=8, color='black')\n",
    "\n",
    "plt.xlabel('Asse X')\n",
    "plt.ylabel('Asse Y')\n",
    "plt.title('Punti caratteristici sulla griglia del Robotarium con pesi')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment the results you observe in the figure generated by the above cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come enunciato già in precedenza, alla visualizzazione non grafica, ma analitica dei pesi, notiamo che i pesi relativi al mapping dello spazio assumono valori più alti, in segno negativo, più vicini sono\n",
    "agli ostacoli. Ovviamente questo ha senso, poichè il costo, combinazione lineare di queste feature, riesce a rappresentare in maniera fedele il costo dello stato, poichè è più alto in vicinanza dei punti in cui sono concentrati\n",
    "più ostacoli. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di proporre un nuovo costo e nuove feature, ci siamo interessati a comprendere a pieno due elementi chiave del problema:\n",
    "-  l'environment robotarium e le sue caratteristiche, in particolare, ci siamo interessati a capire la dimensione\n",
    "dell'ostacolo che viene effettivamente inserito come parametro del robotarium.\n",
    "- come evitare a pieno che il robot possa colpire degli impedimenti lungo il tragitto\n",
    "\n",
    "Per quanto riguarda il primo punto, dopo aver fatto vari test, abbiamo notato che l'ostacolo viene rappresentato come un rettangolo di dimensioni $0.35mx0.35m$ , e questo\n",
    "vale anche per la zona di goal point, siamo riusciti a comprenderlo grazie a varie simulazioni di test inviate alla piattaforma online del robotarium, ciò che ci ha fatto capire quale fosse la dimensione dell'ostacolo\n",
    "è la seguente simulazione, effettuata con ostacoli distanti 0.35 fra di loro:\n",
    "[Video: comprensione della dimensione dell'ostacolo](https://robotzoo-video.ecs.gatech.edu/owncloud/index.php/s/bUUjobOimI5ftYC)\n",
    "\n",
    "Per quanto riguarda il secondo punto invece, è stata fatta una riflessione a partire da come la simulazione effettivamente accedesse ai dati del enviroment e come il robot fosse modellato. $\\\\$ Per tale motivo, indagando documentazione e sperimentazioni, si è identificato che l'enviroment accedesse al valore della posa del robot rappresentata dalla posizione dell'hand position sul robot posta a $0.05$ rispetto al centro del robot,in direzione della terza ruota rotante, il cui diametro, recuperabile dalla variabile $r$ del robotarium, è $0.095$, approssimabile a $0.1$ TODO CONTROLLARE QUESTO $\\\\$\n",
    "Date queste considerazioni, come esplicato nel paragrafo \"Hand-position problem\" della relazione, si è deciso di tenere conto di questo fattore nella modellazione del costo e degli ostacoli. Infatti dato che è la posizione dell'hand position che viene utilizzata per valutare la posizione del robot, dato che il robot potrebbe trovarsi ruotato in qualsiasi direzione, è come se in realtà il robot dovesse evitare gli ostacoli e gli impedimenti con un aggiunta di una soglia critica, pari a $0.1$ in questo caso, per evitare che il robot ruotato in alcune pose urti queste ostruzioni lungo il percorso. Il seguente discorso è generalizzabile sia rispetto agli ostacoli che rispetto ai muri del robotarium. Nella trattazione fatta nel seguito si è deciso di proseguire secondo ordine temporale, e quindi prevedere una risoluzione a questa problematica nel costo prima per quanto riguarda gli ostacoli e successivamente per quanto riguarda i muri.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avendo compreso la dimensione dell'ostacolo, abbiamo deciso di modellare nuovamente il termine gaussiano, in modo da avere una rappresentazione più fedele della realtà, in particolare, abbiamo deciso di rappresentarlo\n",
    "con una varianza minore, manetenendo più o meno lo stesso valore di costo nel picco. Si fa notare come questo valore della varianza non crei semplicemente una gaussiana che assume valori all'interno dell'ostacolo, ma ha anche valori in un intorno dell'ostacolo. Questo è dovuto all'\"hand-position problem\" enunciato in precedenza. Grazie all'aiuto del plot, è possibile vedere come abbiamo modellato l'effettivo ostacolo\n",
    "come un rettangolo blu, mentre la posizione \"safe\" di hand-position in rosso. In questo modo il robot non tenderà di avvicinarsi neanche a questa safe position, e se lo farà in retromarcia comunque arriverà al massimo vicino all'ostacolo senza mai toccarlo effettivamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "obs_points = np.array(np.mat('0 ;0 ;0 ')) # da traccia\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "   \n",
    "\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) # Questo dipende dalle gaussiane mediate negli ostacoli,\n",
    "    \n",
    "    return(gauss_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)\n",
    "plot_3d_heatmap(goal_points,obs_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussiana inversa posizionata sul goal point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come prima modifica alla funzione di costo si fa notare un comportamento non ottimo che il robot ha quando si trova in prossimità del goal point, infatti, come si può notare dall'immagine nella cella successiva, il robot, nonostante arrivi in prossimità\n",
    "del goal point, non riesce a fermarsi subito, ma continua a muoversi in un intorno del goal point. Questo comportamento è dovuto al fatto che il costo dello stato è calcolato come la distanza dal goal point, e quindi, quando il robot si trova in prossimità\n",
    "il costo nel suo intorno assume valori simili e molto bassi, portando il robot a non puntare subito direttamente al goal point. Per tale motivo si è deciso di modificare la funzione di costo, in modo da rendere il costo in prossimità del goal point più \"scalato\", in maniera\n",
    "gauassiana, e quindi, in prossimità del goal point, il costo diminuisce rapidamente, portando il robot a puntare subito al goal point, senza girarci intorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "image_path = \"Training_Trajectories.jpg\" #TODO AGGIORNARE IMMAGINE\n",
    "\n",
    "image = mpimg.imread(image_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di conseguenza aggiungiamo un termine inverso per la gaussiana del goal point, con varianza uguale a quella dell'ostacolo, ma con valore leggermente minore, questo per evitare che in caso di errori di pianificazione, e scelta del goal point in prossimità,\n",
    "se non sull'ostacolo, il robot non provi ad andare nell'ostacolo per provare a raggiungere il goal point, ma ne rimanga comunque respinto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "    \n",
    "    sigma=0.02\n",
    "    cost = -10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                  +np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))\n",
    "   \n",
    "    return(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) \n",
    "\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "'''\n",
    "Definiamo un esperimento analogo a quello della traccia, per far notare le differenze nella scelta di questo costo\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Per le simulazioni future, abbiamo semplicemente deciso di rendere la simulazione una funzione, così da poterla semplicemente richiamare senza riscrivere nuovamente il codice\n",
    "'''\n",
    "\n",
    "def genericSimulation(initial_conditions,goal_points,obs_points):\n",
    "    # Instantiate Robotarium object\n",
    "    N = 1 #Amount of robots per simulation\n",
    "\n",
    "    N_experiment = len(initial_conditions)\n",
    "    # X_si is going to be two-dimensional state history\n",
    "    X_Si = [0]*N_experiment\n",
    "    # D_Xi is going to be two-dimensional inputs history\n",
    "    D_Xi = [0]*N_experiment\n",
    "\n",
    "    # This first for loop creates the initial conditions\n",
    "    for I in range(N_experiment):\n",
    "\n",
    "        X_si = []\n",
    "        D_xi = []\n",
    "\n",
    "        r = robotarium.Robotarium(number_of_robots=N, show_figure=True, initial_conditions=initial_conditions[I], sim_in_real_time=False)\n",
    "\n",
    "        # Create mapping from the control inputs to the actual velocity commands to the unicycle\n",
    "        # Note: this is a very practical situation (robots often provide transformation functions to low level commands)\n",
    "        si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion() #Converts single integrator inputs to unicycle inputs (low-level controller)\n",
    "        _, uni_to_si_states = create_si_to_uni_mapping()\n",
    "        \n",
    "        # define x initially\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        # Plotting Parameters\n",
    "        CM = np.random.rand(N+10,3) # Random Colors\n",
    "        goal_marker_size_m = 0.15\n",
    "        obs_marker_size_m = 0.15\n",
    "        marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "        marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "        font_size = determine_font_size(r,0.1)\n",
    "        line_width = 5\n",
    "\n",
    "        # Create Goal Point Markers\n",
    "        #Text with goal identification\n",
    "        goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "        #Plot text for caption\n",
    "        goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "        for ii in range(goal_points.shape[1])]\n",
    "        goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "        for ii in range(goal_points.shape[1])]\n",
    "\n",
    "        #Text with goal identification\n",
    "        obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "        #Plot text for caption\n",
    "        obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "        for ii in range(obs_points.shape[1])]\n",
    "        obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "        for ii in range(obs_points.shape[1])]\n",
    "\n",
    "        r.step()\n",
    "\n",
    "        # While the robot is away from the objective ...\n",
    "        while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N):\n",
    "\n",
    "            try:\n",
    "                # Get poses of agents\n",
    "                x = r.get_poses()\n",
    "                x_si = uni_to_si_states(x)\n",
    "\n",
    "                #Add to the dataset\n",
    "                X_si.append(x_si)\n",
    "\n",
    "                # The lines below define the pdf of the robot \n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "                x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "                # This is about plotting\n",
    "                for j in range(goal_points.shape[1]):\n",
    "                    goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "                for j in range(obs_points.shape[1]):\n",
    "                    obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "                # Task: compute the action from the policy. Call the variable dxi: \n",
    "                # this is the action sampled from the optimal solution to the control problem\n",
    "                dxi = Control_step(x_sample,U_space_1,U_space_2,goal_points,obs_points) \n",
    "\n",
    "                D_xi.append(dxi)\n",
    "\n",
    "                # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "                dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "                # Set the velocities inputs\n",
    "                r.set_velocities(np.arange(N), dxu)\n",
    "                # Iterate the simulation\n",
    "                r.step()\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        D_Xi[I] = D_xi\n",
    "        X_Si[I] = X_si\n",
    "\n",
    "        #Call at end of script to print debug information and for your script to run on the Robotarium server properly\n",
    "        r.call_at_scripts_end()\n",
    "\n",
    "        '''\n",
    "        Dato che grazie a matplotlib qt è possibile visualizzare la simulazione live, è stato aggiunto un ramo try except per bloccare forzatamente l'esperimento, in caso di non raggiungimento del goal point\n",
    "        '''\n",
    "    return X_Si,D_Xi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))] #Initial pose of the robots\n",
    "\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points, obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "E' stata creata una funzione anche per la preparazione dei dati per il plotting\n",
    "'''\n",
    "\n",
    "def prepareDataForPlotting(XX, UU):\n",
    "    #Prepare data for plotting\n",
    "    X = []\n",
    "    X_plot = []\n",
    "    U = []\n",
    "    U_plot = []\n",
    "\n",
    "    for i in range(len(XX)):\n",
    "        X.append(np.array(XX[i]))\n",
    "        X_plot.append(np.array(XX[i]))\n",
    "\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    X = np.reshape(X, (-1, 2))\n",
    "\n",
    "    U = []\n",
    "    for i in range(len(UU)):\n",
    "        U.append(np.array(UU[i]))\n",
    "        U_plot.append(np.array(UU[i]))\n",
    "\n",
    "    U = np.concatenate(U, axis=0)\n",
    "    U = np.reshape(U, (-1, 2))\n",
    "    return X, X_plot, U, U_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import cm \n",
    "from matplotlib.ticker import LinearLocator \n",
    "import numpy as np \n",
    "\n",
    "'''\n",
    "E anche una funzione per il plot delle traiettorie in 2D\n",
    "'''\n",
    "def plotTrajectory(X_plot,obs_points,goal_points): \n",
    " \n",
    "#Task: plot trajectories with different colors \n",
    "    plt.figure(figsize=(9, 6)) \n",
    " \n",
    "    for i in range(len(X_plot)): \n",
    "        plt.plot(X_plot[i][:, 0], X_plot[i][:, 1], label=f'Traiettoria {i+1}') \n",
    "        plt.plot(X_plot[i][0, 0],X_plot[i][0, 1],'*',color='black',markersize=10) \n",
    " \n",
    "    ''' \n",
    "    Le linee di codice precedenti servono per visualizzare le traiettorie dei robot, in particolare, per ogni esperimento viene visualizzata la traiettoria del robot, mappandola con un diverso colore aggiungendo \n",
    "    un marker alla posizione iniziale del robot. \n",
    " \n",
    "    NOTA: nelle successive linee di codice, vengono plottati i goal point e gli ostacoli, ma non rappresentano in maniera fedele la realtà, in quanto sono stati plottati in un ambiente 2D e rappresentati come rettangoli, mentre, \n",
    "    come già discusso in precedenza, gli ostacoli dovrebbero essere rappresentati più come delle sfere, a causa della natura gaussiana multivariata che rappresenta la distanza. \n",
    "    ''' \n",
    "    square= plt.Rectangle((goal_points[0,0]-0.175,goal_points[1,0]-0.175), 0.35, 0.35, fc='green',ec=\"black\") \n",
    "\n",
    "    #Draw obstacles \n",
    "    for i in range(np.size(obs_points,axis=1)): \n",
    "        # square= plt.Rectangle((obs_points_f[0,i]-0.1,obs_points_f[1,i]-0.1), 0.2, 0.2, fc='red',ec=\"black\")\n",
    "        square= plt.Rectangle((obs_points[0,i]-0.175,obs_points[1,i]-0.175), 0.35, 0.35, fc='red',ec=\"black\")\n",
    "        obstacle_square2 = patches.Rectangle((obs_points[0,i]-0.225, obs_points[1,i]-0.225), 0.45, 0.45, linewidth=1, edgecolor='r', facecolor='none',alpha=0.5)\n",
    "\n",
    "        plt.gca().add_patch(obstacle_square2)\n",
    "        plt.gca().add_patch(square) \n",
    "     \n",
    " \n",
    "    square= plt.Rectangle((goal_points[0,0]-0.175,goal_points[1,0]-0.175), 0.35, 0.35, fc='green',ec=\"black\") \n",
    "    plt.gca().add_patch(square) \n",
    "    plt.ylim(-1.1,1.1) \n",
    "    plt.xlim(-1.6,1.6) \n",
    "    plt.xlabel('X [m]') \n",
    "    plt.ylabel('Y [m]')\n",
    "    plt.title('Robot trajectories')\n",
    "    \n",
    "    arena_border = patches.Rectangle((-1.5, -1), 1.5-(-1.5), 1-(-1), linewidth=1, edgecolor='black', facecolor='none')\n",
    "    plt.gca().add_patch(arena_border)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "E anche una funzione per il plot delle traiettorie in 3D, sappiamo che il robot non si muove in uno spazio tridimensionale, ma in base alle traiettorie è possibile capire quali sono state le scelte del robot e perchè\n",
    "'''\n",
    " \n",
    "def plotTrajectory3D(X_plot,obs_points,goal_points): \n",
    "    x_min = -1.6  \n",
    "    x_max = 1.6 \n",
    "    y_min = -1.1 \n",
    "    y_max = 1.1 \n",
    "    x_range = np.linspace(x_min, x_max, 100)  \n",
    "    y_range = np.linspace(y_min, y_max, 100)  \n",
    "    X, Y = np.meshgrid(x_range, y_range)  \n",
    "    Z = np.zeros((100, 100))  \n",
    "    for i in range(100):  \n",
    "        for j in range(100):  \n",
    "            Z[i, j] = state_cost(np.array([X[i, j], Y[i, j]]), goal_points, obs_points)  \n",
    "    fig = plt.figure(figsize=(12,8))  \n",
    "    ax = fig.add_subplot(111, projection='3d', autoscale_on=True)  \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7)  # Update alpha value here  \n",
    "    ax.set_xlabel('X')  \n",
    "    ax.set_ylabel('Y')  \n",
    "    ax.set_zlabel('Cost')  \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point')  \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here  \n",
    "    \n",
    "    original_list=[] \n",
    "    for i in range(len(X_plot)): \n",
    "        new_inner_list=[] \n",
    "        for j in range(len(X_plot[i])): \n",
    "            new_array_3d=np.append(X_plot[i][j],state_cost(X_plot[i][j],goal_points,obs_points)) \n",
    "            new_inner_list.append(new_array_3d) \n",
    "            \n",
    "        original_list.append(new_inner_list) \n",
    "    \n",
    "    for i in range(len(X_plot)): \n",
    "        original_array = np.array(original_list[i]) \n",
    "        plt.plot(original_array[:, 0], original_array[:, 1], 0,  label=f'Trajectory {i+1}') \n",
    "\n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.15, obs_points[0, i] - 0.15, obs_points[0, i] + 0.15, obs_points[0, i] + 0.15, obs_points[0, i] - 0.15]\n",
    "        square_y = [obs_points[1, i] - 0.15, obs_points[1, i] + 0.15, obs_points[1, i] + 0.15, obs_points[1, i] - 0.15, obs_points[1, i] - 0.15]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "        # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.25, obs_points[0, i] - 0.25, obs_points[0, i] + 0.25, obs_points[0, i] + 0.25, obs_points[0, i] - 0.25]\n",
    "        square_y_large = [obs_points[1, i] - 0.25, obs_points[1, i] + 0.25, obs_points[1, i] + 0.25, obs_points[1, i] - 0.25, obs_points[1, i] - 0.25]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "\n",
    "    ax.legend() \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dopo aver inserito questo nuovo termine facciamo notare come, in caso di sbagliata pianificazione, il robot non si avvicina mai all'ostacolo, ma rimane sempre a una distanza di sicurezza, e questo è dovuto al fatto che il costo della gaussiana inversa è minore\n",
    "rispetto a quello della gaussiana sull'ostacolo\n",
    "'''\n",
    "goal_points = np.array(np.mat('0; 0; 0'))\n",
    "\n",
    "obs_points = np.array(np.mat('0 ;0;0')) \n",
    "\n",
    "\n",
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions=[np.array(np.mat('1.4;0.9; 0'))] \n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points, obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "\n",
    "'''\n",
    "Come vediamo il robot non tenta di andare nel goal point, ma rimane respinto dall'ostacolo, da notare come viene in caso di sovrapposizione abbiamo deciso di mostrare l'ostacolo implicitamente assumendo che il goal point\n",
    "fosse nello stesso punto\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROVA CON CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "image_path = \"Wall.jpeg\"\n",
    "\n",
    "image = mpimg.imread(image_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ulteriore appunto che possiamo fare al costo attuale, è che, come è possibile vedere dal plot 3D qui sopra, il cluster di ostacoli crea una sorta di \"muro\" che porta il robot a fermarsi intorno al suo punto medio, in caso di goal point posizionato dietro\n",
    "al cluster di ostacoli. Per evitare ciò, c'è bisogno che anche il cluster sia modellato come una gaussiana per permettere così al robot di \"scivolare\" ai bordi del cluster e raggiungere il goal point. Questo lo abbiamo raggiunto grazie alla modellazione\n",
    "degli ostacoli tramite grafo, così da trovare i cluster, e modellazione del costo del clustering come una gaussiana centrata nel centro geometrico del cluster.\n",
    "La scelta di clusterizzazione per una distanza < 0.45 tra gli ostacoli, è per discretizzare quei gruppi di ostacoli tra i quali il robot non passerebbe (il robot è grosso 0.11 cm, quindi se la distanza fra i centri degli ostacoli è < 0.45, allora sicuramente lì il robot\n",
    "non passa)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "Funzione per creare il grafo, trovare le componenti connesse e calcolare il loro centro geometrico\n",
    "'''\n",
    "def clustering(obs_points):\n",
    "\n",
    "    # Create an empty graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        G.add_node(i)\n",
    "\n",
    "    # Add edges between nodes based on Euclidean distance\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        for j in range(i+1, obs_points.shape[1]):\n",
    "            distance = np.linalg.norm(obs_points[:,i] - obs_points[:,j])\n",
    "            if distance <= 0.45:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "   \n",
    "    # Find connected components\n",
    "    connected_components = list(nx.connected_components(G))\n",
    "    centroidi = []\n",
    "    # Print connected components\n",
    "    for i, component in enumerate(connected_components):\n",
    "        sumx=0\n",
    "        sumy=0\n",
    "        for j in component:\n",
    "            sumx+=obs_points[0][j]\n",
    "            sumy+=obs_points[1][j]\n",
    "        centroidi.append([sumx/len(component),sumy/len(component),len(component)])\n",
    "    \n",
    "    return centroidi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Funzione di costo con aggiunta del costo del clustering, in particolare verifichiamo che il centroide non sia troppo vicino al goal point, in caso contrario il costo tende a 0, altrimenti il costo è proporzionale ad una gaussiana centrata nel centroide e con valore\n",
    "maggiore a seconda del numero di ostacoli che compongono il cluster, perchè maggiori gli ostacoli più velocemente vogliamo che il robot si spinga ai lati del cluster. In questo caso il goal point è assunto essere soltanto uno, in caso di più goal point, la funzione\n",
    "deve essere modificata per tenerlo in conto\n",
    "'''\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    centroidi=clustering(obs_points)\n",
    "\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "    cost2 = 0\n",
    "    for i in range(len(centroidi)):\n",
    "            dist= np.sqrt((goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2) \n",
    "            dist=dist if dist < 0.175 else 1 \n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist\n",
    "            \n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) \n",
    "  \n",
    "    \n",
    "    sigma=0.02\n",
    "    cost = -10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))+cost2\n",
    "\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('-0.5; 0; 0'))\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;-0.4 -0.2 0 0.2 0.4;0 0 0 0 0'))\n",
    "'''\n",
    "Verifichiamo con un esempio a doc cosa succede\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.3; 0; 0'))]\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "'''\n",
    "Il robot, nonostante ai lati del cluster non riesca subito ad individuare la direzione ottimale per raggiungere il goal point, riesce comunque,anche grazie alla rumorosità inserità, a raggiungere il goal point\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Facciamo ora l'esperimento con le condizioni date da traccia\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) \n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))] #Initial pose of the robots\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points, obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "'''\n",
    "Anche in questo caso si comporta in maniera corretta e il robot riesce a raggiungere sempre l'obiettivo\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Facciamo notare come l'aggiunta del termine clustering non crea situazioni critiche, come potrebbe creare la gaussiana inversa (ma che abbiamo fatto notare come ciò non accade), poichè in caso di vicinanza al goal point, il valore\n",
    "della gaussiana del clustering si riduce drasticamente\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggiunta dell'hand position anche per muro \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_cost(state,goal_points,obs_points):\n",
    "    centroidi=clustering(obs_points)\n",
    "\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "    cost2 = 0\n",
    "    for i in range(len(centroidi)):\n",
    "            dist= (goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2 # da cambiare se sono più goal point #TODO\n",
    "            dist=dist if dist < 0.175 else 1 #(%1 è per evitare di farla divergere, cioè mantenerla in 1 però è da verificare)\n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist\n",
    "            # Se il centroide è trppo vicino al goal point, allora la gaussiana è molto piccola, evitando di rischiare di portare il robot a non voler andare verso il goal point\n",
    "\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) \n",
    "  \n",
    "    \n",
    "    sigma=0.06\n",
    "    cost=-10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 20*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))+cost2\n",
    "   \n",
    "\n",
    "    return(cost)\n",
    "\n",
    "'''\n",
    "Come annunciato all'inizio della discussione, anche per quanto riguarda i bordi del robotarium abbiamo aggiunto una safe position per il problema dell'hand position del robot, aumentando un poco la varianza per \"allungarsi\" fino ai bordi teorici del muro\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "'''\n",
    "   Abbiamo ridefinito le funzioni per il plotting, per aggiungere anche il \"nuovo bordo\" da evitare, sia per il caso 2D che per il caso 3D\n",
    "'''\n",
    "\n",
    "def plot_heatmap(goal_points,obs_points):\n",
    "    plt.figure(figsize=(9,6))\n",
    "    x_min = -1.6\n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min,x_max,100)\n",
    "    y_range = np.linspace(y_min,y_max,100)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    Z = np.zeros((100,100))\n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            Z[i,j] = state_cost(np.array([X[i,j],Y[i,j]]),goal_points,obs_points)\n",
    "    plt.pcolormesh(X,Y,Z)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(goal_points[0],goal_points[1],c='r')\n",
    "    plt.scatter(obs_points[0,:],obs_points[1,:],c='k')\n",
    "    plt.title('Cost function')\n",
    "\n",
    "    # Add labels to the axes\n",
    "    plt.xlabel('X [m]')\n",
    "    plt.ylabel('Y [m]')\n",
    "    \n",
    "    # Add a rectangle for the border of the arena\n",
    "    arena_border = patches.Rectangle((-1.5, -1), 1.5-(-1.5), 1-(-1), linewidth=1, edgecolor='black', facecolor='none')\n",
    "    arena_border2 = patches.Rectangle((-1.4, -0.9), 1.4-(-1.4), 0.9-(-0.9), linewidth=1, edgecolor='red', facecolor='none')\n",
    "\n",
    "    plt.gca().add_patch(arena_border)\n",
    "    plt.gca().add_patch(arena_border2)\n",
    "    \n",
    "    # Add squares for each obstacle\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        obstacle_square = patches.Rectangle((obs_points[0,i]-0.175, obs_points[1,i]-0.175), 0.35, 0.35, linewidth=1, edgecolor='b', facecolor='none',alpha=0.5)\n",
    "        obstacle_square2 = patches.Rectangle((obs_points[0,i]-0.225, obs_points[1,i]-0.225), 0.45, 0.45, linewidth=1, edgecolor='r', facecolor='none',alpha=0.5)\n",
    "\n",
    "        plt.gca().add_patch(obstacle_square)\n",
    "        plt.gca().add_patch(obstacle_square2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_3d_heatmap(goal_points, obs_points): \n",
    "    x_min = -1.6 \n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min, x_max, 100) \n",
    "    y_range = np.linspace(y_min, y_max, 100) \n",
    "    X, Y = np.meshgrid(x_range, y_range) \n",
    "    Z = np.zeros((100, 100)) \n",
    "    for i in range(100): \n",
    "        for j in range(100): \n",
    "            Z[i, j] = state_cost(np.array([X[i, j], Y[i, j]]), goal_points, obs_points) \n",
    "    fig = plt.figure(figsize=(15,10)) \n",
    "    ax = fig.add_subplot(111, projection='3d') \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7)  # Update alpha value here \n",
    "    ax.set_xlabel('X') \n",
    "    ax.set_ylabel('Y') \n",
    "    ax.set_zlabel('Cost') \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point') \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here \n",
    "    \n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.175, obs_points[0, i] - 0.175, obs_points[0, i] + 0.175, obs_points[0, i] + 0.175, obs_points[0, i] - 0.175]\n",
    "        square_y = [obs_points[1, i] - 0.175, obs_points[1, i] + 0.175, obs_points[1, i] + 0.175, obs_points[1, i] - 0.175, obs_points[1, i] - 0.175]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "       # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.275, obs_points[0, i] - 0.275, obs_points[0, i] + 0.275, obs_points[0, i] + 0.275, obs_points[0, i] - 0.275]\n",
    "        square_y_large = [obs_points[1, i] - 0.275, obs_points[1, i] + 0.275, obs_points[1, i] + 0.275, obs_points[1, i] - 0.275, obs_points[1, i] - 0.275]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    square_x = [-1.4, -1.4, 1.4, 1.4, -1.4]\n",
    "    square_y = [-0.9, 0.9, 0.9, -0.9, -0.9]\n",
    "    ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "    \n",
    "    # Add larger red square centered at obstacle points\n",
    "    square_x_large = [-1.4, -1.4, 1.4, 1.4, -1.4]\n",
    "    square_y_large = [-0.9, 0.9, 0.9, -0.9, -0.9]\n",
    "    ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "\n",
    "    ax.legend() \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) \n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "plot_heatmap(goal_points,obs_points)\n",
    "\n",
    "'''\n",
    "Effettuiamo l'esperimento dato da traccia\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))] #Initial pose of the robots\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "\n",
    "''' \n",
    "Il robot si comporta bene\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cerchiamo di capire se il robot potrebbe uscire dal robotarium e quindi inserire un termine \"a muro\" letteralmente per evitare che ciò accada\n",
    "'''\n",
    "goal_points = np.array(np.mat('1.25; 0.35; 0')) \n",
    "obs_points = np.array(np.mat('0.9 1.25;0.8 0.6 ;0 0'))\n",
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.25;0.85; 0'))]\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points, obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "'''Da alcuni test fatti, in questo caso bloccando manualmente la funzione, oppure #TODO condizione di terminazione, si nota come il robot non tenta di uscire dai limiti, ma piuttosto rimane intrappolato, il chè va bene, nel caso in cui\n",
    "si trovino situazioni in cui il robot invece tenti di uscire, bisognerebbe agire nuovamente sulla funzione di costo per evitare ciò'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esperimento interessante, robot in mezzo agli ostacoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goal_points = np.array(np.mat('0; 0; 0')) \n",
    "obs_points = np.array(np.mat('-0.4 -0.4 -0.4 0 0.4 0.4 0.4; -0.4 0 0.4 0.4 0.4 0 -0.4; 0 0 0 0 0 0 0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_cost(state,goal_points,obs_points):\n",
    "    centroidi=clustering(goal_points,obs_points)\n",
    "\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "    cost2 = 0\n",
    "    for i in range(len(centroidi)):\n",
    "            dist= (goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2 # da cambiare se sono più goal point #TODO\n",
    "            dist=dist if dist < 0.175 else 1 #(%1 è per evitare di farla divergere, cioè mantenerla in 1 però è da verificare)\n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist\n",
    "            # Se il centroide è trppo vicino al goal point, allora la gaussiana è molto piccola, evitando di rischiare di portare il robot a non voler andare verso il goal point\n",
    "\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) \n",
    "  \n",
    "    \n",
    "    sigma=0.06\n",
    "    cost=-10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 20*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))+cost2\n",
    "   \n",
    "\n",
    "    return(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('0;-0.85; 0'))]\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "'''\n",
    "In questo caso il robot riesce a raggiungere l'obiettivo, nonostante un pò di difficoltà, avendo anche abbastanza spazio per passare tra gli ostacoli. Una simulazione simile, ma in cui il corridoio tra gli ostacoli fosse più piccolo, è stata fatta, e il robot\n",
    "non riesce a raggiungere l'obiettivo, ma rimane intrappolato tra gli ostacoli.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altri esperimenti "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "obs_points = np.array(np.mat('0.5 0.9 0.9; 0.75 0.55 0.25; 0 0 0' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('0.9;0.85; 0'))]\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casi non risolti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goal_points = np.array(np.mat('0.9; 0.85; 0')) # test\n",
    "obs_points = np.array(np.mat('0.5 0.9 0.9; 0.75 0.55 0.25; 0 0 0' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('0.0;0; 0'))]\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altro caso non risolto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('0; 0; 0')) \n",
    "obs_points = np.array(np.mat('-0.35 -0.35 -0.35 0 0.35 0.35 0.35; -0.35 0 0.35 0.35 0.35 0 -0.35; 0 0 0 0 0 0 0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('0;-0.8; 0')),np.array(np.mat('0;+0.8; 0'))] #Initial pose of the robots\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambio delle feature (Esperimento da traccia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data la funzione di costo:\n",
    "'''\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    centroidi=clustering(obs_points)\n",
    "\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "    cost2 = 0\n",
    "    for i in range(len(centroidi)):\n",
    "            dist= (goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2 # da cambiare se sono più goal point #TODO\n",
    "            dist=dist if dist < 0.175 else 1 #(% 1 è per evitare di farla divergere, cioè mantenerla in 1 però è da verificare)\n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist\n",
    "            # Se il centroide è trppo vicino al goal point, allora la gaussiana è molto piccola, evitando di rischiare di portare il robot a non voler andare verso il goal point\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) \n",
    "    \n",
    "    sigma=0.06\n",
    "    cost=-10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 20*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))+cost2\n",
    "   \n",
    "\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) # Da traccia\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0')) # Da traccia\n",
    "\n",
    "initial_conditions = [np.array(np.mat('1.45;0.95; 0')),np.array(np.mat('0.225;0.95; 0')),np.array(np.mat('0.225;0.25; 3.14')),np.array(np.mat('1.45;0.25; 0')),np.array(np.mat('1.45;-0.75; 3.14')),np.array(np.mat('1;-0.95; 0')),\n",
    "                      np.array(np.mat('0.225;-0.95; 0')),np.array(np.mat('-0.225;-0.95; 3.14')), np.array(np.mat('-0.225;0.95; 0')),np.array(np.mat('-0.225;0.45; 0')), np.array(np.mat('-1.45;0.95; 0')),np.array(np.mat('-1.45;0.25; 0'))]\n",
    "\n",
    "\n",
    "print(len(initial_conditions))\n",
    "plot_heatmap(goal_points,obs_points)\n",
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se vuoi runnare di nuovo il FOC devi rieseguire il codice di definizione della control_step sopra.\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggiunta dei termini distanza dai muri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')) # da traccia\n",
    "#obs_points_f = np.array(np.mat('-1.35 -1.35 -1.35 -1.35 -1.35 -0.675 -0.675 -0.675 -0.675 -0.675 0 0 0 0 0 0.675 0.675 0.675 0.675 0.675 1.35 1.35 1.35 1.35 1.35;-0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n",
    "# obs_points_f = np.array(np.mat('0 0 0 0 0 0.5 0.5 0.5 0.5 0.5 -0.5 -0.5 -0.5 -0.5 -0.5 1 1 1 1 1 -1 -1 -1 -1 -1 ;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')) # da traccia\n",
    "\n",
    "# obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8 -1.15 -0.4 0.4 1.15 -1.15 -0.4 0.4 1.15 1.5 1.5 1.5 -1.5 -1.5 -1.5;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 1 1 1 1 -1 -1 -1 -1 0.5 0 -0.5 0.5 0 -0.5;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')) # da traccia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature del prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature nostre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feature = np.size(obs_points_f,axis=1)+1+1 # 1 per la distanza dal goal point, 1 per la gaussiana sul goal point, 4 per i muri\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    sigma=0.06\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) # per il goal point\n",
    "    features[1] = (1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) + np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) + np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2))\n",
    "    \n",
    "    # tollerance=1e-2  \n",
    "    # features[2] = ((1/((next_state[0]-1.5)**2  + tollerance))) + 1/((1.5-goal_points[0])**2+tollerance) # per il muro a destra\n",
    "    # features[3] = ((1/((next_state[0]-(-1.5))**2  + tollerance))) + 1/((-1.5-goal_points[0])**2+tollerance)  # per il muro a sinistra\n",
    "    # features[4] = ((1/((next_state[1]-1.0)**2  + tollerance))) + 1/((1.0-goal_points[1])**2+tollerance) # per il muro sopra\n",
    "    # features[5] = ((1/((next_state[1]-(-1.0))**2  + tollerance))) + 1/((-1.0-goal_points[1])**2+tollerance)  # per il muro sotto\n",
    "\n",
    "    # sigma=0.06\n",
    "    # features[2] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) # per il muro a destra\n",
    "    # features[3] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)  # per il muro a sinistra\n",
    "    # features[4] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) # per il muro sopra\n",
    "    # features[5] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2)  # per il muro sotto\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codice per l'ioc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1\n",
    "w = cp.Variable((1,N_feature))\n",
    "constraints = [w >= 0]\n",
    "R = np.zeros((99,1))\n",
    "L = []\n",
    "\n",
    "f_expect = np.zeros((2,20))\n",
    "feature_sampled = np.zeros((N_feature,M))\n",
    "PF = np.zeros((control_space_size,control_space_size,M))\n",
    "\n",
    "for i in range(M):\n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size))\n",
    "    state = np.array(X[i,:]) #Get the state\n",
    "\n",
    "    x0 = state.reshape(-1,1)\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            next_sample = f.mean\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples)\n",
    "            feature_sample = np.zeros((N_feature,N_samples))\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1)\n",
    "\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy()))\n",
    "            '''\n",
    "            Questo riga rappresenta il termine (5) descritto nel markdown, in particolare rappresenta l'esponenziale dell'entropia cambiata di segno.\n",
    "            '''\n",
    "\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # N features x 9\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step)\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov)\n",
    "    next_samples_f1 = f1.rvs(N_samples)\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    tempPF = np.reshape(PF,(control_space_size**2,M)) # N features x 9\n",
    "\n",
    "    l =-(w @ feature_sampled[:,i])+cp.log_sum_exp(cp.reshape(w@features[:,:],(9,))+cp.log(tempPF[:,i]))\n",
    "    \n",
    "    '''\n",
    "    Ogni termine l, rappresenta il singolo termine della sommatoria (4) descritta nel markdown, in particolare, dato che il codice pre-esistente già calcolava il termine (5) e il termine (6), lo scopo di questa parte di codice\n",
    "    è quello di configurare le dimensionalità dei vari termini, effettuando un reshape della PF calcolata, portandola da una dimensionalità (N feature x 3 x 3), a una dimensionalità (N x 9) per essere gestita nella somma con il prodotto dei pesi con le features.\n",
    "    Inoltre, dato che stiamo risolvendo un problema di LSE tramite cvx, dobbiamo fornirgli in input il valore atteso del prodotto tra pesi e feature, e il valore atteso della f cambiata di segno, rappresentato dall'entropia,\n",
    "    ma dato che ci viene già fornito dal codice l'esponenziale dell'entropia, cambiata di segno, dobbiamo sommare il logaritmo di questa quantità in modo da riportarci nella forma originale del problema (4).\n",
    "    '''\n",
    "    \n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    L.append(l)\n",
    "\n",
    "    '''\n",
    "    Con queste linee di codice creiamo l'intera sommatoria su M esperimenti.\n",
    "    '''\n",
    "\n",
    "    # (iii) solve the problem \n",
    "objective = cp.Minimize(cp.sum(L))\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = False)\n",
    "\n",
    "'''\n",
    "Infine risolviamo il problema, facendo uso di cvx, minimizzando la sommatoria dei termini l, ottenendo i pesi w ottimi delle feature scelte.\n",
    "'''\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costo ricostruito professore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum #+ 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "                # + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "                # + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    \n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costro ricostruito nostro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    # tollerance=1e-2\n",
    "    # walls_sum = -(weights[:,2]*1/((state[0]-1.5)**2 + tollerance) + weights[:,3]*1/((state[0]-(-1.5))**2 + tollerance) + weights[:,4]*1/((state[1]-1.0)**2 + tollerance) + weights[:,5]*1/((state[1]+(-1.0))**2 + tollerance))\n",
    "\n",
    "    sigma=0.06\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum -weights[:,1]*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resto del codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transpose the data array to rotate the heatmap\n",
    "#data_rotated = np.transpose(Coat_Map) Costo effettivo\n",
    "data_rotated = np.transpose(Cost_Map)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting the pcolormesh for the data\n",
    "plt.pcolormesh(X_axis, Y_axis, data_rotated, cmap='viridis', alpha=0.92)\n",
    "plt.colorbar()\n",
    "\n",
    "# Define contour levels to create 6 regions\n",
    "contour_levels = np.linspace(data_rotated.min(), data_rotated.max(), 7)  # 7 levels for 6 regions\n",
    "\n",
    "# Get colors based on the viridis colormap for the given contour levels\n",
    "viridis_colors = plt.cm.viridis(np.linspace(0, 1, len(contour_levels)))\n",
    "\n",
    "for i, level in enumerate(contour_levels):\n",
    "    plt.contour(X_axis, Y_axis, data_rotated, levels=[level], colors=[viridis_colors[i]], linewidths=2.5, linestyles='dashed')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "In questo pezzo di codice viene visualizzato il costo dello stato calcolato con i pesi ottenuti dall'ottimizzazione, ovvero il costo stimato. In particolare, è rappresentato come una heatmap analogamente a quanto accaduto\n",
    "per il costo definito nel problema di FOC. Inoltre, sono state anche disegnate delle linee tratteggiate che rappresentano i livelli di costo.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_3d_heatmap_recostructed(goal_points, obs_points): \n",
    "    x_min = -1.6 \n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min, x_max, 100) \n",
    "    y_range = np.linspace(y_min, y_max, 100) \n",
    "    X, Y = np.meshgrid(x_range, y_range) \n",
    "    Z = np.zeros((100, 100)) \n",
    "    for i in range(100): \n",
    "        for j in range(100): \n",
    "            Z[i, j] = state_cost_estimated(np.array([X[i, j], Y[i, j]]), goal_points, obs_points, weights)\n",
    "    fig = plt.figure(figsize=(15,10)) \n",
    "    ax = fig.add_subplot(111, projection='3d') \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.97)  # Update alpha value here \n",
    "    ax.set_xlabel('X') \n",
    "    ax.set_ylabel('Y') \n",
    "    ax.set_zlabel('Cost') \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point') \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here \n",
    "\n",
    "    original_list=[] \n",
    "    for i in range(len(X_plot)): \n",
    "        new_inner_list=[] \n",
    "        for j in range(len(X_plot[i])): \n",
    "            new_array_3d=np.append(X_plot[i][j],state_cost(X_plot[i][j],goal_points,obs_points)) \n",
    "            new_inner_list.append(new_array_3d) \n",
    "            \n",
    "        original_list.append(new_inner_list) \n",
    "    \n",
    "    for i in range(len(X_plot)): \n",
    "        original_array = np.array(original_list[i]) \n",
    "        plt.plot(original_array[:, 0], original_array[:, 1],  0,  label=f'Trajectory {i+1}')\n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.175, obs_points[0, i] - 0.175, obs_points[0, i] + 0.175, obs_points[0, i] + 0.175, obs_points[0, i] - 0.175]\n",
    "        square_y = [obs_points[1, i] - 0.175, obs_points[1, i] + 0.175, obs_points[1, i] + 0.175, obs_points[1, i] - 0.175, obs_points[1, i] - 0.175]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "       # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.275, obs_points[0, i] - 0.275, obs_points[0, i] + 0.275, obs_points[0, i] + 0.275, obs_points[0, i] - 0.275]\n",
    "        square_y_large = [obs_points[1, i] - 0.275, obs_points[1, i] + 0.275, obs_points[1, i] + 0.275, obs_points[1, i] - 0.275, obs_points[1, i] - 0.275]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    \n",
    "    ax.legend() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap_recostructed(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "\n",
    "'''\n",
    "La funzione ha la sintassi e il significato analogo a quella definita per il problema di FOC, con la sola differenza che il costo dello stato viene calcolato con i pesi ottenuti dall'ottimizzazione,\n",
    "e quindi il costo è quello stimato dal problema IOC.\n",
    "'''\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                # Queste tre linee di codice calcolano il prossimo stato, a partire da una delle 9 azioni scandite\n",
    "                # dai cicli for, e creano una multivariata normale centrata nel prossimo stato con covarianza data\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                # Queste due linee di codice campionano 20 campioni dalla distribuzione calcolata precedentemente\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                # Calcoliamo il costo medio dei campioni secondo la funzione state_cost, si tratta di calcolare\n",
    "                # l'expected value della formula per la policy\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "                # print(\"entropy: \" + str(f.entropy()))\n",
    "                # print(\"next state: \" + str(next_state))\n",
    "                # print(\"cost: \" + str(cost))\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())\n",
    "\n",
    "                # la log_DKL è uguale, secondo formulazione, a np.exp(-DKL-costoatteso), il costo atteso lo abbiamo calcolato\n",
    "                # al punto precedente, mentre la DKL(f||g), dato che g è uniforme, diventa semplicemente l'entropia con un termine \n",
    "                # log(q) derivante da calcoli algebrici\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "\n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) # Da traccia\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0')) # Da traccia\n",
    "initial_conditions = [np.array(np.mat('-1.4;0.9; 0')),np.array(np.mat('1;0.9; 0')),np.array(np.mat('1;-0.25; 0'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supponendo che 'obs_points_f' e 'weights' siano definiti\n",
    "\n",
    "# Plot dei punti caratteristici sulla griglia\n",
    "plt.figure(figsize=(8, 6))\n",
    "newWeights=-weights[0][5:]# Normalizza i pesi nell'intervallo 100-1000\n",
    "weights_normalized = (newWeights - newWeights.min()) / (newWeights.max() - newWeights.min())\n",
    "weights_mapped = 100 + (weights_normalized * 900)  # Scala il valore tra 100 e 1000\n",
    "\n",
    "# Plot dei punti caratteristici con dimensioni basate sui pesi\n",
    "plt.scatter(obs_points_f[0], obs_points_f[1], s=weights_mapped, c='red', marker='o')\n",
    "\n",
    "# Plot del testo con i pesi corrispondenti\n",
    "for i in range(len(newWeights)):\n",
    "    plt.text(obs_points_f[0, i], obs_points_f[1, i]-0.15, f'{-newWeights[i]:.2f}', fontsize=8, color='black')\n",
    "\n",
    "plt.xlabel('Asse X')\n",
    "plt.ylabel('Asse Y')\n",
    "plt.title('Punti caratteristici sulla griglia del Robotarium con pesi')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambio delle feature (Robot che parte diedro un muro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideriamo il caso in cui il robot parta in un angolo tra degli ostacoli ed il goal point sia dietro questi ostacoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data la funzione di costo:\n",
    "'''\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    centroidi=clustering(obs_points)\n",
    "\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "    cost2 = 0\n",
    "    for i in range(len(centroidi)):\n",
    "            dist= (goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2 # da cambiare se sono più goal point #TODO\n",
    "            dist=dist if dist < 0.175 else 1 #(% 1 è per evitare di farla divergere, cioè mantenerla in 1 però è da verificare)\n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist\n",
    "            # Se il centroide è trppo vicino al goal point, allora la gaussiana è molto piccola, evitando di rischiare di portare il robot a non voler andare verso il goal point\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) \n",
    "    \n",
    "    sigma=0.06\n",
    "    cost=-10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 20*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))+cost2\n",
    "   \n",
    "\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "obs_points = np.array(np.mat('0.5 0.9 0.9; 0.75 0.55 0.20; 0 0 0' ))\n",
    "\n",
    "# initial_conditions = [np.array(np.mat('0.7; 0.85; 0')), np.array(np.mat('1.4; 0.9; 3.14')), np.array(np.mat('0.6; 0.45; 0'))]\n",
    "initial_conditions = [np.array(np.mat('0.7; 0.85; 0')), np.array(np.mat('1.4; 0.9; 3.14')), np.array(np.mat('0.6; 0.45; 0')), np.array(np.mat('1.45;0.95; 0')),np.array(np.mat('0.225;0.95; 0')),np.array(np.mat('-1.0; -0.75; 3.14')),np.array(np.mat('1.45; 0.25; 3.14')),np.array(np.mat('1.45;-0.75; 3.14')),np.array(np.mat('1;-0.95; 0')),\n",
    "                      np.array(np.mat('0.225;-0.95; 0')),np.array(np.mat('-0.225;-0.95; 3.14')), np.array(np.mat('-0.225;0.95; 0')),np.array(np.mat('-1.4; -0.95; 1.57')), np.array(np.mat('-1.45;0.95; 0')),np.array(np.mat('-1.45;0.25; 0'))]\n",
    "\n",
    "\n",
    "\n",
    "# for _ in range(20):\n",
    "#     x = np.random.uniform(-1.45, 1.45)\n",
    "#     y = np.random.uniform(-0.95, 0.95)\n",
    "#     initial_conditions.append(np.array([[x], [y], [0]]))\n",
    "\n",
    "\n",
    "plot_heatmap(goal_points,obs_points)\n",
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se vuoi runnare di nuovo il FOC devi rieseguire il codice di definizione della control_step sopra.\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature del prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')) # da traccia\n",
    "plot_heatmap(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature nostre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('-1.35 -1.35 -1.35 -1.35 -1.35 -0.675 -0.675 -0.675 -0.675 -0.675 0 0 0 0 0 0.675 0.675 0.675 0.675 0.675 1.35 1.35 1.35 1.35 1.35;-0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n",
    "plot_heatmap(goal_points,obs_points_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feature = np.size(obs_points_f,axis=1)+1+1 # 1 per la distanza dal goal point, 1 per la gaussiana sul goal point, 4 per i muri\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    sigma=0.06\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) # per il goal point\n",
    "    features[1] = (1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) + np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) + np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2))\n",
    "    \n",
    "    # tollerance=1e-2  \n",
    "    # features[2] = ((1/((next_state[0]-1.5)**2  + tollerance))) + 1/((1.5-goal_points[0])**2+tollerance) # per il muro a destra\n",
    "    # features[3] = ((1/((next_state[0]-(-1.5))**2  + tollerance))) + 1/((-1.5-goal_points[0])**2+tollerance)  # per il muro a sinistra\n",
    "    # features[4] = ((1/((next_state[1]-1.0)**2  + tollerance))) + 1/((1.0-goal_points[1])**2+tollerance) # per il muro sopra\n",
    "    # features[5] = ((1/((next_state[1]-(-1.0))**2  + tollerance))) + 1/((-1.0-goal_points[1])**2+tollerance)  # per il muro sotto\n",
    "\n",
    "    # sigma=0.06\n",
    "    # features[2] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) # per il muro a destra\n",
    "    # features[3] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)  # per il muro a sinistra\n",
    "    # features[4] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) # per il muro sopra\n",
    "    # features[5] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2)  # per il muro sotto\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codice per l'ioc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1\n",
    "w = cp.Variable((1,N_feature))\n",
    "constraints = [w >= 0]\n",
    "R = np.zeros((99,1))\n",
    "L = []\n",
    "\n",
    "f_expect = np.zeros((2,20))\n",
    "feature_sampled = np.zeros((N_feature,M))\n",
    "PF = np.zeros((control_space_size,control_space_size,M))\n",
    "\n",
    "for i in range(M):\n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size))\n",
    "    state = np.array(X[i,:]) #Get the state\n",
    "\n",
    "    x0 = state.reshape(-1,1)\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            next_sample = f.mean\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples)\n",
    "            feature_sample = np.zeros((N_feature,N_samples))\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1)\n",
    "\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy()))\n",
    "            '''\n",
    "            Questo riga rappresenta il termine (5) descritto nel markdown, in particolare rappresenta l'esponenziale dell'entropia cambiata di segno.\n",
    "            '''\n",
    "\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # N features x 9\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step)\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov)\n",
    "    next_samples_f1 = f1.rvs(N_samples)\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    tempPF = np.reshape(PF,(control_space_size**2,M)) # N features x 9\n",
    "\n",
    "    l =-(w @ feature_sampled[:,i])+cp.log_sum_exp(cp.reshape(w@features[:,:],(9,))+cp.log(tempPF[:,i]))\n",
    "    \n",
    "    '''\n",
    "    Ogni termine l, rappresenta il singolo termine della sommatoria (4) descritta nel markdown, in particolare, dato che il codice pre-esistente già calcolava il termine (5) e il termine (6), lo scopo di questa parte di codice\n",
    "    è quello di configurare le dimensionalità dei vari termini, effettuando un reshape della PF calcolata, portandola da una dimensionalità (N feature x 3 x 3), a una dimensionalità (N x 9) per essere gestita nella somma con il prodotto dei pesi con le features.\n",
    "    Inoltre, dato che stiamo risolvendo un problema di LSE tramite cvx, dobbiamo fornirgli in input il valore atteso del prodotto tra pesi e feature, e il valore atteso della f cambiata di segno, rappresentato dall'entropia,\n",
    "    ma dato che ci viene già fornito dal codice l'esponenziale dell'entropia, cambiata di segno, dobbiamo sommare il logaritmo di questa quantità in modo da riportarci nella forma originale del problema (4).\n",
    "    '''\n",
    "    \n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    L.append(l)\n",
    "\n",
    "    '''\n",
    "    Con queste linee di codice creiamo l'intera sommatoria su M esperimenti.\n",
    "    '''\n",
    "\n",
    "    # (iii) solve the problem \n",
    "objective = cp.Minimize(cp.sum(L))\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = False)\n",
    "\n",
    "'''\n",
    "Infine risolviamo il problema, facendo uso di cvx, minimizzando la sommatoria dei termini l, ottenendo i pesi w ottimi delle feature scelte.\n",
    "'''\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costo ricostruito professore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    \n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costro ricostruito nostro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    # tollerance=1e-2\n",
    "    # walls_sum = -(weights[:,2]*1/((state[0]-1.5)**2 + tollerance) + weights[:,3]*1/((state[0]-(-1.5))**2 + tollerance) + weights[:,4]*1/((state[1]-1.0)**2 + tollerance) + weights[:,5]*1/((state[1]+(-1.0))**2 + tollerance))\n",
    "\n",
    "    sigma=0.06\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum -weights[:,1]*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resto del codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "In questo pezzo di codice viene visualizzato il costo dello stato calcolato con i pesi ottenuti dall'ottimizzazione, ovvero il costo stimato. In particolare, è rappresentato come una heatmap analogamente a quanto accaduto\n",
    "per il costo definito nel problema di FOC. Inoltre, sono state anche disegnate delle linee tratteggiate che rappresentano i livelli di costo.\n",
    "'''\n",
    "\n",
    "# Transpose the data array to rotate the heatmap\n",
    "#data_rotated = np.transpose(Coat_Map) Costo effettivo\n",
    "data_rotated = np.transpose(Cost_Map)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting the pcolormesh for the data\n",
    "plt.pcolormesh(X_axis, Y_axis, data_rotated, cmap='viridis', alpha=0.92)\n",
    "plt.colorbar()\n",
    "\n",
    "# Define contour levels to create 6 regions\n",
    "contour_levels = np.linspace(data_rotated.min(), data_rotated.max(), 7)  # 7 levels for 6 regions\n",
    "\n",
    "# Get colors based on the viridis colormap for the given contour levels\n",
    "viridis_colors = plt.cm.viridis(np.linspace(0, 1, len(contour_levels)))\n",
    "\n",
    "for i, level in enumerate(contour_levels):\n",
    "    plt.contour(X_axis, Y_axis, data_rotated, levels=[level], colors=[viridis_colors[i]], linewidths=2.5, linestyles='dashed')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_3d_heatmap_recostructed(goal_points, obs_points): \n",
    "    x_min = -1.6 \n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min, x_max, 100) \n",
    "    y_range = np.linspace(y_min, y_max, 100) \n",
    "    X, Y = np.meshgrid(x_range, y_range) \n",
    "    Z = np.zeros((100, 100)) \n",
    "    for i in range(100): \n",
    "        for j in range(100): \n",
    "            Z[i, j] = state_cost_estimated(np.array([X[i, j], Y[i, j]]), goal_points, obs_points, weights)\n",
    "    fig = plt.figure(figsize=(15,10)) \n",
    "    ax = fig.add_subplot(111, projection='3d') \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.97)  # Update alpha value here \n",
    "    ax.set_xlabel('X') \n",
    "    ax.set_ylabel('Y') \n",
    "    ax.set_zlabel('Cost') \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point') \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here \n",
    "\n",
    "    original_list=[] \n",
    "    for i in range(len(X_plot)): \n",
    "        new_inner_list=[] \n",
    "        for j in range(len(X_plot[i])): \n",
    "            new_array_3d=np.append(X_plot[i][j],state_cost(X_plot[i][j],goal_points,obs_points)) \n",
    "            new_inner_list.append(new_array_3d) \n",
    "            \n",
    "        original_list.append(new_inner_list) \n",
    "    \n",
    "    for i in range(len(X_plot)): \n",
    "        original_array = np.array(original_list[i]) \n",
    "        plt.plot(original_array[:, 0], original_array[:, 1],  0,  label=f'Trajectory {i+1}')\n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.175, obs_points[0, i] - 0.175, obs_points[0, i] + 0.175, obs_points[0, i] + 0.175, obs_points[0, i] - 0.175]\n",
    "        square_y = [obs_points[1, i] - 0.175, obs_points[1, i] + 0.175, obs_points[1, i] + 0.175, obs_points[1, i] - 0.175, obs_points[1, i] - 0.175]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "       # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.275, obs_points[0, i] - 0.275, obs_points[0, i] + 0.275, obs_points[0, i] + 0.275, obs_points[0, i] - 0.275]\n",
    "        square_y_large = [obs_points[1, i] - 0.275, obs_points[1, i] + 0.275, obs_points[1, i] + 0.275, obs_points[1, i] - 0.275, obs_points[1, i] - 0.275]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    \n",
    "    ax.legend() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap_recostructed(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "\n",
    "'''\n",
    "La funzione ha la sintassi e il significato analogo a quella definita per il problema di FOC, con la sola differenza che il costo dello stato viene calcolato con i pesi ottenuti dall'ottimizzazione,\n",
    "e quindi il costo è quello stimato dal problema IOC.\n",
    "'''\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                # Queste tre linee di codice calcolano il prossimo stato, a partire da una delle 9 azioni scandite\n",
    "                # dai cicli for, e creano una multivariata normale centrata nel prossimo stato con covarianza data\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                # Queste due linee di codice campionano 20 campioni dalla distribuzione calcolata precedentemente\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                # Calcoliamo il costo medio dei campioni secondo la funzione state_cost, si tratta di calcolare\n",
    "                # l'expected value della formula per la policy\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "                # print(\"entropy: \" + str(f.entropy()))\n",
    "                # print(\"next state: \" + str(next_state))\n",
    "                # print(\"cost: \" + str(cost))\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())\n",
    "\n",
    "                # la log_DKL è uguale, secondo formulazione, a np.exp(-DKL-costoatteso), il costo atteso lo abbiamo calcolato\n",
    "                # al punto precedente, mentre la DKL(f||g), dato che g è uniforme, diventa semplicemente l'entropia con un termine \n",
    "                # log(q) derivante da calcoli algebrici\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "\n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "obs_points = np.array(np.mat('0.5 0.9 0.9; 0.75 0.55 0.20; 0 0 0' ))\n",
    "\n",
    "initial_conditions = [np.array(np.mat('0.7; 0.85; 0')), np.array(np.mat('1.4; 0.9; 3.14')), np.array(np.mat('0.6; 0.45; 0'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supponendo che 'obs_points_f' e 'weights' siano definiti\n",
    "\n",
    "# Plot dei punti caratteristici sulla griglia\n",
    "plt.figure(figsize=(8, 6))\n",
    "newWeights=-weights[0][5:]# Normalizza i pesi nell'intervallo 100-1000\n",
    "weights_normalized = (newWeights - newWeights.min()) / (newWeights.max() - newWeights.min())\n",
    "weights_mapped = 100 + (weights_normalized * 900)  # Scala il valore tra 100 e 1000\n",
    "\n",
    "# Plot dei punti caratteristici con dimensioni basate sui pesi\n",
    "plt.scatter(obs_points_f[0], obs_points_f[1], s=weights_mapped, c='red', marker='o')\n",
    "\n",
    "# Plot del testo con i pesi corrispondenti\n",
    "for i in range(len(newWeights)):\n",
    "    plt.text(obs_points_f[0, i], obs_points_f[1, i]-0.15, f'{-newWeights[i]:.2f}', fontsize=8, color='black')\n",
    "\n",
    "plt.xlabel('Asse X')\n",
    "plt.ylabel('Asse Y')\n",
    "plt.title('Punti caratteristici sulla griglia del Robotarium con pesi')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È una situazione sicuramente critica per il robot. Si fa notare che c'è bisogno di abbastanza esperimenti per ricostruire bene il costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambio delle feature (Goal point dietro gli ostacoli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideriamo il caso in cui il robot parta in un angolo tra degli ostacoli ed il goal point sia dietro questi ostacoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### MODIFCATA ########\n",
    "'''\n",
    "Data la funzione di costo:\n",
    "'''\n",
    "def state_cost(state,goal_points,obs_points): \n",
    "    centroidi=clustering(obs_points) \n",
    " \n",
    "    v = np.array([0.015, 0.015], dtype=np.float32) \n",
    "    covar = np.diag(v) \n",
    "    gauss_sum = 0 \n",
    "    cost2 = 0 \n",
    "    for i in range(len(centroidi)): \n",
    "            dist= np.sqrt((goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2) # da cambiare se sono più goal point #TODO \n",
    "            dist=dist if dist < 0.175 else 1 #(% 1 è per evitare di farla divergere, cioè mantenerla in 1 però è da verificare) \n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist \n",
    "            # Se il centroide è troppo vicino al goal point, allora la gaussiana è molto piccola, evitando di rischiare di portare il robot a non voler andare verso il goal point \n",
    " \n",
    "    for i in range(np.size(obs_points,axis=1)): \n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar)  \n",
    " \n",
    "    muri=[np.array([1.5,0.0,0.0]),np.array([-1.5,0.0,0.0]),np.array([0.0,1.0,0.0]),np.array([0.0,-1.0,0.0])] \n",
    "    muri_gauss_sum=0 \n",
    "    \n",
    "    covar_muri_oriz=np.diag(np.array([0.01, 0.1], dtype=np.float32))\n",
    "    covar_muri_vert=np.diag(np.array([0.1, 0.01], dtype=np.float32))\n",
    "    \n",
    "    for i in range (4): \n",
    "        for j in range (np.size(obs_points,axis=1)): \n",
    "            if(muri[i][0]!=0): \n",
    "                 if(np.abs(muri[i][0]-obs_points[0,j])<0.495): \n",
    "                        muri_gauss_sum += 15*my_logpdf(state[:2],np.array([(muri[i][0]+obs_points[0,j])/2,obs_points[1,j]]),covar_muri_oriz) \n",
    "            else: \n",
    "                if(np.abs(muri[i][1]-obs_points[1,j])<0.495): \n",
    "                        muri_gauss_sum += 15*my_logpdf(state[:2],np.array([obs_points[0,j],(muri[i][1]+obs_points[1,j])/2]),covar_muri_vert) \n",
    "                  \n",
    "    sigma=0.06 \n",
    "    cost=-10*my_logpdf(state[:2],goal_points[:2,0],covar) + 75*np.sqrt(((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2)) + gauss_sum + 20*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2) \n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2)) + cost2 + muri_gauss_sum\n",
    "    \n",
    "    # 30*(abs(state[0] - goal_points[0]) + abs(state[1] - goal_points[1]))\n",
    "    \n",
    "    return (cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# goal_points = np.array(np.mat('-1.4; -0.8; 0')) # Da traccia\n",
    "goal_points = np.array(np.mat('-0.35; 0.5; 0'))\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0')) # Da traccia\n",
    "\n",
    "# initial_conditions = [np.array(np.mat('1.4;0.95; 3.14')),np.array(np.mat('0.225;0.95; 0')),np.array(np.mat('0.225;0.25; 3.14')),np.array(np.mat('1.45;0.25; 0')),np.array(np.mat('1.45;-0.75; 3.14')),np.array(np.mat('1;-0.95; 0')),\n",
    "                    #   np.array(np.mat('0.225;-0.95; 0')),np.array(np.mat('-0.225;-0.95; 3.14')), np.array(np.mat('-0.225;0.95; 0')),np.array(np.mat('-0.225;0.45; 0')), np.array(np.mat('-1.45;0.95; 0')),np.array(np.mat('-1.45;0.25; 0'))]\n",
    "\n",
    "initial_conditions = [np.array(np.mat('1.4;0.95; 3.14')),np.array(np.mat('0.225;0.95; 0'))]\n",
    "\n",
    "plot_heatmap(goal_points,obs_points)\n",
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se vuoi runnare di nuovo il FOC devi rieseguire il codice di definizione della control_step sopra.\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature del prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')) # da traccia\n",
    "plot_heatmap(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature nostre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('-1.35 -1.35 -1.35 -1.35 -1.35 -0.675 -0.675 -0.675 -0.675 -0.675 0 0 0 0 0 0.675 0.675 0.675 0.675 0.675 1.35 1.35 1.35 1.35 1.35;-0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n",
    "plot_heatmap(goal_points,obs_points_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feature = np.size(obs_points_f,axis=1)+1+1 # 1 per la distanza dal goal point, 1 per la gaussiana sul goal point, 4 per i muri\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    sigma=0.06\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) # per il goal point\n",
    "    features[1] = (1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) + np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) + np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2))\n",
    "    \n",
    "    # tollerance=1e-2  \n",
    "    # features[2] = ((1/((next_state[0]-1.5)**2  + tollerance))) + 1/((1.5-goal_points[0])**2+tollerance) # per il muro a destra\n",
    "    # features[3] = ((1/((next_state[0]-(-1.5))**2  + tollerance))) + 1/((-1.5-goal_points[0])**2+tollerance)  # per il muro a sinistra\n",
    "    # features[4] = ((1/((next_state[1]-1.0)**2  + tollerance))) + 1/((1.0-goal_points[1])**2+tollerance) # per il muro sopra\n",
    "    # features[5] = ((1/((next_state[1]-(-1.0))**2  + tollerance))) + 1/((-1.0-goal_points[1])**2+tollerance)  # per il muro sotto\n",
    "\n",
    "    # sigma=0.06\n",
    "    # features[2] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) # per il muro a destra\n",
    "    # features[3] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)  # per il muro a sinistra\n",
    "    # features[4] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) # per il muro sopra\n",
    "    # features[5] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2)  # per il muro sotto\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codice per l'ioc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1\n",
    "w = cp.Variable((1,N_feature))\n",
    "constraints = [w >= 0]\n",
    "R = np.zeros((99,1))\n",
    "L = []\n",
    "\n",
    "f_expect = np.zeros((2,20))\n",
    "feature_sampled = np.zeros((N_feature,M))\n",
    "PF = np.zeros((control_space_size,control_space_size,M))\n",
    "\n",
    "for i in range(M):\n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size))\n",
    "    state = np.array(X[i,:]) #Get the state\n",
    "\n",
    "    x0 = state.reshape(-1,1)\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            next_sample = f.mean\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples)\n",
    "            feature_sample = np.zeros((N_feature,N_samples))\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1)\n",
    "\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy()))\n",
    "            '''\n",
    "            Questo riga rappresenta il termine (5) descritto nel markdown, in particolare rappresenta l'esponenziale dell'entropia cambiata di segno.\n",
    "            '''\n",
    "\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # N features x 9\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step)\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov)\n",
    "    next_samples_f1 = f1.rvs(N_samples)\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    tempPF = np.reshape(PF,(control_space_size**2,M)) # N features x 9\n",
    "\n",
    "    l =-(w @ feature_sampled[:,i])+cp.log_sum_exp(cp.reshape(w@features[:,:],(9,))+cp.log(tempPF[:,i]))\n",
    "    \n",
    "    '''\n",
    "    Ogni termine l, rappresenta il singolo termine della sommatoria (4) descritta nel markdown, in particolare, dato che il codice pre-esistente già calcolava il termine (5) e il termine (6), lo scopo di questa parte di codice\n",
    "    è quello di configurare le dimensionalità dei vari termini, effettuando un reshape della PF calcolata, portandola da una dimensionalità (N feature x 3 x 3), a una dimensionalità (N x 9) per essere gestita nella somma con il prodotto dei pesi con le features.\n",
    "    Inoltre, dato che stiamo risolvendo un problema di LSE tramite cvx, dobbiamo fornirgli in input il valore atteso del prodotto tra pesi e feature, e il valore atteso della f cambiata di segno, rappresentato dall'entropia,\n",
    "    ma dato che ci viene già fornito dal codice l'esponenziale dell'entropia, cambiata di segno, dobbiamo sommare il logaritmo di questa quantità in modo da riportarci nella forma originale del problema (4).\n",
    "    '''\n",
    "    \n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    L.append(l)\n",
    "\n",
    "    '''\n",
    "    Con queste linee di codice creiamo l'intera sommatoria su M esperimenti.\n",
    "    '''\n",
    "\n",
    "    # (iii) solve the problem \n",
    "objective = cp.Minimize(cp.sum(L))\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = False)\n",
    "\n",
    "'''\n",
    "Infine risolviamo il problema, facendo uso di cvx, minimizzando la sommatoria dei termini l, ottenendo i pesi w ottimi delle feature scelte.\n",
    "'''\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costo ricostruito professore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    \n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costro ricostruito nostro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    # tollerance=1e-2\n",
    "    # walls_sum = -(weights[:,2]*1/((state[0]-1.5)**2 + tollerance) + weights[:,3]*1/((state[0]-(-1.5))**2 + tollerance) + weights[:,4]*1/((state[1]-1.0)**2 + tollerance) + weights[:,5]*1/((state[1]+(-1.0))**2 + tollerance))\n",
    "\n",
    "    sigma=0.06\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum -weights[:,1]*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resto del codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "In questo pezzo di codice viene visualizzato il costo dello stato calcolato con i pesi ottenuti dall'ottimizzazione, ovvero il costo stimato. In particolare, è rappresentato come una heatmap analogamente a quanto accaduto\n",
    "per il costo definito nel problema di FOC. Inoltre, sono state anche disegnate delle linee tratteggiate che rappresentano i livelli di costo.\n",
    "'''\n",
    "\n",
    "# Transpose the data array to rotate the heatmap\n",
    "#data_rotated = np.transpose(Coat_Map) Costo effettivo\n",
    "data_rotated = np.transpose(Cost_Map)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting the pcolormesh for the data\n",
    "plt.pcolormesh(X_axis, Y_axis, data_rotated, cmap='viridis', alpha=0.92)\n",
    "plt.colorbar()\n",
    "\n",
    "# Define contour levels to create 6 regions\n",
    "contour_levels = np.linspace(data_rotated.min(), data_rotated.max(), 7)  # 7 levels for 6 regions\n",
    "\n",
    "# Get colors based on the viridis colormap for the given contour levels\n",
    "viridis_colors = plt.cm.viridis(np.linspace(0, 1, len(contour_levels)))\n",
    "\n",
    "for i, level in enumerate(contour_levels):\n",
    "    plt.contour(X_axis, Y_axis, data_rotated, levels=[level], colors=[viridis_colors[i]], linewidths=2.5, linestyles='dashed')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_3d_heatmap_recostructed(goal_points, obs_points): \n",
    "    x_min = -1.6 \n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min, x_max, 100) \n",
    "    y_range = np.linspace(y_min, y_max, 100) \n",
    "    X, Y = np.meshgrid(x_range, y_range) \n",
    "    Z = np.zeros((100, 100)) \n",
    "    for i in range(100): \n",
    "        for j in range(100): \n",
    "            Z[i, j] = state_cost_estimated(np.array([X[i, j], Y[i, j]]), goal_points, obs_points, weights)\n",
    "    fig = plt.figure(figsize=(15,10)) \n",
    "    ax = fig.add_subplot(111, projection='3d') \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.97)  # Update alpha value here \n",
    "    ax.set_xlabel('X') \n",
    "    ax.set_ylabel('Y') \n",
    "    ax.set_zlabel('Cost') \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point') \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here \n",
    "\n",
    "    original_list=[] \n",
    "    for i in range(len(X_plot)): \n",
    "        new_inner_list=[] \n",
    "        for j in range(len(X_plot[i])): \n",
    "            new_array_3d=np.append(X_plot[i][j],state_cost(X_plot[i][j],goal_points,obs_points)) \n",
    "            new_inner_list.append(new_array_3d) \n",
    "            \n",
    "        original_list.append(new_inner_list) \n",
    "    \n",
    "    for i in range(len(X_plot)): \n",
    "        original_array = np.array(original_list[i]) \n",
    "        plt.plot(original_array[:, 0], original_array[:, 1],  0,  label=f'Trajectory {i+1}')\n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.175, obs_points[0, i] - 0.175, obs_points[0, i] + 0.175, obs_points[0, i] + 0.175, obs_points[0, i] - 0.175]\n",
    "        square_y = [obs_points[1, i] - 0.175, obs_points[1, i] + 0.175, obs_points[1, i] + 0.175, obs_points[1, i] - 0.175, obs_points[1, i] - 0.175]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "       # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.275, obs_points[0, i] - 0.275, obs_points[0, i] + 0.275, obs_points[0, i] + 0.275, obs_points[0, i] - 0.275]\n",
    "        square_y_large = [obs_points[1, i] - 0.275, obs_points[1, i] + 0.275, obs_points[1, i] + 0.275, obs_points[1, i] - 0.275, obs_points[1, i] - 0.275]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    \n",
    "    ax.legend() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap_recostructed(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "\n",
    "'''\n",
    "La funzione ha la sintassi e il significato analogo a quella definita per il problema di FOC, con la sola differenza che il costo dello stato viene calcolato con i pesi ottenuti dall'ottimizzazione,\n",
    "e quindi il costo è quello stimato dal problema IOC.\n",
    "'''\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                # Queste tre linee di codice calcolano il prossimo stato, a partire da una delle 9 azioni scandite\n",
    "                # dai cicli for, e creano una multivariata normale centrata nel prossimo stato con covarianza data\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                # Queste due linee di codice campionano 20 campioni dalla distribuzione calcolata precedentemente\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                # Calcoliamo il costo medio dei campioni secondo la funzione state_cost, si tratta di calcolare\n",
    "                # l'expected value della formula per la policy\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "                # print(\"entropy: \" + str(f.entropy()))\n",
    "                # print(\"next state: \" + str(next_state))\n",
    "                # print(\"cost: \" + str(cost))\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())\n",
    "\n",
    "                # la log_DKL è uguale, secondo formulazione, a np.exp(-DKL-costoatteso), il costo atteso lo abbiamo calcolato\n",
    "                # al punto precedente, mentre la DKL(f||g), dato che g è uniforme, diventa semplicemente l'entropia con un termine \n",
    "                # log(q) derivante da calcoli algebrici\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "\n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "obs_points = np.array(np.mat('0.5 0.9 0.9; 0.75 0.55 0.20; 0 0 0' ))\n",
    "\n",
    "initial_conditions = [np.array(np.mat('0.7; 0.85; 0')), np.array(np.mat('1.4; 0.9; 3.14')), np.array(np.mat('0.6; 0.45; 0'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supponendo che 'obs_points_f' e 'weights' siano definiti\n",
    "\n",
    "# Plot dei punti caratteristici sulla griglia\n",
    "plt.figure(figsize=(8, 6))\n",
    "newWeights=-weights[0][5:]# Normalizza i pesi nell'intervallo 100-1000\n",
    "weights_normalized = (newWeights - newWeights.min()) / (newWeights.max() - newWeights.min())\n",
    "weights_mapped = 100 + (weights_normalized * 900)  # Scala il valore tra 100 e 1000\n",
    "\n",
    "# Plot dei punti caratteristici con dimensioni basate sui pesi\n",
    "plt.scatter(obs_points_f[0], obs_points_f[1], s=weights_mapped, c='red', marker='o')\n",
    "\n",
    "# Plot del testo con i pesi corrispondenti\n",
    "for i in range(len(newWeights)):\n",
    "    plt.text(obs_points_f[0, i], obs_points_f[1, i]-0.15, f'{-newWeights[i]:.2f}', fontsize=8, color='black')\n",
    "\n",
    "plt.xlabel('Asse X')\n",
    "plt.ylabel('Asse Y')\n",
    "plt.title('Punti caratteristici sulla griglia del Robotarium con pesi')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È una situazione sicuramente critica per il robot. Si fa notare che c'è bisogno di abbastanza esperimenti per ricostruire bene il costo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#TODO Riprovare a fare l'IOC con meno punti (magari tornando alle feature aggiugendo gaussiana inversa e muri), oppure in generale rifare l'IOC avendo meno simulazioni nel FOC (6-12 come range secondo me non è male)\n",
    "#TODO Inotre fare altri markdown da qui dove magari scrivere (Esperimento cluster di blocchi), oppure (Esperimento goal point tra ostacolo) e così via, più sono meglio è teoricamente, tanto si tratta semplicemente di prendere qualche configurazione\n",
    "# di sopra e fare anche l'IOC, e magari aggiungerne altre se volete\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
