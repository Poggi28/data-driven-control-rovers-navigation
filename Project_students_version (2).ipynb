{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kph1lruSgPWp"
   },
   "outputs": [],
   "source": [
    "import rps.robotarium as robotarium\n",
    "from rps.utilities.transformations import *\n",
    "from rps.utilities.barrier_certificates import *\n",
    "from rps.utilities.misc import *\n",
    "from rps.utilities.controllers import *\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzioni introduttive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eszwfUCygPWs"
   },
   "outputs": [],
   "source": [
    "#Defining the input axes\n",
    "# Note: the boundaries for the control actions are the actuation constraints imposed by the physics of the robots\n",
    "\n",
    "control_space_size = 3  # Three possible inputs for each control axis\n",
    "\n",
    "'''Lo spazio di controllo è discretizzato su 3 possibili valori, che rappresentano la direzione di movimento del robot su un determinato asse, dato che il robot può muoversi solo sul piano\n",
    "x-y (non può muoversi in altezza), rappresentano lo spostamento positivo, negativo o nullo su quel determinato asse. Dal punto di vista del codice ciò è codificato come:'''\n",
    "\n",
    "# TODO: CONTROLLARE SE SONO VELOCITA' QUI, PERCHE' DOPO NELLA FUNZIONE MODEL_STEP LE CHIAMA VELOCITIES\n",
    "'''-0.5 -> velocità lungo la direzione negativa dell'asse\n",
    "0 -> nessuna velocità lungo l'asse\n",
    "+0.5-> velocità lungo la direzione positiva dell'asse'''\n",
    "\n",
    "# Definiamo quindi lo spazio di controllo come un array di 3 elementi, che rappresentano i possibili valori che può assumere un asse di controllo, sia per l'asse delle x che per l'asse delle y\n",
    "U_space_1 = np.array(np.linspace((-0.5),(0.5),control_space_size)) \n",
    "U_space_2 = np.array(np.linspace((-0.5),(0.5),control_space_size))\n",
    "\n",
    "# La variabile time_step rappresenta l'intervallo di tempo tra due istanti successivi della simulazione robotarium. In particolare, dalla documentazione,\n",
    "# il codice viene eseguito ogni 0.033 secondi,\n",
    "time_step = 0.033 # Robotarium time-step (from the documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Nonostante per il controllo data driven non sia necessario conoscere il modello del sistema, è necessario conoscerlo per simularlo, questa funzione è utilizzata\n",
    "semplicemente per calcolare il prossimo stato del robot, dato lo stato attuale e l'azione che si vuole compiere, in questo caso l'azione è rappresentata da un vettore di velocità come\n",
    "spiegato precedentemente '''\n",
    "# This function performs a \"model\" step using the documented dynamics\n",
    "# Note: from the viewpoint of the controller the dynamics is not necesarily known\n",
    "def model_step(x,velocities,time_step):\n",
    "    poses = np.zeros((2,1))\n",
    "    # Update pose of the robots\n",
    "    poses[0] = x[0] + time_step*velocities[0]\n",
    "    poses[1] = x[1] + time_step*velocities[1]\n",
    "    return(poses)\n",
    "\n",
    "# Get the value of a Gaussian pf at a given point *****?\n",
    "# This function is used to evaluate the pf at a given point (x,y) given the mean and covariance of the Gaussian \n",
    "def my_logpdf(x, u, covar):\n",
    "    k = len(x)  # dimension\n",
    "    a = np.transpose(x - u)\n",
    "    b = np.linalg.inv(covar)\n",
    "    c = x - u\n",
    "    d = np.matmul(a, b)\n",
    "    e = np.matmul(d, c)\n",
    "    numer = np.exp(-0.5 * e)\n",
    "    f = (2 * np.pi)**k\n",
    "    g = np.linalg.det(covar)\n",
    "    denom = np.sqrt(f * g)\n",
    "    pdf = numer / denom\n",
    "    return pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione my_logpdf calcola il valore della pdf di una gaussiana multivariata, dato un punto (x,y), la media e la covarianza della gaussiana. In questo caso specifico la covarianza\n",
    "è fissata, come si può vedere successivamente nel codice, al valore: covar = np.diag(v), dove v = np.array([0.02, 0.02], dtype=np.float32). \n",
    "Questo significa che la gaussiana è isotropa con varianza 0.02 su entrambi gli assi, ovvero la covarianza è definibile come:\n",
    "\n",
    "$$\\sum = \\sigma^2I$$ \n",
    "\n",
    "$I$ rappresenta la matrice identità, mentre $\\sigma$ è la varianza scalare.\n",
    "\n",
    "Per quanto riguarda la modellazione dell'ostacolo, l'isotropia della gaussiana implica che la varianza della distribuzione è la stessa su entrambi gli assi. Ciò significa che l'ostacolo è considerato sferico, con la stessa estensione in tutte le direzioni (per tale motivo, successivamente, si fa anche l'assunzione che la visualizzazione degli ostacoli come dei rettangoli sia un mero artificio di visualizzazione, piuttosto che una rappresentazione fidata dell'ostacolo dato il tipo di modellazione scelta). In questo caso la funzione è utilizzata per calcolare la distanza tra il punto (x,y), che rappresenta lo stato attuale del robot, e un generico ostacolo.\n",
    "\n",
    "Riferimento per [l'isotropia della gaussiana](https://magic-with-latents.github.io/latent/posts/ddpms/part2/#:~:text=Isotropic%20Gaussian,-An%20isotropic%20Gaussian&text=(4)%20represents%20a%20diagonal%20matrix,Gaussian%20is%20circular%20or%20spherical)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP0\n",
    "Prima di introdurre ulteriormente il codice, per supporto all'analisi del codice e delle scelte progettuali già fatte all'interno del codice fornito, e quelle compiute dal gruppo, si fa riferimento alla formalizzazione del problema di controllo effettuato nella relazione in allegato al codice del progetto. In particolare si riporta la formula semplificata la per la risoluzione del $\\bold {FOC}$ nel caso in cui la $q_{0:N}$ è uniforme:\n",
    "$${p^{(u)}_{k|k-1}}^* = \\frac{exp(\\mathbb{E_{p_{k+1|k}^{(x)}}}[ln(p_{k+1|k}^{(x)})+ \\overline c_{k}(X_k)])}{\\sum_{u_k}exp(\\mathbb{E_{p_{k+1|k}^{(x)}}}[ln(p_{k+1|k}^{(x)})+ \\overline c_{k}(X_k)])} \\space \\space \\bold{(1)}$$\n",
    "e ci riconduciamo al caso greedy in cui:\n",
    "$$\\overline c_{k}(X_k) = c_k(X_k)$$\n",
    "ovvero il cost-to-go è semplicemente il costo instantaneo.\n",
    "Inoltre indichiamo, per semplicità di notazione\n",
    "$$\\mathbb{E_{p_{k+1|k}^{(x)}}}[ln(p_{k+1|k}^{(x)})] = p_{k+1|k}^{(x)}.entropy()\\space \\space\\bold{(2)}$$\n",
    "e infine:\n",
    "$$\\mathbb{E_{p_{k+1|k}^{(x)}}}[c_{k}(X_k)] \\space \\space \\bold{(3)}$$\n",
    "così da poter meglio esplicitare le scelte progettuali del seguito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW7iQ2FfgPWv"
   },
   "outputs": [],
   "source": [
    "##### WP0: formalize the control problem #####\n",
    "\n",
    "# Task: reverse engineer the cost function used by the robots. What is the problem formulation? \n",
    "#      Is the one below a good cost for the task? Create a heatmap to visualize the cost \n",
    "\n",
    "# TODO: Verificare se ci sono altre situazioni in cui il robot potrebbe non comportarsi in maniera ottimale\n",
    "''' Questa funzione calcola il costo dello stato attuale, passato come parametro, rispetto al goal point e agli ostacoli, anche questi passati come parametri, di conseguenza è una funzione\n",
    "generica che può essere utilizzata per calcolare il costo per qualsiasi enviroment limitato al caso robotarium (in cui lo spazio di task può andare da -1.5 a 1.5 per l'asse x \n",
    "e da -1 a 1 per l'asse y). Il costo è calcolato come somma di tre macro termini, il primo rappresenta la distanza dal goal point:\n",
    "\n",
    "        30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2)\n",
    "\n",
    "Il secondo rappresenta la distanza dagli ostacoli, in particolare è una somma di gaussiane centrate negli ostacoli, la cui struttura è stata ampiamente descritta precedentemente:\n",
    "\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "Il terzo rappresenta la distanza dai bordi dell'ambiente robotarium, in particolare è una somma di quattro gaussiane centrate nei bordi dell'ambiente:\n",
    "\n",
    "        10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "        + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "\n",
    "in questo caso è una gaussiana molto stretta, è serve per evitare che il robot si avvicini troppo ai bordi dell'ambiente, in quanto potrebbe andare fuori dallo spazio di task, ma è un\n",
    "termine che pesa poco rispetto agli altri due, in quanto la gaussiana è molto stretta e quindi il costo è molto basso, se non in estrema prossimità dei bordi dell'ambiente.\n",
    "\n",
    "Il costo fornito racchiude in se stesso alcuni degli elementi chiave del problema di controllo, ovvero:\n",
    "    - il raggiungimento dell'obiettivo\n",
    "    - l'evitamento degli ostacoli\n",
    "    - l'evitamento dei bordi dell'ambiente\n",
    "tutto ciò che è necessario per la risoluzione del problema di controllo. Nonostante ciò, da una breve analisi sui termini del costo, è possibile commentare alcuni aspetti critici:\n",
    "    - da un punto di vista analitico, il contributo massimo che un singolo ostacolo da al costo è 159.15, se il robot si trovasse esattamente sopra l'ostacolo, mentre in un intorno di 0.1 dal centro\n",
    "    dell'ostacolo il contributo è nel range [96.53; 123.95];\n",
    "    - da un punto di vista analitico, il contributo massimo che un bordo da al costo è 199.47, se il robot si trovasse esattamente sul bordo, mentre in un intorno di 0.1 dal bordo, il valore è \n",
    "    estremamente basso, nell'ordine di 10^-5.\n",
    "Queste analisi preliminari evidenziano alcune situazioni in cui il robot potrebbe non comportarsi in maniera ottimale, in particolare:\n",
    "    - se l'ostacolo è molto vicino al goal point, il robot potrebbe non raggiungere mai il goal point, in quanto nell'intorno dell'ostacolo il costo è comunque alto, \n",
    "    il che può portare il robot a scegliere di non avvicinarsi all'ostacolo e di conseguenza al goal point;\n",
    "    - se uno o più ostacoli sono posti nei pressi delle pareti del robotarium, e il robot è posizionato tra le pareti e gli ostacoli, il robot potrebbe decidere di non avvicinarsi agli ostacoli,\n",
    "    ma piuttosto di avvicinarsi alle pareti, in quanto il costo è più basso, e di conseguenza potrebbe rimanere intrappolato tra ostacoli e pareti o addirittura andare fuori dall'ambiente descritto\n",
    "    dal robotarium;\n",
    "    - ALTRO?\n",
    "\n",
    "Infine, è evidenziabile anche un comportamento indesiderato del robot, non dovuto in questo caso al valore specifico dei coefficienti del costo, ovvero:\n",
    "- potrebbe capitare che, a causa dell'allineamento del robot rispetto al goal point, in caso di presenza di ostacolo tra il robot e il goal point, il robot continui a militare nell'\n",
    "intorno dell'ostacolo poichè il costo assume valori simili in entrambe le direzioni ortogonali all'asse di congiunzione, e il robot potrebbe continuare a scegliere direzioni opposte in passi\n",
    "successivi dell'algoritmo, senza mai superare l'ostacolo. \n",
    "\n",
    "Date queste considerazioni, è possibile affermare che il costo fornito, potrebbe essere migliorato, in particolare, verrà proposto un nuovo costo in seguito, come richiesto da work package\n",
    "successivi nel progetto'''\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar) # Questo dipende dalle gaussiane mediate negli ostacoli,\n",
    "        # come se avessimo che più ci avviciniamo all'ostacolo più aumenti il posto\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP1: fill-in the code for the function below.\n",
    "#         The function needs to return the optimal action sampled from the optimal policy.\n",
    "#         The action is used in the simulation loop #####\n",
    "\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "\n",
    "                '''\n",
    "                Il calcolo della policy descritta nel markdown (1) è valutata per ogni possibile azione, e per questo motivo, è necessario ciclare su tutte le possibili azioni, che in questo caso sono le possibili\n",
    "                combinazioni di velocità lungo l'asse x e lungo l'asse y, 9 in totale.\n",
    "                '''\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                # TODO: Da controllare il commento sotto\n",
    "                '''\n",
    "                Queste tre righe di codice servono per modellare i sensori rumorosi del sistema, in particolare, la funzione model_step calcola il prossimo stato del robot a cui viene iniettato del rumore gaussiano\n",
    "                con media nulla e covarianza 0.001 sulla x e 0.001 sulla y. Inoltre, il rumore gaussiano è necessario per la risoluzione del problema di controllo, in quanto, se non fosse presente, il robot potrebbe rimanere\n",
    "                intrappolato in un minimo locale del costo, in quanto il costo è una funzione continua e derivabile, e quindi potrebbe capitare che il robot non riesca a raggiungere il goal point. \n",
    "                '''\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                \n",
    "                '''\n",
    "                Queste due righe di codice servono per campionare la gaussiana dello stato, in modo da ottenere un numero di campioni pari a N_samples (in questo caso pari a 20), che rappresentano i possibili stati\n",
    "                successivi del robot. In particolare, la funzione rvs(N_samples) campiona la gaussiana N_samples volte, e restituisce un array di dimensione N_samples*2, in cui ogni riga rappresenta un campione.\n",
    "                '''\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost(next_sample[k,:],goal_points,obs_points)/N_samples\n",
    "                '''\n",
    "                Queste tre righe invece, servono a computare il costo dello stato successivo, espresso come valore atteso, indicato nella formula (1) nel markdown nella cella precedente. In particolare, il costo\n",
    "                viene calcolato come somma dei costi di ogni campione, diviso il numero di campioni, andando ad ottene il valore atteso del costo.\n",
    "                '''\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())\n",
    "                '''\n",
    "                Come descritto nel markdown, la policy è ottenibile dalla formula (1), in particolare abbiamo al numeratore l'esponenziale della somma di due termini: il valore atteso del costo (3) e l'entropia della policy (2)\n",
    "                '''\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        \n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "\n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        '''\n",
    "        La policy ottima sarà di dimensione 3x3, in quanto abbiamo discretizzato lo spazio di controllo su 3 possibili valori per ogni asse, in cui ogni elemento rappresenta la probabilità di scegliere quell'azione.\n",
    "        Con il metodo flatten() è possibile trasformare la matrice in un array monodimensionale, in cui ogni elemento rappresenta la probabilità di scegliere l'azione corrispondente all'indice dell'elemento nell'array.\n",
    "        '''\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        \n",
    "        '''\n",
    "        Riprendendo ancora una volta la formula (3) nel markdown, al denominatore abbiamo la normalizzazione della policy, quindi la policy ottima, da cui campionare l'azione, è ottenuta come il rapporto tra il numeratore\n",
    "        calcolato precedentemente e il normalizzatore della stessa.\n",
    "        '''\n",
    "\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        '''\n",
    "        Infine, a partire dall'indice campionato, è possibile ottenere l'azione ottima corrispondente.\n",
    "        '''\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Questa funzione, richiesta dal WP1, serve per visualizzare il costo dello stato in funzione della posizione del robot, discretizzata come una griglia 100 x 100, dagli ostacoli e dal goal point\n",
    "'''\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_heatmap(goal_points,obs_points):\n",
    "    plt.figure(figsize=(9,6))\n",
    "    x_min = -1.6\n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min,x_max,100)\n",
    "    y_range = np.linspace(y_min,y_max,100)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    Z = np.zeros((100,100))\n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            Z[i,j] = state_cost(np.array([X[i,j],Y[i,j]]),goal_points,obs_points)\n",
    "    plt.pcolormesh(X,Y,Z)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(goal_points[0],goal_points[1],c='r')\n",
    "    plt.scatter(obs_points[0,:],obs_points[1,:],c='k')\n",
    "    plt.title('Cost function')\n",
    "\n",
    "    # Add labels to the axes\n",
    "    plt.xlabel('X [m]')\n",
    "    plt.ylabel('Y [m]')\n",
    "    \n",
    "    # Add a rectangle for the border of the arena\n",
    "    arena_border = patches.Rectangle((-1.5, -1), 1.5-(-1.5), 1-(-1), linewidth=1, edgecolor='black', facecolor='none')\n",
    "    plt.gca().add_patch(arena_border)\n",
    "    \n",
    "    # Add squares for each obstacle\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        obstacle_square = patches.Rectangle((obs_points[0,i]-0.175, obs_points[1,i]-0.175), 0.35, 0.35, linewidth=1, edgecolor='b', facecolor='none',alpha=0.5)\n",
    "        obstacle_square2 = patches.Rectangle((obs_points[0,i]-0.225, obs_points[1,i]-0.225), 0.45, 0.45, linewidth=1, edgecolor='r', facecolor='none',alpha=0.5)\n",
    "\n",
    "        plt.gca().add_patch(obstacle_square)\n",
    "        plt.gca().add_patch(obstacle_square2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    '''\n",
    "    Notare che la dimensione dell'ostacolo è stata ottenuta da un esperimento dal vivo sul robotarium, il significato dei rettangoli rossi e blu è stato enunciato nel WP5, invitiamo pertanto\n",
    "    a scendere alla cella [#TODO INSERIRE NUMERO CELLA], per ulteriori spiegazioni.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "'''\n",
    "Il plot della heatmap è stato effettuato anche in 3D, e analogamente al caso precedentemente, per la spiegazione dettagliata si rimanda al WP5.\n",
    "'''\n",
    "def plot_3d_heatmap(goal_points, obs_points): \n",
    "    x_min = -1.6 \n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min, x_max, 100) \n",
    "    y_range = np.linspace(y_min, y_max, 100) \n",
    "    X, Y = np.meshgrid(x_range, y_range) \n",
    "    Z = np.zeros((100, 100)) \n",
    "    for i in range(100): \n",
    "        for j in range(100): \n",
    "            Z[i, j] = state_cost(np.array([X[i, j], Y[i, j]]), goal_points, obs_points) \n",
    "    fig = plt.figure(figsize=(15,10)) \n",
    "    ax = fig.add_subplot(111, projection='3d') \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7)  # Update alpha value here \n",
    "    ax.set_xlabel('X') \n",
    "    ax.set_ylabel('Y') \n",
    "    ax.set_zlabel('Cost') \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point') \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here \n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.175, obs_points[0, i] - 0.175, obs_points[0, i] + 0.175, obs_points[0, i] + 0.175, obs_points[0, i] - 0.175]\n",
    "        square_y = [obs_points[1, i] - 0.175, obs_points[1, i] + 0.175, obs_points[1, i] + 0.175, obs_points[1, i] - 0.175, obs_points[1, i] - 0.175]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "       # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.275, obs_points[0, i] - 0.275, obs_points[0, i] + 0.275, obs_points[0, i] + 0.275, obs_points[0, i] - 0.275]\n",
    "        square_y_large = [obs_points[1, i] - 0.275, obs_points[1, i] + 0.275, obs_points[1, i] + 0.275, obs_points[1, i] - 0.275, obs_points[1, i] - 0.275]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    \n",
    "    ax.legend() \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wy2b_CxogPWy"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In questa cella viene inizializzato l'enviroment del task di controllo, in particolar modo gli ostacoli e il goal point. \n",
    "In seguito viene chiamata la funzione plot_heatmap per visualizzare il costo dello stato per questo particolare\n",
    "enviroment, che verrà commentato nella relazione allegata al progetto.\n",
    "'''\n",
    "\n",
    "# Define goal and obstacle points\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) # Da traccia\n",
    "# goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "# Plot the heatmap of the cost function\n",
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points, obs_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WP2: Simulate (4 experiments) and visualize each robot's trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WsfTaVW4gPW0",
    "outputId": "40848e0e-6a4c-4ddc-b80e-b576acbbff2b"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In questa cella viene effettuata la simulazione del robot, in particolare, per un singolo robot, vengono effettuati 4 esperimenti, in cui il robot parte da 4 posizioni diverse. \n",
    "Nello specifico, è stato fornito un set di condizioni iniziali di esempio, che sono state utilizzate per effettuare la simulazione.\n",
    "Innanzitutto viene inizializzato l'enviroment robotarium e creato il mapping tra il sistema unicycle del robot e il sistema single integrator. Tralasciamo la descrizione del modello unicycle, ampiamente descritta\n",
    "nella documentazione del robotarium, e ci concentriamo sul modello single integrator, che è quello che interessa per la simulazione, non è necessario conoscerlo per la risoluzione del problema di controllo. Successivamente\n",
    "viene effettuato un esperimento alla volta, il quale prevede:\n",
    "- il recupero della posa del robot a cui viene iniettato del rumore per simulare gli eventuali errori di misura del sensore di posizione del robot;\n",
    "- viene effettuato il passo di controllo attraverso la funzione Control_step che restituirà l'azione ottima come descritto in precedenza;\n",
    "- viene effettuata la conversione dell'azione ottima in velocità del robot, attraverso la funzione si_to_uni_dyn;\n",
    "- vengono assegnate le velocità al robot;\n",
    "- viene effettuato il passo di simulazione.\n",
    "'''\n",
    "\n",
    "# Instantiate Robotarium object\n",
    "N = 1 #Amount of robots per simulation\n",
    "# Initial conditions of the robot for 4 experiments\n",
    "initial_conditions = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))] #Initial pose of the robots\n",
    "N_experiment = 4\n",
    "# X_si is going to be two-dimensional state history\n",
    "X_Si = [0]*N_experiment\n",
    "# D_Xi is going to be two-dimensional inputs history\n",
    "D_Xi = [0]*N_experiment\n",
    "\n",
    "# This first for loop creates the initial conditions\n",
    "for I in range(N_experiment):\n",
    "\n",
    "    X_si = []\n",
    "    D_xi = []\n",
    "\n",
    "    r = robotarium.Robotarium(number_of_robots=N, show_figure=True, initial_conditions=initial_conditions[I], sim_in_real_time=False)\n",
    "\n",
    "    # Create mapping from the control inputs to the actual velocity commands to the unicycle\n",
    "    # Note: this is a very practical situation (robots often provide transformation functions to low level commands)\n",
    "    si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion() #Converts single integrator inputs to unicycle inputs (low-level controller)\n",
    "    _, uni_to_si_states = create_si_to_uni_mapping()\n",
    "    \n",
    "    # define x initially\n",
    "    x = r.get_poses()\n",
    "    x_si = uni_to_si_states(x)\n",
    "\n",
    "    # Plotting Parameters\n",
    "    CM = np.random.rand(N+10,3) # Random Colors\n",
    "    goal_marker_size_m = 0.15\n",
    "    obs_marker_size_m = 0.15\n",
    "    marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "    marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "    font_size = determine_font_size(r,0.1)\n",
    "    line_width = 5\n",
    "\n",
    "    # Create Goal Point Markers\n",
    "    #Text with goal identification\n",
    "    goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "    #Plot text for caption\n",
    "    goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "    goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "\n",
    "    #Text with goal identification\n",
    "    obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "    #Plot text for caption\n",
    "    obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "    obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "\n",
    "    r.step()\n",
    "\n",
    "    # While the robot is away from the objective ...\n",
    "    while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N):\n",
    "\n",
    "        # Get poses of agents\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        #Add to the dataset\n",
    "        X_si.append(x_si)\n",
    "\n",
    "        # The lines below define the pdf of the robot \n",
    "        cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "        x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "        x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "        # This is about plotting\n",
    "        for j in range(goal_points.shape[1]):\n",
    "            goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "        for j in range(obs_points.shape[1]):\n",
    "            obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "        # Task: compute the action from the policy. Call the variable dxi: \n",
    "        # this is the action sampled from the optimal solution to the control problem\n",
    "        dxi = Control_step(x_sample,U_space_1,U_space_2,goal_points,obs_points) \n",
    "\n",
    "        D_xi.append(dxi)\n",
    "\n",
    "        # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "        dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "        # Set the velocities inputs\n",
    "        r.set_velocities(np.arange(N), dxu)\n",
    "        # Iterate the simulation\n",
    "        r.step()\n",
    "\n",
    "    D_Xi[I] = D_xi\n",
    "    X_Si[I] = X_si\n",
    "    \n",
    "    #Call at end of script to print debug information and for your script to run on the Robotarium server properly\n",
    "    r.call_at_scripts_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ass2XqjRgPW3"
   },
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyRxll4KgPW5"
   },
   "outputs": [],
   "source": [
    "#Prepare data for plotting\n",
    "X = []\n",
    "X_plot = []\n",
    "U = []\n",
    "U_plot = []\n",
    "\n",
    "for i in range(len(XX)):\n",
    "    X.append(np.array(XX[i]))\n",
    "    X_plot.append(np.array(XX[i]))\n",
    "\n",
    "X = np.concatenate(X, axis=0)\n",
    "X = np.reshape(X, (-1, 2))\n",
    "\n",
    "U = []\n",
    "for i in range(len(UU)):\n",
    "    U.append(np.array(UU[i]))\n",
    "    U_plot.append(np.array(UU[i]))\n",
    "\n",
    "U = np.concatenate(U, axis=0)\n",
    "U = np.reshape(U, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "PqEl3OXpgPW_",
    "outputId": "a710f7af-4b2e-486e-908b-063e24924946"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "\n",
    "#Task: plot trajectories with different colors\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "for i in range(len(X_plot)):\n",
    "    plt.plot(X_plot[i][:, 0], X_plot[i][:, 1], label=f'Traiettoria {i+1}')\n",
    "    plt.plot(X_plot[i][0, 0],X_plot[i][0, 1],'*',color='black',markersize=10)\n",
    "\n",
    "'''\n",
    "Le linee di codice precedenti servono per visualizzare le traiettorie dei robot, in particolare, per ogni esperimento viene visualizzata la traiettoria del robot, mappandola con un diverso colore aggiungendo\n",
    "un marker alla posizione iniziale del robot.\n",
    "\n",
    "NOTA: nelle successive linee di codice, vengono plottati i goal point e gli ostacoli, ma non rappresentano in maniera fedele la realtà, in quanto sono stati plottati in un ambiente 2D e rappresentati come rettangoli, mentre,\n",
    "come già discusso in precedenza, gli ostacoli dovrebbero essere rappresentati più come delle sfere, a causa della natura gaussiana multivariata che rappresenta la distanza.\n",
    "'''\n",
    "#Draw obstacles\n",
    "square1 = plt.Rectangle((-1.6,-1), 0.4, 0.4, fc='green',ec=\"black\")\n",
    "square3 = plt.Rectangle((-0.2,-1), 0.4, 0.4, fc='red',ec=\"black\")\n",
    "square2 = plt.Rectangle((-0.2,0), 0.4, 0.8, fc='red',ec=\"black\")\n",
    "plt.gca().add_patch(square2)\n",
    "plt.gca().add_patch(square1)\n",
    "plt.gca().add_patch(square3)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "plt.savefig('C:/Users/giova/Desktop/ProjectDDC/Progetto/Training_Trajectories.jpg',dpi=1000,bbox_inches ='tight')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP3: Reverse engineer the features and visualize them #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjLf-AbTgPXB"
   },
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XXOIr-DgPXD"
   },
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2))\n",
    "\n",
    "    return features\n",
    "\n",
    "'''\n",
    "Le feature proposte dal docente sono 16, la prima rappresenta la distanza rispetto al goal point, mentre le altre 15 rappresentano la distanza rispetto a dei punti fissi, che sono posizionati in maniera tale da\n",
    "ricoprire l'intero spazio di task. Questo set di feature, mappa in maniera fedele il costo dello stato relativo alla distanza dal goal point e dagli ostacoli, infatti ogni punto di feature è posizionato in un punto\n",
    "dell'ambiente e, in base al relativo peso, esso rappresentarà la distanza da eventuali ostacoli presenti in quell'area dell'ambiente.\n",
    "Data la natura del set di feature proposto, una prima analisi critica mette alla luce qualche problema: il numero di punti della griglia robotarium di riferimento sono in numero limitato. \n",
    "Questa \"discretizzazione\" della griglia potrebbe portare a una perdita di informazione, in quanto non è detto che è possibile ricavare tutte le informazioni riguardanti il costo dello stato a causa del numero ridotto di simulazioni,\n",
    "e queste, anche se aumentassero in numero, potrebbero non coprire tutte le casistiche possibili. Per tale motivo una prima analisi critica porterebbe all'aumento del numero di punti della griglia robotarium, in modo da avere più informazioni\n",
    "riguardo il costo dello stato, e quindi avere una migliore approssimazione del costo dello stato. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAi2q4NvgPXE"
   },
   "outputs": [],
   "source": [
    "##### WP4: using the previously defined features solve the inverse optimal control problem. \n",
    "#          Plot the estimated cost. \n",
    "#          Verify that the estimated cost allows the robot to complete the task #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di introdurre ulteriormente il codice, per supporto all'analisi dello stesso e delle scelte progettuali già fatte all'interno del codice fornito, e quelle compiute dal gruppo, si fa riferimento alla formalizzazione del problema di controllo inverso effettuato nella relazione in allegato al codice del progetto. In particolare, si riporta la formula semplificata la per la risoluzione dell'$\\bold {IOC}$ nel caso in cui la $q_{0:N}$ è uniforme:\n",
    "$$argmin_w\\{\\sum^M_{k=1}(\\mathbb{E_{p(x_k|\\hat x_{k-1},\\hat u_k)}}[w_k^Th(x_k)]+ln(\\sum_{u_k}exp(\\mathbb{E_{p(x_k|\\hat x_{k-1},u_k)}}[-ln(p(x_k|\\hat x_{k-1},u_k))+w_k^Th(x_k)])))\\} \\space \\space \\bold{(4)}$$\n",
    "\n",
    "Inoltre indichiamo, per semplicità di notazione\n",
    "$$exp(\\mathbb{E_{p(x_k|\\hat x_{k-1},u_k)}}[-ln(p(x_k|\\hat x_{k-1},u_k))]) = -p(x_k|\\hat x_{k-1},u_k).entropy()\\space \\space\\bold{(5)}$$\n",
    "e infine:\n",
    "$$\\mathbb{E_{p(x_k|\\hat x_{k-1},u_k)}}[w_k^Th(x_k)] \\space \\space \\bold{(6)}$$\n",
    "così da poter meglio esplicitare le scelte progettuali del seguito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7shmt6xgPXF"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1\n",
    "w = cp.Variable((1,N_feature))\n",
    "constraints = [w >= 0]\n",
    "R = np.zeros((99,1))\n",
    "L = []\n",
    "\n",
    "f_expect = np.zeros((2,20))\n",
    "feature_sampled = np.zeros((N_feature,M))\n",
    "PF = np.zeros((control_space_size,control_space_size,M))\n",
    "\n",
    "for i in range(M):\n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size))\n",
    "    state = np.array(X[i,:]) #Get the state\n",
    "\n",
    "    x0 = state.reshape(-1,1)\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            next_sample = f.mean\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples)\n",
    "            feature_sample = np.zeros((N_feature,N_samples))\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1)\n",
    "\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy()))\n",
    "            '''\n",
    "            Questo riga rappresenta il termine (5) descritto nel markdown, in particolare rappresenta l'esponenziale dell'entropia cambiata di segno.\n",
    "            '''\n",
    "\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # N features x 9\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step)\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov)\n",
    "    next_samples_f1 = f1.rvs(N_samples)\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    tempPF = np.reshape(PF,(control_space_size**2,M)) # N features x 9\n",
    "\n",
    "    l =-(w @ feature_sampled[:,i])+cp.log_sum_exp(cp.reshape(w@features[:,:],(9,))+cp.log(tempPF[:,i]))\n",
    "    \n",
    "    '''\n",
    "    Ogni termine l, rappresenta il singolo termine della sommatoria (4) descritta nel markdown, in particolare, dato che il codice pre-esistente già calcolava il termine (5) e il termine (6), lo scopo di questa parte di codice\n",
    "    è quello di configurare le dimensionalità dei vari termini, effettuando un reshape della PF calcolata, portandola da una dimensionalità (N feature x 3 x 3), a una dimensionalità (N x 9) per essere gestita nella somma con il prodotto dei pesi con le features.\n",
    "    Inoltre, dato che stiamo risolvendo un problema di LSE tramite cvx, dobbiamo fornirgli in input il valore atteso del prodotto tra pesi e feature, e il valore atteso della f cambiata di segno, rappresentato dall'entropia,\n",
    "    ma dato che ci viene già fornito dal codice l'esponenziale dell'entropia, cambiata di segno, dobbiamo sommare il logaritmo di questa quantità in modo da riportarci nella forma originale del problema (4).\n",
    "    '''\n",
    "    \n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    L.append(l)\n",
    "\n",
    "    '''\n",
    "    Con queste linee di codice creiamo l'intera sommatoria su M esperimenti.\n",
    "    '''\n",
    "\n",
    "    # (iii) solve the problem \n",
    "objective = cp.Minimize(cp.sum(L))\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = False)\n",
    "\n",
    "'''\n",
    "Infine risolviamo il problema, facendo uso di cvx, minimizzando la sommatoria dei termini l, ottenendo i pesi w ottimi delle feature scelte.\n",
    "'''\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EY1orFxPgPXH",
    "outputId": "24a7b313-560d-4e31-d3f1-49d9a25a0543"
   },
   "outputs": [],
   "source": [
    "# Show the values: critically discuss if these weights make sense\n",
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)\n",
    "\n",
    "''' \n",
    "A termine dell'ottimizazzione vengono visualizzati i pesi calcolati dal problema. In questo caso particolare notiamo che i pesi relativi al mapping dello spazio assumono valori più alti, in segno negativo, più vicini sono\n",
    "agli ostacoli. Ovviamente questo ha senso, poichè il costo, è combinazione lineare di queste feature cambiate di segno e pesate per i relativi pesi, e riesce a rappresentare in maniera fedele il costo dello stato, \n",
    "poichè è più alto in vicinanza dei punti in cui sono concentrati più ostacoli. Inoltre anche il peso della feature che mappa la distanza dal goal point è negativo e di modulo alto, \n",
    "e questo ha senso in quanto il costo dello stato è tanto più alto quanto più il robot è lontano dal goal point.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QgxBdrNgPXI",
    "outputId": "699171d0-3d2f-4195-af1c-fdbe5032e7af"
   },
   "outputs": [],
   "source": [
    "# Check the status of the optimization problem: did the optimization go well?\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)\n",
    "\n",
    "'''\n",
    "Come descritto anche in precedenza, l'ottimizzazione è andata a buon fine e il valore dei pesi calcolati è ragionevole in relazione allo specifico task attuato.\n",
    "Il fatto che lo status sia optimal indica che l'ottmizzazione ha raggiunto con successo la soluzione ottimale, trovando il miglior valore possibile rispetto alla funzione obiettivo.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Xs5LG7IgPXJ"
   },
   "outputs": [],
   "source": [
    "# Reformatting the original cost map (just for checking and plotting purposes)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "#obs_points = np.array(np.mat('0 0 0 0 0 0;0 0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0 0'))\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost(state,goal_points,obs_points)\n",
    "\n",
    "Coat_Map = pd.DataFrame(Cost_Map,index=list(X_axis),columns=Y_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXBeF23UgPXL"
   },
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "I7poUkevgPXM",
    "outputId": "e4e9bc4c-b6a7-422e-a08b-0fa3a0652535"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transpose the data array to rotate the heatmap\n",
    "#data_rotated = np.transpose(Coat_Map) Costo effettivo\n",
    "data_rotated = np.transpose(Cost_Map)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting the pcolormesh for the data\n",
    "plt.pcolormesh(X_axis, Y_axis, data_rotated, cmap='viridis', alpha=0.92)\n",
    "plt.colorbar()\n",
    "\n",
    "# Define contour levels to create 6 regions\n",
    "contour_levels = np.linspace(data_rotated.min(), data_rotated.max(), 7)  # 7 levels for 6 regions\n",
    "\n",
    "# Get colors based on the viridis colormap for the given contour levels\n",
    "viridis_colors = plt.cm.viridis(np.linspace(0, 1, len(contour_levels)))\n",
    "\n",
    "for i, level in enumerate(contour_levels):\n",
    "    plt.contour(X_axis, Y_axis, data_rotated, levels=[level], colors=[viridis_colors[i]], linewidths=2.5, linestyles='dashed')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "In questo pezzo di codice viene visualizzato il costo dello stato calcolato con i pesi ottenuti dall'ottimizzazione, ovvero il costo stimato. In particolare, è rappresentato come una heatmap analogamente a quanto accaduto\n",
    "per il costo definito nel problema di FOC. Inoltre, sono state anche disegnate delle linee tratteggiate che rappresentano i livelli di costo.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIo_AnGpgPXT"
   },
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "\n",
    "'''\n",
    "La funzione ha la sintassi e il significato analogo a quella definita per il problema di FOC, con la sola differenza che il costo dello stato viene calcolato con i pesi ottenuti dall'ottimizzazione,\n",
    "e quindi il costo è quello stimato dal problema IOC.\n",
    "'''\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                # Queste tre linee di codice calcolano il prossimo stato, a partire da una delle 9 azioni scandite\n",
    "                # dai cicli for, e creano una multivariata normale centrata nel prossimo stato con covarianza data\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                # Queste due linee di codice campionano 20 campioni dalla distribuzione calcolata precedentemente\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                # Calcoliamo il costo medio dei campioni secondo la funzione state_cost, si tratta di calcolare\n",
    "                # l'expected value della formula per la policy\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "                # print(\"entropy: \" + str(f.entropy()))\n",
    "                # print(\"next state: \" + str(next_state))\n",
    "                # print(\"cost: \" + str(cost))\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())\n",
    "\n",
    "                # la log_DKL è uguale, secondo formulazione, a np.exp(-DKL-costoatteso), il costo atteso lo abbiamo calcolato\n",
    "                # al punto precedente, mentre la DKL(f||g), dato che g è uniforme, diventa semplicemente l'entropia con un termine \n",
    "                # log(q) derivante da calcoli algebrici\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "\n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uLNguEgFgPXU",
    "outputId": "24679b38-d525-492f-e678-8799b8a28ff6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Anche questo pezzo di codice, come in precedenza, è analogo a quello scritto per il problema di FOC, con la sola differenza che viene utilizzata la policy con il costo stimato, e non quello definito nel problema di FOC.\n",
    "Il codice è esattamente lo stesso, ma viene effettuata una chiamata alla funzione Control_step con i parametri aggiornati, ovvero il costo stimato e non quello definito nel problema di FOC.\n",
    "'''\n",
    "# Instantiate Robotarium object (start the robots from different initial conditions than the 4 experiments above)\n",
    "N = 1\n",
    "initial_conditions = [np.array(np.mat('-1.4;0.9; 0')),np.array(np.mat('1;0.9; 0')),np.array(np.mat('1;-0.25; 0'))]\n",
    "N_experiment = 3\n",
    "# Definitions as above...\n",
    "X_Si = [0]*N_experiment\n",
    "D_Xi = [0]*N_experiment\n",
    "\n",
    "for I in range(N_experiment):\n",
    "\n",
    "    X_si = []\n",
    "    D_xi = []\n",
    "\n",
    "    r = robotarium.Robotarium(number_of_robots=N, show_figure=True, initial_conditions=initial_conditions[I], sim_in_real_time=False)\n",
    "\n",
    "    si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion()\n",
    "\n",
    "    x = r.get_poses()\n",
    "    x_si = uni_to_si_states(x)\n",
    "\n",
    "    CM = np.random.rand(N+10,3) \n",
    "    goal_marker_size_m = 0.15\n",
    "    obs_marker_size_m = 0.15\n",
    "    marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "    marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "    font_size = determine_font_size(r,0.1)\n",
    "    line_width = 5\n",
    "\n",
    "    goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "    goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "    goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "\n",
    "    obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "    obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "    obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "\n",
    "    r.step()\n",
    "    # Task: re-implement the simulation loop this time using the policy with the estimated cost\n",
    "    while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N):\n",
    "\n",
    "        \n",
    "        # Get poses of agents\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        #Add to the dataset\n",
    "        X_si.append(x_si)\n",
    "\n",
    "        # The lines below define the pdf of the robot \n",
    "        cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "        x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "        x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "        # This is about plotting\n",
    "        for j in range(goal_points.shape[1]):\n",
    "            goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "        for j in range(obs_points.shape[1]):\n",
    "            obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "        # Task: compute the action from the policy. Call the variable dxi: \n",
    "        # this is the action sampled from the optimal solution to the control problem\n",
    "        dxi = Control_step(x_sample,U_space_1,U_space_2,goal_points,obs_points) \n",
    "\n",
    "        D_xi.append(dxi)\n",
    "\n",
    "        # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "        dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "        # Set the velocities inputs\n",
    "        r.set_velocities(np.arange(N), dxu)\n",
    "        # Iterate the simulation\n",
    "        r.step()\n",
    "\n",
    "    D_Xi[I] = D_xi\n",
    "    X_Si[I] = X_si\n",
    "\n",
    "    r.call_at_scripts_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2gUBs9HgPXW"
   },
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zc26PNAzgPXX"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "X_plot = []\n",
    "U = []\n",
    "U_plot = []\n",
    "\n",
    "for i in range(len(XX)):\n",
    "    X.append(np.array(XX[i]))\n",
    "    X_plot.append(np.array(XX[i]))\n",
    "\n",
    "X = np.concatenate(X, axis=0)\n",
    "X = np.reshape(X, (-1, 2))\n",
    "\n",
    "U = []\n",
    "for i in range(len(UU)):\n",
    "    U.append(np.array(UU[i]))\n",
    "    U_plot.append(np.array(UU[i]))\n",
    "\n",
    "U = np.concatenate(U, axis=0)\n",
    "U = np.reshape(U, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Sq2vsBLMgPXY",
    "outputId": "c6e65995-63e3-47ac-fb97-7d930abc5887"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Infine, ancora una volta come nel FOC, plottiamo i risultati degli esperimenti. Effettivamente, per le condizioni iniziali scelte da traccia, il robot riesce a raggiungere il goal point,\n",
    "ma non è detto che questo accada sempre, infatti se si cambiano le condizioni iniziali, il robot potrebbe non raggiungere il goal point, e alcuni casi di ciò sono riportati nella relazione allegata al progetto.\n",
    "Proprio per tale motivo si è deciso di modellare una nuova funzione di costo e un nuovo set di feature, così come richiesto dal work package.\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "\n",
    "# Task: Plot robot trajectories (when the policy uses the reconstructed cost)\n",
    "plt.figure()\n",
    "\n",
    "for i in range(len(X_plot)):\n",
    "    plt.plot(X_plot[i][:, 0], X_plot[i][:, 1], label=f'Traiettoria {i+1}')\n",
    "    plt.plot(X_plot[i][0, 0],X_plot[i][0, 1],'*',color='black',markersize=10)\n",
    "\n",
    "\n",
    "#Draw obstacles\n",
    "square1 = plt.Rectangle((-1.6,-1), 0.4, 0.4, fc='green',ec=\"black\")\n",
    "square3 = plt.Rectangle((-0.2,-1), 0.4, 0.4, fc='red',ec=\"black\")\n",
    "square2 = plt.Rectangle((-0.2,0), 0.4, 0.8, fc='red',ec=\"black\")\n",
    "plt.gca().add_patch(square2)\n",
    "plt.gca().add_patch(square1)\n",
    "plt.gca().add_patch(square3)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "Xgg5hhMogPXQ",
    "outputId": "b8c54575-1e46-441a-991d-9561ed668256"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Infine, prima di passare alla modellazione di una nuova funzione di costo e di un nuovo set di feature, viene visualizzato il set di feature utilizzato per il problema di IOC.\n",
    "In particolare, i punti caratteristici sono rappresentati come dei cerchi rossi, e la dimensione del cerchio è proporzionale al peso associato alla feature, in particolare, più il peso è alto, più il cerchio sarà grande. \n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supponendo che 'obs_points_f' e 'weights' siano definiti\n",
    "\n",
    "# Plot dei punti caratteristici sulla griglia\n",
    "plt.figure(figsize=(8, 6))\n",
    "newWeights=-weights[0][1:]# Normalizza i pesi nell'intervallo 100-1000\n",
    "weights_normalized = (newWeights - newWeights.min()) / (newWeights.max() - newWeights.min())\n",
    "weights_mapped = 100 + (weights_normalized * 900)  # Scala il valore tra 100 e 1000\n",
    "\n",
    "# Plot dei punti caratteristici con dimensioni basate sui pesi\n",
    "plt.scatter(obs_points_f[0], obs_points_f[1], s=weights_mapped, c='red', marker='o')\n",
    "\n",
    "# Plot del testo con i pesi corrispondenti\n",
    "for i in range(len(newWeights)):\n",
    "    plt.text(obs_points_f[0, i], obs_points_f[1, i]-0.15, f'{-newWeights[i]:.2f}', fontsize=8, color='black')\n",
    "\n",
    "plt.xlabel('Asse X')\n",
    "plt.ylabel('Asse Y')\n",
    "plt.title('Punti caratteristici sulla griglia del Robotarium con pesi')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment the results you observe in the figure generated by the above cell\n",
    "\n",
    "'''\n",
    "Come enunciato già in precedenza, alla visualizzazione non grafica, ma analitica dei pesi, notiamo che i pesi relativi al mapping dello spazio assumono valori più alti, in segno negativo, più vicini sono\n",
    "agli ostacoli. Ovviamente questo ha senso, poichè il costo, combinazione lineare di queste feature, riesce a rappresentare in maniera fedele il costo dello stato, poichè è più alto in vicinanza dei punti in cui sono concentrati\n",
    "più ostacoli. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prima di proporre un nuovo costo e nuove feature, ci siamo interessati a comprendere a pieno l'environment robotarium e le sue caratteristiche, in particolare, ci siamo interessati a capire la dimensione\n",
    "dell'ostacolo che viene effettivamente inserito come parametro del robotarium. Dopo aver fatto vari test, abbiamo notato che l'ostacolo viene rappresentato come un rettangolo di dimensioni 0.35x0.35m, e questo\n",
    "vale anche per la zona di goal point, siamo riusciti a comprenderlo grazie a varie simulazioni di test inviate alla piattaforma online del robotarium, ciò che ci ha fatto capire quale fosse la dimensione dell'ostacolo\n",
    "è la seguente simulazione, effettuata con ostacoli distanti 0.35 fra di loro:\n",
    "https://robotzoo-video.ecs.gatech.edu/owncloud/index.php/s/bUUjobOimI5ftYC\n",
    "'''\n",
    "\n",
    "obs_points = np.array(np.mat('0 ;0 ;0 ')) # da traccia\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "   \n",
    "\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) # Questo dipende dalle gaussiane mediate negli ostacoli,\n",
    "    \n",
    "    return(gauss_sum)\n",
    "\n",
    "'''\n",
    "Avendo compreso la dimensione dell'ostacolo, abbiamo deciso di modellare nuovamente il termine gaussiano, in modo da avere una rappresentazione più fedele della realtà, in particolare, abbiamo deciso di rappresentarlo\n",
    "con una varianza minore, manetenendo più o meno lo stesso valore di costo nel picco. Si fa notare come questo valore della varianza non crei semplicemente una gaussiana che assume valori all'interno dell'ostacolo, ma ha anche valori\n",
    "in un intorno dell'ostacolo. Questo è dovuto all'\"hand-position problem\", o almeno questo è il nome che gli abbiamo attribuito. In particolare questo problema, deriva dalla rappresentazione del robot, la cui posa recuperata dall'environment\n",
    "è quella della sua hand position, che si trova a 0.05m dal centro del robot, che a sua volta è lungo all'incirca 0.10/0.11m. Dato ciò, e dato che il robot può comunque muoversi in retromarcia, potrebbe capitare che se la gaussiana\n",
    "non è molto ampia, il robot prima di accorgersi che il costo si sta alzando, comunque sbatte con il retro del suo corpo verso l'ostacolo. Grazie all'aiuto del plot, è possibile vedere come abbiamo modellato l'effettivo ostacolo\n",
    "come un rettangolo blu, mentre la posizione \"safe\" di hand-position in rosso. In questo modo il robot non tenderà di avvicinarsi neanche a questa safe position, e se lo farà in retromarcia comunque arriverà al massimo vicino all'ostacolo\n",
    "senza mai toccarlo effettivamente. Ragionamenti analoghi possono essere portati avanti per i limiti fisici del robotarium, noi vogliamo che anche se il robot arriva in retromarcia lungo i bordi non tocchi mai effettivamente i bordi\n",
    "per tale motivo, nell'avanzare del miglioramento del costo, si è tenuto conto anche di questo fattore.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)\n",
    "'''\n",
    "Come preannunciato nella definizione della funzione, abbiamo spiegato come mai dell'inserimento di un rettangolo blu, che rappresenta l'ostacolo, e un rettangolo rosso, che rappresenta la posizione \"safe\" di hand-position.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)\n",
    "'''\n",
    "Lo stesso vale in questo caso\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggiunto gaussiana inversa centrata sul goal point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "'''\n",
    "Grazie al seguente widget di matplotlib, possiamo visualizzare in maniera interattiva i grafici in altre finestre, ma soprattutto è possibile vedere in live la simulazione del robot sul simulatore robotarium\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "image_path = \"Training_Trajectories.jpg\"\n",
    "\n",
    "image = mpimg.imread(image_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Come prima modifica alla funzione di costo si fa notare un comportamento non ottimo che il robot ha quando si trova in prossimità del goal point, infatti, come si può notare dall'immagine qui sopra, il robot, nonostante arrivi in prossimità\n",
    "del goal point, non riesce a fermarsi subito, ma continua a muoversi in un intorno del goal point. Questo comportamento è dovuto al fatto che il costo dello stato è calcolato come la distanza dal goal point, e quindi, quando il robot si trova in prossimità\n",
    "il costo nel suo intorno assume valori simili, portando il robot a non puntare subito direttamente al goal point. Per tale motivo si è deciso di modificare la funzione di costo, in modo da rendere il costo in prossimità del goal point più \"scalato\", in maniera\n",
    "gauassiana, e quindi, in prossimità del goal point, il costo diminuisce rapidamente, portando il robot a puntare subito al goal point, senza girarci intorno.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "    \n",
    "    sigma=0.02\n",
    "    cost = -10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                  +np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))\n",
    "   \n",
    "    return(cost)\n",
    "\n",
    "'''\n",
    "Di conseguenza aggiungiamo un termine inverso per la gaussiana del goal point, con varianza uguale a quella dell'ostacolo, ma con valore leggermente minore, questo per evitare che in caso di errori di pianificazione, e scelta del goal point in prossimità,\n",
    "se non sull'ostacolo, il robot non provi ad andare nell'ostacolo per provare a raggiungere il goal point, ma ne rimanga comunque respinto.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) \n",
    "\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "'''\n",
    "Definiamo un esperimento analogo a quello della traccia, per far notare le differenze nella scelta di questo costo\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Per le simulazioni future, abbiamo semplicemente deciso di rendere la simulazione una funzione, così da poterla semplicemente richiamare senza riscrivere nuovamente il codice\n",
    "'''\n",
    "\n",
    "def genericSimulation(initial_conditions,goal_points,obs_points):\n",
    "    # Instantiate Robotarium object\n",
    "    N = 1 #Amount of robots per simulation\n",
    "\n",
    "    N_experiment = len(initial_conditions)\n",
    "    # X_si is going to be two-dimensional state history\n",
    "    X_Si = [0]*N_experiment\n",
    "    # D_Xi is going to be two-dimensional inputs history\n",
    "    D_Xi = [0]*N_experiment\n",
    "\n",
    "    # This first for loop creates the initial conditions\n",
    "    for I in range(N_experiment):\n",
    "\n",
    "        X_si = []\n",
    "        D_xi = []\n",
    "\n",
    "        r = robotarium.Robotarium(number_of_robots=N, show_figure=True, initial_conditions=initial_conditions[I], sim_in_real_time=False)\n",
    "\n",
    "        # Create mapping from the control inputs to the actual velocity commands to the unicycle\n",
    "        # Note: this is a very practical situation (robots often provide transformation functions to low level commands)\n",
    "        si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion() #Converts single integrator inputs to unicycle inputs (low-level controller)\n",
    "        _, uni_to_si_states = create_si_to_uni_mapping()\n",
    "        \n",
    "        # define x initially\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        # Plotting Parameters\n",
    "        CM = np.random.rand(N+10,3) # Random Colors\n",
    "        goal_marker_size_m = 0.15\n",
    "        obs_marker_size_m = 0.15\n",
    "        marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "        marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "        font_size = determine_font_size(r,0.1)\n",
    "        line_width = 5\n",
    "\n",
    "        # Create Goal Point Markers\n",
    "        #Text with goal identification\n",
    "        goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "        #Plot text for caption\n",
    "        goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "        for ii in range(goal_points.shape[1])]\n",
    "        goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "        for ii in range(goal_points.shape[1])]\n",
    "\n",
    "        #Text with goal identification\n",
    "        obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "        #Plot text for caption\n",
    "        obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "        for ii in range(obs_points.shape[1])]\n",
    "        obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "        for ii in range(obs_points.shape[1])]\n",
    "\n",
    "        r.step()\n",
    "\n",
    "        # While the robot is away from the objective ...\n",
    "        while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N):\n",
    "\n",
    "            try:\n",
    "                # Get poses of agents\n",
    "                x = r.get_poses()\n",
    "                x_si = uni_to_si_states(x)\n",
    "\n",
    "                #Add to the dataset\n",
    "                X_si.append(x_si)\n",
    "\n",
    "                # The lines below define the pdf of the robot \n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "                x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "                # This is about plotting\n",
    "                for j in range(goal_points.shape[1]):\n",
    "                    goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "                for j in range(obs_points.shape[1]):\n",
    "                    obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "                # Task: compute the action from the policy. Call the variable dxi: \n",
    "                # this is the action sampled from the optimal solution to the control problem\n",
    "                dxi = Control_step(x_sample,U_space_1,U_space_2,goal_points,obs_points) \n",
    "\n",
    "                D_xi.append(dxi)\n",
    "\n",
    "                # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "                dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "                # Set the velocities inputs\n",
    "                r.set_velocities(np.arange(N), dxu)\n",
    "                # Iterate the simulation\n",
    "                r.step()\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        D_Xi[I] = D_xi\n",
    "        X_Si[I] = X_si\n",
    "\n",
    "        #Call at end of script to print debug information and for your script to run on the Robotarium server properly\n",
    "        r.call_at_scripts_end()\n",
    "\n",
    "        '''\n",
    "        Dato che grazie a matplotlib qt è possibile visualizzare la simulazione live, è stato aggiunto un ramo try except per bloccare forzatamente l'esperimento, in caso di non raggiungimento del goal point\n",
    "        '''\n",
    "    return X_Si,D_Xi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))] #Initial pose of the robots\n",
    "\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points, obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "E' stata creata una funzione anche per la preparazione dei dati per il plotting\n",
    "'''\n",
    "\n",
    "def prepareDataForPlotting(XX, UU):\n",
    "    #Prepare data for plotting\n",
    "    X = []\n",
    "    X_plot = []\n",
    "    U = []\n",
    "    U_plot = []\n",
    "\n",
    "    for i in range(len(XX)):\n",
    "        X.append(np.array(XX[i]))\n",
    "        X_plot.append(np.array(XX[i]))\n",
    "\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    X = np.reshape(X, (-1, 2))\n",
    "\n",
    "    U = []\n",
    "    for i in range(len(UU)):\n",
    "        U.append(np.array(UU[i]))\n",
    "        U_plot.append(np.array(UU[i]))\n",
    "\n",
    "    U = np.concatenate(U, axis=0)\n",
    "    U = np.reshape(U, (-1, 2))\n",
    "    return X, X_plot, U, U_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import cm \n",
    "from matplotlib.ticker import LinearLocator \n",
    "import numpy as np \n",
    "\n",
    "'''\n",
    "E anche una funzione per il plot delle traiettorie in 2D\n",
    "'''\n",
    "def plotTrajectory(X_plot,obs_points,goal_points): \n",
    " \n",
    "#Task: plot trajectories with different colors \n",
    "    plt.figure(figsize=(9, 6)) \n",
    " \n",
    "    for i in range(len(X_plot)): \n",
    "        plt.plot(X_plot[i][:, 0], X_plot[i][:, 1], label=f'Traiettoria {i+1}') \n",
    "        plt.plot(X_plot[i][0, 0],X_plot[i][0, 1],'*',color='black',markersize=10) \n",
    " \n",
    "    ''' \n",
    "    Le linee di codice precedenti servono per visualizzare le traiettorie dei robot, in particolare, per ogni esperimento viene visualizzata la traiettoria del robot, mappandola con un diverso colore aggiungendo \n",
    "    un marker alla posizione iniziale del robot. \n",
    " \n",
    "    NOTA: nelle successive linee di codice, vengono plottati i goal point e gli ostacoli, ma non rappresentano in maniera fedele la realtà, in quanto sono stati plottati in un ambiente 2D e rappresentati come rettangoli, mentre, \n",
    "    come già discusso in precedenza, gli ostacoli dovrebbero essere rappresentati più come delle sfere, a causa della natura gaussiana multivariata che rappresenta la distanza. \n",
    "    ''' \n",
    "    square= plt.Rectangle((goal_points[0,0]-0.175,goal_points[1,0]-0.175), 0.35, 0.35, fc='green',ec=\"black\") \n",
    "\n",
    "    #Draw obstacles \n",
    "    for i in range(np.size(obs_points,axis=1)): \n",
    "        # square= plt.Rectangle((obs_points_f[0,i]-0.1,obs_points_f[1,i]-0.1), 0.2, 0.2, fc='red',ec=\"black\")\n",
    "        square= plt.Rectangle((obs_points[0,i]-0.175,obs_points[1,i]-0.175), 0.35, 0.35, fc='red',ec=\"black\")\n",
    "        obstacle_square2 = patches.Rectangle((obs_points[0,i]-0.225, obs_points[1,i]-0.225), 0.45, 0.45, linewidth=1, edgecolor='r', facecolor='none',alpha=0.5)\n",
    "\n",
    "        plt.gca().add_patch(obstacle_square2)\n",
    "        plt.gca().add_patch(square) \n",
    "     \n",
    " \n",
    "    square= plt.Rectangle((goal_points[0,0]-0.175,goal_points[1,0]-0.175), 0.35, 0.35, fc='green',ec=\"black\") \n",
    "    plt.gca().add_patch(square) \n",
    "    plt.ylim(-1.1,1.1) \n",
    "    plt.xlim(-1.6,1.6) \n",
    "    plt.xlabel('X [m]') \n",
    "    plt.ylabel('Y [m]')\n",
    "    plt.title('Robot trajectories')\n",
    "    \n",
    "    arena_border = patches.Rectangle((-1.5, -1), 1.5-(-1.5), 1-(-1), linewidth=1, edgecolor='black', facecolor='none')\n",
    "    plt.gca().add_patch(arena_border)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "E anche una funzione per il plot delle traiettorie in 3D, sappiamo che il robot non si muove in uno spazio tridimensionale, ma in base alle traiettorie è possibile capire quali sono state le scelte del robot e perchè\n",
    "'''\n",
    " \n",
    "def plotTrajectory3D(X_plot,obs_points,goal_points): \n",
    "    x_min = -1.6  \n",
    "    x_max = 1.6 \n",
    "    y_min = -1.1 \n",
    "    y_max = 1.1 \n",
    "    x_range = np.linspace(x_min, x_max, 100)  \n",
    "    y_range = np.linspace(y_min, y_max, 100)  \n",
    "    X, Y = np.meshgrid(x_range, y_range)  \n",
    "    Z = np.zeros((100, 100))  \n",
    "    for i in range(100):  \n",
    "        for j in range(100):  \n",
    "            Z[i, j] = state_cost(np.array([X[i, j], Y[i, j]]), goal_points, obs_points)  \n",
    "    fig = plt.figure(figsize=(12,8))  \n",
    "    ax = fig.add_subplot(111, projection='3d', autoscale_on=True)  \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7)  # Update alpha value here  \n",
    "    ax.set_xlabel('X')  \n",
    "    ax.set_ylabel('Y')  \n",
    "    ax.set_zlabel('Cost')  \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point')  \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here  \n",
    "    \n",
    "    original_list=[] \n",
    "    for i in range(len(X_plot)): \n",
    "        new_inner_list=[] \n",
    "        for j in range(len(X_plot[i])): \n",
    "            new_array_3d=np.append(X_plot[i][j],state_cost(X_plot[i][j],goal_points,obs_points)) \n",
    "            new_inner_list.append(new_array_3d) \n",
    "            \n",
    "        original_list.append(new_inner_list) \n",
    "    \n",
    "    for i in range(len(X_plot)): \n",
    "        original_array = np.array(original_list[i]) \n",
    "        plt.plot(original_array[:, 0], original_array[:, 1], 0,  label=f'Trajectory {i+1}') \n",
    "\n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.15, obs_points[0, i] - 0.15, obs_points[0, i] + 0.15, obs_points[0, i] + 0.15, obs_points[0, i] - 0.15]\n",
    "        square_y = [obs_points[1, i] - 0.15, obs_points[1, i] + 0.15, obs_points[1, i] + 0.15, obs_points[1, i] - 0.15, obs_points[1, i] - 0.15]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "        # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.25, obs_points[0, i] - 0.25, obs_points[0, i] + 0.25, obs_points[0, i] + 0.25, obs_points[0, i] - 0.25]\n",
    "        square_y_large = [obs_points[1, i] - 0.25, obs_points[1, i] + 0.25, obs_points[1, i] + 0.25, obs_points[1, i] - 0.25, obs_points[1, i] - 0.25]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "\n",
    "    ax.legend() \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dopo aver inserito questo nuovo termine facciamo notare come, in caso di sbagliata pianificazione, il robot non si avvicina mai all'ostacolo, ma rimane sempre a una distanza di sicurezza, e questo è dovuto al fatto che il costo della gaussiana inversa è minore\n",
    "rispetto a quello della gaussiana sull'ostacolo\n",
    "'''\n",
    "goal_points = np.array(np.mat('0; 0; 0'))\n",
    "\n",
    "obs_points = np.array(np.mat('0 ;0;0')) \n",
    "\n",
    "\n",
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions=[np.array(np.mat('1.4;0.9; 0'))] \n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points, obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "\n",
    "'''\n",
    "Come vediamo il robot non tenta di andare nel goal point, ma rimane respinto dall'ostacolo, da notare come viene in caso di sovrapposizione abbiamo deciso di mostrare l'ostacolo implicitamente assumendo che il goal point\n",
    "fosse nello stesso punto\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROVA CON CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "image_path = \"Wall.jpeg\"\n",
    "\n",
    "image = mpimg.imread(image_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ulteriore appunto che possiamo fare al costo attuale, è che, come è possibile vedere dal plot 3D qui sopra, il cluster di ostacoli crea una sorta di \"muro\" che porta il robot a fermarsi intorno al suo punto medio, in caso di goal point posizionato dietro\n",
    "al cluster di ostacoli. Per evitare ciò, c'è bisogno che anche il cluster sia modellato come una gaussiana per permettere così al robot di \"scivolare\" ai bordi del cluster e raggiungere il goal point. Questo lo abbiamo raggiunto grazie alla modellazione\n",
    "degli ostacoli tramite grafo, così da trovare i cluster, e modellazione del costo del clustering come una gaussiana centrata nel centro geometrico del cluster.\n",
    "La scelta di clusterizzazione per una distanza < 0.45 tra gli ostacoli, è per discretizzare quei gruppi di ostacoli tra i quali il robot non passerebbe (il robot è grosso 0.11 cm, quindi se la distanza fra i centri degli ostacoli è < 0.45, allora sicuramente lì il robot\n",
    "non passa)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "Funzione per creare il grafo, trovare le componenti connesse e calcolare il loro centro geometrico\n",
    "'''\n",
    "def clustering(obs_points):\n",
    "\n",
    "    # Create an empty graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        G.add_node(i)\n",
    "\n",
    "    # Add edges between nodes based on Euclidean distance\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        for j in range(i+1, obs_points.shape[1]):\n",
    "            distance = np.linalg.norm(obs_points[:,i] - obs_points[:,j])\n",
    "            if distance <= 0.45:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "   \n",
    "    # Find connected components\n",
    "    connected_components = list(nx.connected_components(G))\n",
    "    centroidi = []\n",
    "    # Print connected components\n",
    "    for i, component in enumerate(connected_components):\n",
    "        sumx=0\n",
    "        sumy=0\n",
    "        for j in component:\n",
    "            sumx+=obs_points[0][j]\n",
    "            sumy+=obs_points[1][j]\n",
    "        centroidi.append([sumx/len(component),sumy/len(component),len(component)])\n",
    "    \n",
    "    return centroidi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Funzione di costo con aggiunta del costo del clustering, in particolare verifichiamo che il centroide non sia troppo vicino al goal point, in caso contrario il costo tende a 0, altrimenti il costo è proporzionale ad una gaussiana centrata nel centroide e con valore\n",
    "maggiore a seconda del numero di ostacoli che compongono il cluster, perchè maggiori gli ostacoli più velocemente vogliamo che il robot si spinga ai lati del cluster. In questo caso il goal point è assunto essere soltanto uno, in caso di più goal point, la funzione\n",
    "deve essere modificata per tenerlo in conto\n",
    "'''\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    centroidi=clustering(obs_points)\n",
    "\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "    cost2 = 0\n",
    "    for i in range(len(centroidi)):\n",
    "            dist= np.sqrt((goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2) \n",
    "            dist=dist if dist < 0.175 else 1 \n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist\n",
    "            \n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) \n",
    "  \n",
    "    \n",
    "    sigma=0.02\n",
    "    cost = -10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))+cost2\n",
    "\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('-0.5; 0; 0'))\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;-0.4 -0.2 0 0.2 0.4;0 0 0 0 0'))\n",
    "'''\n",
    "Verifichiamo con un esempio a doc cosa succede\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.3; 0; 0'))]\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "'''\n",
    "Il robot, nonostante ai lati del cluster non riesca subito ad individuare la direzione ottimale per raggiungere il goal point, riesce comunque,anche grazie alla rumorosità inserità, a raggiungere il goal point\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Facciamo ora l'esperimento con le condizioni date da traccia\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) \n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))] #Initial pose of the robots\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points, obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "'''\n",
    "Anche in questo caso si comporta in maniera corretta e il robot riesce a raggiungere sempre l'obiettivo\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Facciamo notare come l'aggiunta del termine clustering non crea situazioni critiche, come potrebbe creare la gaussiana inversa (ma che abbiamo fatto notare come ciò non accade), poichè in caso di vicinanza al goal point, il valore\n",
    "della gaussiana del clustering si riduce drasticamente\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggiunta dell'hand position anche per muro \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_cost(state,goal_points,obs_points):\n",
    "    centroidi=clustering(obs_points)\n",
    "\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "    cost2 = 0\n",
    "    for i in range(len(centroidi)):\n",
    "            dist= (goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2 # da cambiare se sono più goal point #TODO\n",
    "            dist=dist if dist < 0.175 else 1 #(%1 è per evitare di farla divergere, cioè mantenerla in 1 però è da verificare)\n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist\n",
    "            # Se il centroide è trppo vicino al goal point, allora la gaussiana è molto piccola, evitando di rischiare di portare il robot a non voler andare verso il goal point\n",
    "\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) \n",
    "  \n",
    "    \n",
    "    sigma=0.06\n",
    "    cost=-10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 20*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))+cost2\n",
    "   \n",
    "\n",
    "    return(cost)\n",
    "\n",
    "'''\n",
    "Come annunciato all'inizio della discussione, anche per quanto riguarda i bordi del robotarium abbiamo aggiunto una safe position per il problema dell'hand position del robot, aumentando un poco la varianza per \"allungarsi\" fino ai bordi teorici del muro\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "'''\n",
    "   Abbiamo ridefinito le funzioni per il plotting, per aggiungere anche il \"nuovo bordo\" da evitare, sia per il caso 2D che per il caso 3D\n",
    "'''\n",
    "\n",
    "def plot_heatmap(goal_points,obs_points):\n",
    "    plt.figure(figsize=(9,6))\n",
    "    x_min = -1.6\n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min,x_max,100)\n",
    "    y_range = np.linspace(y_min,y_max,100)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    Z = np.zeros((100,100))\n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            Z[i,j] = state_cost(np.array([X[i,j],Y[i,j]]),goal_points,obs_points)\n",
    "    plt.pcolormesh(X,Y,Z)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(goal_points[0],goal_points[1],c='r')\n",
    "    plt.scatter(obs_points[0,:],obs_points[1,:],c='k')\n",
    "    plt.title('Cost function')\n",
    "\n",
    "    # Add labels to the axes\n",
    "    plt.xlabel('X [m]')\n",
    "    plt.ylabel('Y [m]')\n",
    "    \n",
    "    # Add a rectangle for the border of the arena\n",
    "    arena_border = patches.Rectangle((-1.5, -1), 1.5-(-1.5), 1-(-1), linewidth=1, edgecolor='black', facecolor='none')\n",
    "    arena_border2 = patches.Rectangle((-1.4, -0.9), 1.4-(-1.4), 0.9-(-0.9), linewidth=1, edgecolor='red', facecolor='none')\n",
    "\n",
    "    plt.gca().add_patch(arena_border)\n",
    "    plt.gca().add_patch(arena_border2)\n",
    "    \n",
    "    # Add squares for each obstacle\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        obstacle_square = patches.Rectangle((obs_points[0,i]-0.175, obs_points[1,i]-0.175), 0.35, 0.35, linewidth=1, edgecolor='b', facecolor='none',alpha=0.5)\n",
    "        obstacle_square2 = patches.Rectangle((obs_points[0,i]-0.225, obs_points[1,i]-0.225), 0.45, 0.45, linewidth=1, edgecolor='r', facecolor='none',alpha=0.5)\n",
    "\n",
    "        plt.gca().add_patch(obstacle_square)\n",
    "        plt.gca().add_patch(obstacle_square2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_3d_heatmap(goal_points, obs_points): \n",
    "    x_min = -1.6 \n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min, x_max, 100) \n",
    "    y_range = np.linspace(y_min, y_max, 100) \n",
    "    X, Y = np.meshgrid(x_range, y_range) \n",
    "    Z = np.zeros((100, 100)) \n",
    "    for i in range(100): \n",
    "        for j in range(100): \n",
    "            Z[i, j] = state_cost(np.array([X[i, j], Y[i, j]]), goal_points, obs_points) \n",
    "    fig = plt.figure(figsize=(15,10)) \n",
    "    ax = fig.add_subplot(111, projection='3d') \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7)  # Update alpha value here \n",
    "    ax.set_xlabel('X') \n",
    "    ax.set_ylabel('Y') \n",
    "    ax.set_zlabel('Cost') \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point') \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here \n",
    "    \n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.175, obs_points[0, i] - 0.175, obs_points[0, i] + 0.175, obs_points[0, i] + 0.175, obs_points[0, i] - 0.175]\n",
    "        square_y = [obs_points[1, i] - 0.175, obs_points[1, i] + 0.175, obs_points[1, i] + 0.175, obs_points[1, i] - 0.175, obs_points[1, i] - 0.175]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "       # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.275, obs_points[0, i] - 0.275, obs_points[0, i] + 0.275, obs_points[0, i] + 0.275, obs_points[0, i] - 0.275]\n",
    "        square_y_large = [obs_points[1, i] - 0.275, obs_points[1, i] + 0.275, obs_points[1, i] + 0.275, obs_points[1, i] - 0.275, obs_points[1, i] - 0.275]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    square_x = [-1.4, -1.4, 1.4, 1.4, -1.4]\n",
    "    square_y = [-0.9, 0.9, 0.9, -0.9, -0.9]\n",
    "    ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "    \n",
    "    # Add larger red square centered at obstacle points\n",
    "    square_x_large = [-1.4, -1.4, 1.4, 1.4, -1.4]\n",
    "    square_y_large = [-0.9, 0.9, 0.9, -0.9, -0.9]\n",
    "    ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "\n",
    "    ax.legend() \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) \n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "plot_heatmap(goal_points,obs_points)\n",
    "\n",
    "'''\n",
    "Effettuiamo l'esperimento dato da traccia\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))] #Initial pose of the robots\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "\n",
    "''' \n",
    "Il robot si comporta bene\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cerchiamo di capire se il robot potrebbe uscire dal robotarium e quindi inserire un termine \"a muro\" letteralmente per evitare che ciò accada\n",
    "'''\n",
    "goal_points = np.array(np.mat('1.25; 0.35; 0')) \n",
    "obs_points = np.array(np.mat('0.9 1.25;0.8 0.6 ;0 0'))\n",
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('1.25;0.85; 0'))]\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points, obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "'''Da alcuni test fatti, in questo caso bloccando manualmente la funzione, oppure #TODO condizione di terminazione, si nota come il robot non tenta di uscire dai limiti, ma piuttosto rimane intrappolato, il chè va bene, nel caso in cui\n",
    "si trovino situazioni in cui il robot invece tenti di uscire, bisognerebbe agire nuovamente sulla funzione di costo per evitare ciò'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esperimento interessante, robot in mezzo agli ostacoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goal_points = np.array(np.mat('0; 0; 0')) \n",
    "obs_points = np.array(np.mat('-0.4 -0.4 -0.4 0 0.4 0.4 0.4; -0.4 0 0.4 0.4 0.4 0 -0.4; 0 0 0 0 0 0 0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_cost(state,goal_points,obs_points):\n",
    "    centroidi=clustering(goal_points,obs_points)\n",
    "\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "    cost2 = 0\n",
    "    for i in range(len(centroidi)):\n",
    "            dist= (goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2 # da cambiare se sono più goal point #TODO\n",
    "            dist=dist if dist < 0.175 else 1 #(%1 è per evitare di farla divergere, cioè mantenerla in 1 però è da verificare)\n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist\n",
    "            # Se il centroide è trppo vicino al goal point, allora la gaussiana è molto piccola, evitando di rischiare di portare il robot a non voler andare verso il goal point\n",
    "\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) \n",
    "  \n",
    "    \n",
    "    sigma=0.06\n",
    "    cost=-10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 20*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))+cost2\n",
    "   \n",
    "\n",
    "    return(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('0;-0.85; 0'))]\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)\n",
    "'''\n",
    "In questo caso il robot riesce a raggiungere l'obiettivo, nonostante un pò di difficoltà, avendo anche abbastanza spazio per passare tra gli ostacoli. Una simulazione simile, ma in cui il corridoio tra gli ostacoli fosse più piccolo, è stata fatta, e il robot\n",
    "non riesce a raggiungere l'obiettivo, ma rimane intrappolato tra gli ostacoli.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altri esperimenti "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "obs_points = np.array(np.mat('0.5 0.9 0.9; 0.75 0.55 0.25; 0 0 0' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('0.9;0.85; 0'))]\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "_,X_plot,_,_=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casi non risolti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goal_points = np.array(np.mat('0.9; 0.85; 0')) # test\n",
    "obs_points = np.array(np.mat('0.5 0.9 0.9; 0.75 0.55 0.25; 0 0 0' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('0.0;0; 0'))]\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altro caso non risolto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('0; 0; 0')) \n",
    "obs_points = np.array(np.mat('-0.35 -0.35 -0.35 0 0.35 0.35 0.35; -0.35 0 0.35 0.35 0.35 0 -0.35; 0 0 0 0 0 0 0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = [np.array(np.mat('0;-0.8; 0')),np.array(np.mat('0;+0.8; 0'))] #Initial pose of the robots\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambio delle feature (Esperimento da traccia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data la funzione di costo:\n",
    "'''\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    centroidi=clustering(obs_points)\n",
    "\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "    cost2 = 0\n",
    "    for i in range(len(centroidi)):\n",
    "            dist= (goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2 # da cambiare se sono più goal point #TODO\n",
    "            dist=dist if dist < 0.175 else 1 #(% 1 è per evitare di farla divergere, cioè mantenerla in 1 però è da verificare)\n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist\n",
    "            # Se il centroide è trppo vicino al goal point, allora la gaussiana è molto piccola, evitando di rischiare di portare il robot a non voler andare verso il goal point\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) \n",
    "    \n",
    "    sigma=0.06\n",
    "    cost=-10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 20*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))+cost2\n",
    "   \n",
    "\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) # Da traccia\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0')) # Da traccia\n",
    "\n",
    "initial_conditions = [np.array(np.mat('1.45;0.95; 0')),np.array(np.mat('0.225;0.95; 0')),np.array(np.mat('0.225;0.25; 3.14')),np.array(np.mat('1.45;0.25; 0')),np.array(np.mat('1.45;-0.75; 3.14')),np.array(np.mat('1;-0.95; 0')),\n",
    "                      np.array(np.mat('0.225;-0.95; 0')),np.array(np.mat('-0.225;-0.95; 3.14')), np.array(np.mat('-0.225;0.95; 0')),np.array(np.mat('-0.225;0.45; 0')), np.array(np.mat('-1.45;0.95; 0')),np.array(np.mat('-1.45;0.25; 0'))]\n",
    "\n",
    "\n",
    "print(len(initial_conditions))\n",
    "plot_heatmap(goal_points,obs_points)\n",
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se vuoi runnare di nuovo il FOC devi rieseguire il codice di definizione della control_step sopra.\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggiunta dei termini distanza dai muri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')) # da traccia\n",
    "#obs_points_f = np.array(np.mat('-1.35 -1.35 -1.35 -1.35 -1.35 -0.675 -0.675 -0.675 -0.675 -0.675 0 0 0 0 0 0.675 0.675 0.675 0.675 0.675 1.35 1.35 1.35 1.35 1.35;-0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n",
    "# obs_points_f = np.array(np.mat('0 0 0 0 0 0.5 0.5 0.5 0.5 0.5 -0.5 -0.5 -0.5 -0.5 -0.5 1 1 1 1 1 -1 -1 -1 -1 -1 ;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')) # da traccia\n",
    "\n",
    "# obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8 -1.15 -0.4 0.4 1.15 -1.15 -0.4 0.4 1.15 1.5 1.5 1.5 -1.5 -1.5 -1.5;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 1 1 1 1 -1 -1 -1 -1 0.5 0 -0.5 0.5 0 -0.5;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')) # da traccia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature del prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature nostre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feature = np.size(obs_points_f,axis=1)+1+1 # 1 per la distanza dal goal point, 1 per la gaussiana sul goal point, 4 per i muri\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    sigma=0.06\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) # per il goal point\n",
    "    features[1] = (1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) + np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) + np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2))\n",
    "    \n",
    "    # tollerance=1e-2  \n",
    "    # features[2] = ((1/((next_state[0]-1.5)**2  + tollerance))) + 1/((1.5-goal_points[0])**2+tollerance) # per il muro a destra\n",
    "    # features[3] = ((1/((next_state[0]-(-1.5))**2  + tollerance))) + 1/((-1.5-goal_points[0])**2+tollerance)  # per il muro a sinistra\n",
    "    # features[4] = ((1/((next_state[1]-1.0)**2  + tollerance))) + 1/((1.0-goal_points[1])**2+tollerance) # per il muro sopra\n",
    "    # features[5] = ((1/((next_state[1]-(-1.0))**2  + tollerance))) + 1/((-1.0-goal_points[1])**2+tollerance)  # per il muro sotto\n",
    "\n",
    "    # sigma=0.06\n",
    "    # features[2] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) # per il muro a destra\n",
    "    # features[3] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)  # per il muro a sinistra\n",
    "    # features[4] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) # per il muro sopra\n",
    "    # features[5] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2)  # per il muro sotto\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codice per l'ioc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1\n",
    "w = cp.Variable((1,N_feature))\n",
    "constraints = [w >= 0]\n",
    "R = np.zeros((99,1))\n",
    "L = []\n",
    "\n",
    "f_expect = np.zeros((2,20))\n",
    "feature_sampled = np.zeros((N_feature,M))\n",
    "PF = np.zeros((control_space_size,control_space_size,M))\n",
    "\n",
    "for i in range(M):\n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size))\n",
    "    state = np.array(X[i,:]) #Get the state\n",
    "\n",
    "    x0 = state.reshape(-1,1)\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            next_sample = f.mean\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples)\n",
    "            feature_sample = np.zeros((N_feature,N_samples))\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1)\n",
    "\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy()))\n",
    "            '''\n",
    "            Questo riga rappresenta il termine (5) descritto nel markdown, in particolare rappresenta l'esponenziale dell'entropia cambiata di segno.\n",
    "            '''\n",
    "\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # N features x 9\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step)\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov)\n",
    "    next_samples_f1 = f1.rvs(N_samples)\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    tempPF = np.reshape(PF,(control_space_size**2,M)) # N features x 9\n",
    "\n",
    "    l =-(w @ feature_sampled[:,i])+cp.log_sum_exp(cp.reshape(w@features[:,:],(9,))+cp.log(tempPF[:,i]))\n",
    "    \n",
    "    '''\n",
    "    Ogni termine l, rappresenta il singolo termine della sommatoria (4) descritta nel markdown, in particolare, dato che il codice pre-esistente già calcolava il termine (5) e il termine (6), lo scopo di questa parte di codice\n",
    "    è quello di configurare le dimensionalità dei vari termini, effettuando un reshape della PF calcolata, portandola da una dimensionalità (N feature x 3 x 3), a una dimensionalità (N x 9) per essere gestita nella somma con il prodotto dei pesi con le features.\n",
    "    Inoltre, dato che stiamo risolvendo un problema di LSE tramite cvx, dobbiamo fornirgli in input il valore atteso del prodotto tra pesi e feature, e il valore atteso della f cambiata di segno, rappresentato dall'entropia,\n",
    "    ma dato che ci viene già fornito dal codice l'esponenziale dell'entropia, cambiata di segno, dobbiamo sommare il logaritmo di questa quantità in modo da riportarci nella forma originale del problema (4).\n",
    "    '''\n",
    "    \n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    L.append(l)\n",
    "\n",
    "    '''\n",
    "    Con queste linee di codice creiamo l'intera sommatoria su M esperimenti.\n",
    "    '''\n",
    "\n",
    "    # (iii) solve the problem \n",
    "objective = cp.Minimize(cp.sum(L))\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = False)\n",
    "\n",
    "'''\n",
    "Infine risolviamo il problema, facendo uso di cvx, minimizzando la sommatoria dei termini l, ottenendo i pesi w ottimi delle feature scelte.\n",
    "'''\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costo ricostruito professore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum #+ 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "                # + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "                # + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    \n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costro ricostruito nostro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    # tollerance=1e-2\n",
    "    # walls_sum = -(weights[:,2]*1/((state[0]-1.5)**2 + tollerance) + weights[:,3]*1/((state[0]-(-1.5))**2 + tollerance) + weights[:,4]*1/((state[1]-1.0)**2 + tollerance) + weights[:,5]*1/((state[1]+(-1.0))**2 + tollerance))\n",
    "\n",
    "    sigma=0.06\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum -weights[:,1]*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resto del codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transpose the data array to rotate the heatmap\n",
    "#data_rotated = np.transpose(Coat_Map) Costo effettivo\n",
    "data_rotated = np.transpose(Cost_Map)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting the pcolormesh for the data\n",
    "plt.pcolormesh(X_axis, Y_axis, data_rotated, cmap='viridis', alpha=0.92)\n",
    "plt.colorbar()\n",
    "\n",
    "# Define contour levels to create 6 regions\n",
    "contour_levels = np.linspace(data_rotated.min(), data_rotated.max(), 7)  # 7 levels for 6 regions\n",
    "\n",
    "# Get colors based on the viridis colormap for the given contour levels\n",
    "viridis_colors = plt.cm.viridis(np.linspace(0, 1, len(contour_levels)))\n",
    "\n",
    "for i, level in enumerate(contour_levels):\n",
    "    plt.contour(X_axis, Y_axis, data_rotated, levels=[level], colors=[viridis_colors[i]], linewidths=2.5, linestyles='dashed')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "In questo pezzo di codice viene visualizzato il costo dello stato calcolato con i pesi ottenuti dall'ottimizzazione, ovvero il costo stimato. In particolare, è rappresentato come una heatmap analogamente a quanto accaduto\n",
    "per il costo definito nel problema di FOC. Inoltre, sono state anche disegnate delle linee tratteggiate che rappresentano i livelli di costo.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_3d_heatmap_recostructed(goal_points, obs_points): \n",
    "    x_min = -1.6 \n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min, x_max, 100) \n",
    "    y_range = np.linspace(y_min, y_max, 100) \n",
    "    X, Y = np.meshgrid(x_range, y_range) \n",
    "    Z = np.zeros((100, 100)) \n",
    "    for i in range(100): \n",
    "        for j in range(100): \n",
    "            Z[i, j] = state_cost_estimated(np.array([X[i, j], Y[i, j]]), goal_points, obs_points, weights)\n",
    "    fig = plt.figure(figsize=(15,10)) \n",
    "    ax = fig.add_subplot(111, projection='3d') \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.97)  # Update alpha value here \n",
    "    ax.set_xlabel('X') \n",
    "    ax.set_ylabel('Y') \n",
    "    ax.set_zlabel('Cost') \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point') \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here \n",
    "\n",
    "    original_list=[] \n",
    "    for i in range(len(X_plot)): \n",
    "        new_inner_list=[] \n",
    "        for j in range(len(X_plot[i])): \n",
    "            new_array_3d=np.append(X_plot[i][j],state_cost(X_plot[i][j],goal_points,obs_points)) \n",
    "            new_inner_list.append(new_array_3d) \n",
    "            \n",
    "        original_list.append(new_inner_list) \n",
    "    \n",
    "    for i in range(len(X_plot)): \n",
    "        original_array = np.array(original_list[i]) \n",
    "        plt.plot(original_array[:, 0], original_array[:, 1],  0,  label=f'Trajectory {i+1}')\n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.175, obs_points[0, i] - 0.175, obs_points[0, i] + 0.175, obs_points[0, i] + 0.175, obs_points[0, i] - 0.175]\n",
    "        square_y = [obs_points[1, i] - 0.175, obs_points[1, i] + 0.175, obs_points[1, i] + 0.175, obs_points[1, i] - 0.175, obs_points[1, i] - 0.175]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "       # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.275, obs_points[0, i] - 0.275, obs_points[0, i] + 0.275, obs_points[0, i] + 0.275, obs_points[0, i] - 0.275]\n",
    "        square_y_large = [obs_points[1, i] - 0.275, obs_points[1, i] + 0.275, obs_points[1, i] + 0.275, obs_points[1, i] - 0.275, obs_points[1, i] - 0.275]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    \n",
    "    ax.legend() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap_recostructed(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "\n",
    "'''\n",
    "La funzione ha la sintassi e il significato analogo a quella definita per il problema di FOC, con la sola differenza che il costo dello stato viene calcolato con i pesi ottenuti dall'ottimizzazione,\n",
    "e quindi il costo è quello stimato dal problema IOC.\n",
    "'''\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                # Queste tre linee di codice calcolano il prossimo stato, a partire da una delle 9 azioni scandite\n",
    "                # dai cicli for, e creano una multivariata normale centrata nel prossimo stato con covarianza data\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                # Queste due linee di codice campionano 20 campioni dalla distribuzione calcolata precedentemente\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                # Calcoliamo il costo medio dei campioni secondo la funzione state_cost, si tratta di calcolare\n",
    "                # l'expected value della formula per la policy\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "                # print(\"entropy: \" + str(f.entropy()))\n",
    "                # print(\"next state: \" + str(next_state))\n",
    "                # print(\"cost: \" + str(cost))\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())\n",
    "\n",
    "                # la log_DKL è uguale, secondo formulazione, a np.exp(-DKL-costoatteso), il costo atteso lo abbiamo calcolato\n",
    "                # al punto precedente, mentre la DKL(f||g), dato che g è uniforme, diventa semplicemente l'entropia con un termine \n",
    "                # log(q) derivante da calcoli algebrici\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "\n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) # Da traccia\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0')) # Da traccia\n",
    "initial_conditions = [np.array(np.mat('-1.4;0.9; 0')),np.array(np.mat('1;0.9; 0')),np.array(np.mat('1;-0.25; 0'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supponendo che 'obs_points_f' e 'weights' siano definiti\n",
    "\n",
    "# Plot dei punti caratteristici sulla griglia\n",
    "plt.figure(figsize=(8, 6))\n",
    "newWeights=-weights[0][5:]# Normalizza i pesi nell'intervallo 100-1000\n",
    "weights_normalized = (newWeights - newWeights.min()) / (newWeights.max() - newWeights.min())\n",
    "weights_mapped = 100 + (weights_normalized * 900)  # Scala il valore tra 100 e 1000\n",
    "\n",
    "# Plot dei punti caratteristici con dimensioni basate sui pesi\n",
    "plt.scatter(obs_points_f[0], obs_points_f[1], s=weights_mapped, c='red', marker='o')\n",
    "\n",
    "# Plot del testo con i pesi corrispondenti\n",
    "for i in range(len(newWeights)):\n",
    "    plt.text(obs_points_f[0, i], obs_points_f[1, i]-0.15, f'{-newWeights[i]:.2f}', fontsize=8, color='black')\n",
    "\n",
    "plt.xlabel('Asse X')\n",
    "plt.ylabel('Asse Y')\n",
    "plt.title('Punti caratteristici sulla griglia del Robotarium con pesi')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambio delle feature (Robot che parte diedro un muro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideriamo il caso in cui il robot parta in un angolo tra degli ostacoli ed il goal point sia dietro questi ostacoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data la funzione di costo:\n",
    "'''\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    centroidi=clustering(obs_points)\n",
    "\n",
    "    v = np.array([0.015, 0.015], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "    cost2 = 0\n",
    "    for i in range(len(centroidi)):\n",
    "            dist= (goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2 # da cambiare se sono più goal point #TODO\n",
    "            dist=dist if dist < 0.175 else 1 #(% 1 è per evitare di farla divergere, cioè mantenerla in 1 però è da verificare)\n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist\n",
    "            # Se il centroide è trppo vicino al goal point, allora la gaussiana è molto piccola, evitando di rischiare di portare il robot a non voler andare verso il goal point\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar) \n",
    "    \n",
    "    sigma=0.06\n",
    "    cost=-10*my_logpdf(state[:2],goal_points[:2,0],covar) + 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 20*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))+cost2\n",
    "   \n",
    "\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "obs_points = np.array(np.mat('0.5 0.9 0.9; 0.75 0.55 0.20; 0 0 0' ))\n",
    "\n",
    "# initial_conditions = [np.array(np.mat('0.7; 0.85; 0')), np.array(np.mat('1.4; 0.9; 3.14')), np.array(np.mat('0.6; 0.45; 0'))]\n",
    "initial_conditions = [np.array(np.mat('0.7; 0.85; 0')), np.array(np.mat('1.4; 0.9; 3.14')), np.array(np.mat('0.6; 0.45; 0')), np.array(np.mat('1.45;0.95; 0')),np.array(np.mat('0.225;0.95; 0')),np.array(np.mat('-1.0; -0.75; 3.14')),np.array(np.mat('1.45; 0.25; 3.14')),np.array(np.mat('1.45;-0.75; 3.14')),np.array(np.mat('1;-0.95; 0')),\n",
    "                      np.array(np.mat('0.225;-0.95; 0')),np.array(np.mat('-0.225;-0.95; 3.14')), np.array(np.mat('-0.225;0.95; 0')),np.array(np.mat('-1.4; -0.95; 1.57')), np.array(np.mat('-1.45;0.95; 0')),np.array(np.mat('-1.45;0.25; 0'))]\n",
    "\n",
    "\n",
    "\n",
    "# for _ in range(20):\n",
    "#     x = np.random.uniform(-1.45, 1.45)\n",
    "#     y = np.random.uniform(-0.95, 0.95)\n",
    "#     initial_conditions.append(np.array([[x], [y], [0]]))\n",
    "\n",
    "\n",
    "plot_heatmap(goal_points,obs_points)\n",
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se vuoi runnare di nuovo il FOC devi rieseguire il codice di definizione della control_step sopra.\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature del prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')) # da traccia\n",
    "plot_heatmap(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature nostre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('-1.35 -1.35 -1.35 -1.35 -1.35 -0.675 -0.675 -0.675 -0.675 -0.675 0 0 0 0 0 0.675 0.675 0.675 0.675 0.675 1.35 1.35 1.35 1.35 1.35;-0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n",
    "plot_heatmap(goal_points,obs_points_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feature = np.size(obs_points_f,axis=1)+1+1 # 1 per la distanza dal goal point, 1 per la gaussiana sul goal point, 4 per i muri\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    sigma=0.06\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) # per il goal point\n",
    "    features[1] = (1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) + np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) + np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2))\n",
    "    \n",
    "    # tollerance=1e-2  \n",
    "    # features[2] = ((1/((next_state[0]-1.5)**2  + tollerance))) + 1/((1.5-goal_points[0])**2+tollerance) # per il muro a destra\n",
    "    # features[3] = ((1/((next_state[0]-(-1.5))**2  + tollerance))) + 1/((-1.5-goal_points[0])**2+tollerance)  # per il muro a sinistra\n",
    "    # features[4] = ((1/((next_state[1]-1.0)**2  + tollerance))) + 1/((1.0-goal_points[1])**2+tollerance) # per il muro sopra\n",
    "    # features[5] = ((1/((next_state[1]-(-1.0))**2  + tollerance))) + 1/((-1.0-goal_points[1])**2+tollerance)  # per il muro sotto\n",
    "\n",
    "    # sigma=0.06\n",
    "    # features[2] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) # per il muro a destra\n",
    "    # features[3] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)  # per il muro a sinistra\n",
    "    # features[4] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) # per il muro sopra\n",
    "    # features[5] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2)  # per il muro sotto\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codice per l'ioc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1\n",
    "w = cp.Variable((1,N_feature))\n",
    "constraints = [w >= 0]\n",
    "R = np.zeros((99,1))\n",
    "L = []\n",
    "\n",
    "f_expect = np.zeros((2,20))\n",
    "feature_sampled = np.zeros((N_feature,M))\n",
    "PF = np.zeros((control_space_size,control_space_size,M))\n",
    "\n",
    "for i in range(M):\n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size))\n",
    "    state = np.array(X[i,:]) #Get the state\n",
    "\n",
    "    x0 = state.reshape(-1,1)\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            next_sample = f.mean\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples)\n",
    "            feature_sample = np.zeros((N_feature,N_samples))\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1)\n",
    "\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy()))\n",
    "            '''\n",
    "            Questo riga rappresenta il termine (5) descritto nel markdown, in particolare rappresenta l'esponenziale dell'entropia cambiata di segno.\n",
    "            '''\n",
    "\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # N features x 9\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step)\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov)\n",
    "    next_samples_f1 = f1.rvs(N_samples)\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    tempPF = np.reshape(PF,(control_space_size**2,M)) # N features x 9\n",
    "\n",
    "    l =-(w @ feature_sampled[:,i])+cp.log_sum_exp(cp.reshape(w@features[:,:],(9,))+cp.log(tempPF[:,i]))\n",
    "    \n",
    "    '''\n",
    "    Ogni termine l, rappresenta il singolo termine della sommatoria (4) descritta nel markdown, in particolare, dato che il codice pre-esistente già calcolava il termine (5) e il termine (6), lo scopo di questa parte di codice\n",
    "    è quello di configurare le dimensionalità dei vari termini, effettuando un reshape della PF calcolata, portandola da una dimensionalità (N feature x 3 x 3), a una dimensionalità (N x 9) per essere gestita nella somma con il prodotto dei pesi con le features.\n",
    "    Inoltre, dato che stiamo risolvendo un problema di LSE tramite cvx, dobbiamo fornirgli in input il valore atteso del prodotto tra pesi e feature, e il valore atteso della f cambiata di segno, rappresentato dall'entropia,\n",
    "    ma dato che ci viene già fornito dal codice l'esponenziale dell'entropia, cambiata di segno, dobbiamo sommare il logaritmo di questa quantità in modo da riportarci nella forma originale del problema (4).\n",
    "    '''\n",
    "    \n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    L.append(l)\n",
    "\n",
    "    '''\n",
    "    Con queste linee di codice creiamo l'intera sommatoria su M esperimenti.\n",
    "    '''\n",
    "\n",
    "    # (iii) solve the problem \n",
    "objective = cp.Minimize(cp.sum(L))\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = False)\n",
    "\n",
    "'''\n",
    "Infine risolviamo il problema, facendo uso di cvx, minimizzando la sommatoria dei termini l, ottenendo i pesi w ottimi delle feature scelte.\n",
    "'''\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costo ricostruito professore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    \n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costro ricostruito nostro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    # tollerance=1e-2\n",
    "    # walls_sum = -(weights[:,2]*1/((state[0]-1.5)**2 + tollerance) + weights[:,3]*1/((state[0]-(-1.5))**2 + tollerance) + weights[:,4]*1/((state[1]-1.0)**2 + tollerance) + weights[:,5]*1/((state[1]+(-1.0))**2 + tollerance))\n",
    "\n",
    "    sigma=0.06\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum -weights[:,1]*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resto del codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "In questo pezzo di codice viene visualizzato il costo dello stato calcolato con i pesi ottenuti dall'ottimizzazione, ovvero il costo stimato. In particolare, è rappresentato come una heatmap analogamente a quanto accaduto\n",
    "per il costo definito nel problema di FOC. Inoltre, sono state anche disegnate delle linee tratteggiate che rappresentano i livelli di costo.\n",
    "'''\n",
    "\n",
    "# Transpose the data array to rotate the heatmap\n",
    "#data_rotated = np.transpose(Coat_Map) Costo effettivo\n",
    "data_rotated = np.transpose(Cost_Map)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting the pcolormesh for the data\n",
    "plt.pcolormesh(X_axis, Y_axis, data_rotated, cmap='viridis', alpha=0.92)\n",
    "plt.colorbar()\n",
    "\n",
    "# Define contour levels to create 6 regions\n",
    "contour_levels = np.linspace(data_rotated.min(), data_rotated.max(), 7)  # 7 levels for 6 regions\n",
    "\n",
    "# Get colors based on the viridis colormap for the given contour levels\n",
    "viridis_colors = plt.cm.viridis(np.linspace(0, 1, len(contour_levels)))\n",
    "\n",
    "for i, level in enumerate(contour_levels):\n",
    "    plt.contour(X_axis, Y_axis, data_rotated, levels=[level], colors=[viridis_colors[i]], linewidths=2.5, linestyles='dashed')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_3d_heatmap_recostructed(goal_points, obs_points): \n",
    "    x_min = -1.6 \n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min, x_max, 100) \n",
    "    y_range = np.linspace(y_min, y_max, 100) \n",
    "    X, Y = np.meshgrid(x_range, y_range) \n",
    "    Z = np.zeros((100, 100)) \n",
    "    for i in range(100): \n",
    "        for j in range(100): \n",
    "            Z[i, j] = state_cost_estimated(np.array([X[i, j], Y[i, j]]), goal_points, obs_points, weights)\n",
    "    fig = plt.figure(figsize=(15,10)) \n",
    "    ax = fig.add_subplot(111, projection='3d') \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.97)  # Update alpha value here \n",
    "    ax.set_xlabel('X') \n",
    "    ax.set_ylabel('Y') \n",
    "    ax.set_zlabel('Cost') \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point') \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here \n",
    "\n",
    "    original_list=[] \n",
    "    for i in range(len(X_plot)): \n",
    "        new_inner_list=[] \n",
    "        for j in range(len(X_plot[i])): \n",
    "            new_array_3d=np.append(X_plot[i][j],state_cost(X_plot[i][j],goal_points,obs_points)) \n",
    "            new_inner_list.append(new_array_3d) \n",
    "            \n",
    "        original_list.append(new_inner_list) \n",
    "    \n",
    "    for i in range(len(X_plot)): \n",
    "        original_array = np.array(original_list[i]) \n",
    "        plt.plot(original_array[:, 0], original_array[:, 1],  0,  label=f'Trajectory {i+1}')\n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.175, obs_points[0, i] - 0.175, obs_points[0, i] + 0.175, obs_points[0, i] + 0.175, obs_points[0, i] - 0.175]\n",
    "        square_y = [obs_points[1, i] - 0.175, obs_points[1, i] + 0.175, obs_points[1, i] + 0.175, obs_points[1, i] - 0.175, obs_points[1, i] - 0.175]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "       # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.275, obs_points[0, i] - 0.275, obs_points[0, i] + 0.275, obs_points[0, i] + 0.275, obs_points[0, i] - 0.275]\n",
    "        square_y_large = [obs_points[1, i] - 0.275, obs_points[1, i] + 0.275, obs_points[1, i] + 0.275, obs_points[1, i] - 0.275, obs_points[1, i] - 0.275]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    \n",
    "    ax.legend() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap_recostructed(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "\n",
    "'''\n",
    "La funzione ha la sintassi e il significato analogo a quella definita per il problema di FOC, con la sola differenza che il costo dello stato viene calcolato con i pesi ottenuti dall'ottimizzazione,\n",
    "e quindi il costo è quello stimato dal problema IOC.\n",
    "'''\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                # Queste tre linee di codice calcolano il prossimo stato, a partire da una delle 9 azioni scandite\n",
    "                # dai cicli for, e creano una multivariata normale centrata nel prossimo stato con covarianza data\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                # Queste due linee di codice campionano 20 campioni dalla distribuzione calcolata precedentemente\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                # Calcoliamo il costo medio dei campioni secondo la funzione state_cost, si tratta di calcolare\n",
    "                # l'expected value della formula per la policy\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "                # print(\"entropy: \" + str(f.entropy()))\n",
    "                # print(\"next state: \" + str(next_state))\n",
    "                # print(\"cost: \" + str(cost))\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())\n",
    "\n",
    "                # la log_DKL è uguale, secondo formulazione, a np.exp(-DKL-costoatteso), il costo atteso lo abbiamo calcolato\n",
    "                # al punto precedente, mentre la DKL(f||g), dato che g è uniforme, diventa semplicemente l'entropia con un termine \n",
    "                # log(q) derivante da calcoli algebrici\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "\n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "obs_points = np.array(np.mat('0.5 0.9 0.9; 0.75 0.55 0.20; 0 0 0' ))\n",
    "\n",
    "initial_conditions = [np.array(np.mat('0.7; 0.85; 0')), np.array(np.mat('1.4; 0.9; 3.14')), np.array(np.mat('0.6; 0.45; 0'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supponendo che 'obs_points_f' e 'weights' siano definiti\n",
    "\n",
    "# Plot dei punti caratteristici sulla griglia\n",
    "plt.figure(figsize=(8, 6))\n",
    "newWeights=-weights[0][5:]# Normalizza i pesi nell'intervallo 100-1000\n",
    "weights_normalized = (newWeights - newWeights.min()) / (newWeights.max() - newWeights.min())\n",
    "weights_mapped = 100 + (weights_normalized * 900)  # Scala il valore tra 100 e 1000\n",
    "\n",
    "# Plot dei punti caratteristici con dimensioni basate sui pesi\n",
    "plt.scatter(obs_points_f[0], obs_points_f[1], s=weights_mapped, c='red', marker='o')\n",
    "\n",
    "# Plot del testo con i pesi corrispondenti\n",
    "for i in range(len(newWeights)):\n",
    "    plt.text(obs_points_f[0, i], obs_points_f[1, i]-0.15, f'{-newWeights[i]:.2f}', fontsize=8, color='black')\n",
    "\n",
    "plt.xlabel('Asse X')\n",
    "plt.ylabel('Asse Y')\n",
    "plt.title('Punti caratteristici sulla griglia del Robotarium con pesi')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È una situazione sicuramente critica per il robot. Si fa notare che c'è bisogno di abbastanza esperimenti per ricostruire bene il costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambio delle feature (Goal point dietro gli ostacoli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideriamo il caso in cui il robot parta in un angolo tra degli ostacoli ed il goal point sia dietro questi ostacoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### MODIFCATA ########\n",
    "'''\n",
    "Data la funzione di costo:\n",
    "'''\n",
    "def state_cost(state,goal_points,obs_points): \n",
    "    centroidi=clustering(obs_points) \n",
    " \n",
    "    v = np.array([0.015, 0.015], dtype=np.float32) \n",
    "    covar = np.diag(v) \n",
    "    gauss_sum = 0 \n",
    "    cost2 = 0 \n",
    "    for i in range(len(centroidi)): \n",
    "            dist= np.sqrt((goal_points[0,0]-centroidi[i][0])**2+(goal_points[1,0]-centroidi[i][1])**2) # da cambiare se sono più goal point #TODO \n",
    "            dist=dist if dist < 0.175 else 1 #(% 1 è per evitare di farla divergere, cioè mantenerla in 1 però è da verificare) \n",
    "            cost2 += 20*my_logpdf(state[:2],centroidi[i][:2],np.diag(np.array([0.04, 0.04], dtype=np.float32)))*(centroidi[i][2]-1)*dist \n",
    "            # Se il centroide è troppo vicino al goal point, allora la gaussiana è molto piccola, evitando di rischiare di portare il robot a non voler andare verso il goal point \n",
    " \n",
    "    for i in range(np.size(obs_points,axis=1)): \n",
    "        gauss_sum += 15*my_logpdf(state[:2],obs_points[:2,i],covar)  \n",
    " \n",
    "    muri=[np.array([1.5,0.0,0.0]),np.array([-1.5,0.0,0.0]),np.array([0.0,1.0,0.0]),np.array([0.0,-1.0,0.0])] \n",
    "    muri_gauss_sum=0 \n",
    "    \n",
    "    covar_muri_oriz=np.diag(np.array([0.01, 0.1], dtype=np.float32))\n",
    "    covar_muri_vert=np.diag(np.array([0.1, 0.01], dtype=np.float32))\n",
    "    \n",
    "    for i in range (4): \n",
    "        for j in range (np.size(obs_points,axis=1)): \n",
    "            if(muri[i][0]!=0): \n",
    "                 if(np.abs(muri[i][0]-obs_points[0,j])<0.495): \n",
    "                        muri_gauss_sum += 15*my_logpdf(state[:2],np.array([(muri[i][0]+obs_points[0,j])/2,obs_points[1,j]]),covar_muri_oriz) \n",
    "            else: \n",
    "                if(np.abs(muri[i][1]-obs_points[1,j])<0.495): \n",
    "                        muri_gauss_sum += 15*my_logpdf(state[:2],np.array([obs_points[0,j],(muri[i][1]+obs_points[1,j])/2]),covar_muri_vert) \n",
    "                  \n",
    "    sigma=0.06 \n",
    "    cost=-10*my_logpdf(state[:2],goal_points[:2,0],covar) + 75*np.sqrt(((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2)) + gauss_sum + 20*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2) \n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2)) + cost2 + muri_gauss_sum\n",
    "    \n",
    "    # 30*(abs(state[0] - goal_points[0]) + abs(state[1] - goal_points[1]))\n",
    "    \n",
    "    return (cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# goal_points = np.array(np.mat('-1.4; -0.8; 0')) # Da traccia\n",
    "goal_points = np.array(np.mat('-0.35; 0.5; 0'))\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0')) # Da traccia\n",
    "\n",
    "# initial_conditions = [np.array(np.mat('1.4;0.95; 3.14')),np.array(np.mat('0.225;0.95; 0')),np.array(np.mat('0.225;0.25; 3.14')),np.array(np.mat('1.45;0.25; 0')),np.array(np.mat('1.45;-0.75; 3.14')),np.array(np.mat('1;-0.95; 0')),\n",
    "                    #   np.array(np.mat('0.225;-0.95; 0')),np.array(np.mat('-0.225;-0.95; 3.14')), np.array(np.mat('-0.225;0.95; 0')),np.array(np.mat('-0.225;0.45; 0')), np.array(np.mat('-1.45;0.95; 0')),np.array(np.mat('-1.45;0.25; 0'))]\n",
    "\n",
    "initial_conditions = [np.array(np.mat('1.4;0.95; 3.14')),np.array(np.mat('0.225;0.95; 0'))]\n",
    "\n",
    "plot_heatmap(goal_points,obs_points)\n",
    "plot_3d_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se vuoi runnare di nuovo il FOC devi rieseguire il codice di definizione della control_step sopra.\n",
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)\n",
    "plotTrajectory3D(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature del prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')) # da traccia\n",
    "plot_heatmap(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature nostre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('-1.35 -1.35 -1.35 -1.35 -1.35 -0.675 -0.675 -0.675 -0.675 -0.675 0 0 0 0 0 0.675 0.675 0.675 0.675 0.675 1.35 1.35 1.35 1.35 1.35;-0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9 -0.9 -0.45 0 0.45 0.9;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n",
    "plot_heatmap(goal_points,obs_points_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feature = np.size(obs_points_f,axis=1)+1+1 # 1 per la distanza dal goal point, 1 per la gaussiana sul goal point, 4 per i muri\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    sigma=0.06\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) # per il goal point\n",
    "    features[1] = (1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) + np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) + np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2))\n",
    "    \n",
    "    # tollerance=1e-2  \n",
    "    # features[2] = ((1/((next_state[0]-1.5)**2  + tollerance))) + 1/((1.5-goal_points[0])**2+tollerance) # per il muro a destra\n",
    "    # features[3] = ((1/((next_state[0]-(-1.5))**2  + tollerance))) + 1/((-1.5-goal_points[0])**2+tollerance)  # per il muro a sinistra\n",
    "    # features[4] = ((1/((next_state[1]-1.0)**2  + tollerance))) + 1/((1.0-goal_points[1])**2+tollerance) # per il muro sopra\n",
    "    # features[5] = ((1/((next_state[1]-(-1.0))**2  + tollerance))) + 1/((-1.0-goal_points[1])**2+tollerance)  # per il muro sotto\n",
    "\n",
    "    # sigma=0.06\n",
    "    # features[2] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-1.5)/sigma)**2) # per il muro a destra\n",
    "    # features[3] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[0]-(-1.5))/sigma)**2)  # per il muro a sinistra\n",
    "    # features[4] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-1.0)/sigma)**2) # per il muro sopra\n",
    "    # features[5] = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((next_state[1]-(-1.0))/sigma)**2)  # per il muro sotto\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codice per l'ioc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1\n",
    "w = cp.Variable((1,N_feature))\n",
    "constraints = [w >= 0]\n",
    "R = np.zeros((99,1))\n",
    "L = []\n",
    "\n",
    "f_expect = np.zeros((2,20))\n",
    "feature_sampled = np.zeros((N_feature,M))\n",
    "PF = np.zeros((control_space_size,control_space_size,M))\n",
    "\n",
    "for i in range(M):\n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size))\n",
    "    state = np.array(X[i,:]) #Get the state\n",
    "\n",
    "    x0 = state.reshape(-1,1)\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            next_sample = f.mean\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples)\n",
    "            feature_sample = np.zeros((N_feature,N_samples))\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1)\n",
    "\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy()))\n",
    "            '''\n",
    "            Questo riga rappresenta il termine (5) descritto nel markdown, in particolare rappresenta l'esponenziale dell'entropia cambiata di segno.\n",
    "            '''\n",
    "\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # N features x 9\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step)\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov)\n",
    "    next_samples_f1 = f1.rvs(N_samples)\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    tempPF = np.reshape(PF,(control_space_size**2,M)) # N features x 9\n",
    "\n",
    "    l =-(w @ feature_sampled[:,i])+cp.log_sum_exp(cp.reshape(w@features[:,:],(9,))+cp.log(tempPF[:,i]))\n",
    "    \n",
    "    '''\n",
    "    Ogni termine l, rappresenta il singolo termine della sommatoria (4) descritta nel markdown, in particolare, dato che il codice pre-esistente già calcolava il termine (5) e il termine (6), lo scopo di questa parte di codice\n",
    "    è quello di configurare le dimensionalità dei vari termini, effettuando un reshape della PF calcolata, portandola da una dimensionalità (N feature x 3 x 3), a una dimensionalità (N x 9) per essere gestita nella somma con il prodotto dei pesi con le features.\n",
    "    Inoltre, dato che stiamo risolvendo un problema di LSE tramite cvx, dobbiamo fornirgli in input il valore atteso del prodotto tra pesi e feature, e il valore atteso della f cambiata di segno, rappresentato dall'entropia,\n",
    "    ma dato che ci viene già fornito dal codice l'esponenziale dell'entropia, cambiata di segno, dobbiamo sommare il logaritmo di questa quantità in modo da riportarci nella forma originale del problema (4).\n",
    "    '''\n",
    "    \n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    L.append(l)\n",
    "\n",
    "    '''\n",
    "    Con queste linee di codice creiamo l'intera sommatoria su M esperimenti.\n",
    "    '''\n",
    "\n",
    "    # (iii) solve the problem \n",
    "objective = cp.Minimize(cp.sum(L))\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = False)\n",
    "\n",
    "'''\n",
    "Infine risolviamo il problema, facendo uso di cvx, minimizzando la sommatoria dei termini l, ottenendo i pesi w ottimi delle feature scelte.\n",
    "'''\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costo ricostruito professore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    \n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costro ricostruito nostro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    # tollerance=1e-2\n",
    "    # walls_sum = -(weights[:,2]*1/((state[0]-1.5)**2 + tollerance) + weights[:,3]*1/((state[0]-(-1.5))**2 + tollerance) + weights[:,4]*1/((state[1]-1.0)**2 + tollerance) + weights[:,5]*1/((state[1]+(-1.0))**2 + tollerance))\n",
    "\n",
    "    sigma=0.06\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum -weights[:,1]*(1/(sigma*np.sqrt(2*np.pi)))*(np.exp(-0.5*((state[0]-(-1.5))/sigma)**2)\n",
    "                + np.exp(-0.5*((state[0]-1.5)/sigma)**2) + np.exp(-0.5*((state[1]-1.0)/sigma)**2) + np.exp(-0.5*((state[1]-(-1.0))/sigma)**2))\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resto del codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "In questo pezzo di codice viene visualizzato il costo dello stato calcolato con i pesi ottenuti dall'ottimizzazione, ovvero il costo stimato. In particolare, è rappresentato come una heatmap analogamente a quanto accaduto\n",
    "per il costo definito nel problema di FOC. Inoltre, sono state anche disegnate delle linee tratteggiate che rappresentano i livelli di costo.\n",
    "'''\n",
    "\n",
    "# Transpose the data array to rotate the heatmap\n",
    "#data_rotated = np.transpose(Coat_Map) Costo effettivo\n",
    "data_rotated = np.transpose(Cost_Map)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting the pcolormesh for the data\n",
    "plt.pcolormesh(X_axis, Y_axis, data_rotated, cmap='viridis', alpha=0.92)\n",
    "plt.colorbar()\n",
    "\n",
    "# Define contour levels to create 6 regions\n",
    "contour_levels = np.linspace(data_rotated.min(), data_rotated.max(), 7)  # 7 levels for 6 regions\n",
    "\n",
    "# Get colors based on the viridis colormap for the given contour levels\n",
    "viridis_colors = plt.cm.viridis(np.linspace(0, 1, len(contour_levels)))\n",
    "\n",
    "for i, level in enumerate(contour_levels):\n",
    "    plt.contour(X_axis, Y_axis, data_rotated, levels=[level], colors=[viridis_colors[i]], linewidths=2.5, linestyles='dashed')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_3d_heatmap_recostructed(goal_points, obs_points): \n",
    "    x_min = -1.6 \n",
    "    x_max = 1.6\n",
    "    y_min = -1.1\n",
    "    y_max = 1.1\n",
    "    x_range = np.linspace(x_min, x_max, 100) \n",
    "    y_range = np.linspace(y_min, y_max, 100) \n",
    "    X, Y = np.meshgrid(x_range, y_range) \n",
    "    Z = np.zeros((100, 100)) \n",
    "    for i in range(100): \n",
    "        for j in range(100): \n",
    "            Z[i, j] = state_cost_estimated(np.array([X[i, j], Y[i, j]]), goal_points, obs_points, weights)\n",
    "    fig = plt.figure(figsize=(15,10)) \n",
    "    ax = fig.add_subplot(111, projection='3d') \n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.97)  # Update alpha value here \n",
    "    ax.set_xlabel('X') \n",
    "    ax.set_ylabel('Y') \n",
    "    ax.set_zlabel('Cost') \n",
    "    ax.scatter(goal_points[0], goal_points[1], 0, c='r', marker='o', label='Goal Point') \n",
    "    ax.scatter(obs_points[0], obs_points[1], 0, c='k', marker='x', label='Obstacle Points', alpha=1.0)  # Update alpha value here \n",
    "\n",
    "    original_list=[] \n",
    "    for i in range(len(X_plot)): \n",
    "        new_inner_list=[] \n",
    "        for j in range(len(X_plot[i])): \n",
    "            new_array_3d=np.append(X_plot[i][j],state_cost(X_plot[i][j],goal_points,obs_points)) \n",
    "            new_inner_list.append(new_array_3d) \n",
    "            \n",
    "        original_list.append(new_inner_list) \n",
    "    \n",
    "    for i in range(len(X_plot)): \n",
    "        original_array = np.array(original_list[i]) \n",
    "        plt.plot(original_array[:, 0], original_array[:, 1],  0,  label=f'Trajectory {i+1}')\n",
    "    \n",
    "    # Plot square centered at obstacle points\n",
    "    for i in range(obs_points.shape[1]):\n",
    "        square_x = [obs_points[0, i] - 0.175, obs_points[0, i] - 0.175, obs_points[0, i] + 0.175, obs_points[0, i] + 0.175, obs_points[0, i] - 0.175]\n",
    "        square_y = [obs_points[1, i] - 0.175, obs_points[1, i] + 0.175, obs_points[1, i] + 0.175, obs_points[1, i] - 0.175, obs_points[1, i] - 0.175]\n",
    "        ax.plot(square_x, square_y, [0, 0, 0, 0, 0], c='b', linestyle='-', linewidth=2)\n",
    "        \n",
    "       # Add larger red square centered at obstacle points\n",
    "        square_x_large = [obs_points[0, i] - 0.275, obs_points[0, i] - 0.275, obs_points[0, i] + 0.275, obs_points[0, i] + 0.275, obs_points[0, i] - 0.275]\n",
    "        square_y_large = [obs_points[1, i] - 0.275, obs_points[1, i] + 0.275, obs_points[1, i] + 0.275, obs_points[1, i] - 0.275, obs_points[1, i] - 0.275]\n",
    "        ax.plot(square_x_large, square_y_large, [0, 0, 0, 0, 0], c='r', linestyle='-', linewidth=2)\n",
    "    \n",
    "    ax.legend() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_heatmap_recostructed(goal_points,obs_points_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "\n",
    "'''\n",
    "La funzione ha la sintassi e il significato analogo a quella definita per il problema di FOC, con la sola differenza che il costo dello stato viene calcolato con i pesi ottenuti dall'ottimizzazione,\n",
    "e quindi il costo è quello stimato dal problema IOC.\n",
    "'''\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                # Queste tre linee di codice calcolano il prossimo stato, a partire da una delle 9 azioni scandite\n",
    "                # dai cicli for, e creano una multivariata normale centrata nel prossimo stato con covarianza data\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                # Queste due linee di codice campionano 20 campioni dalla distribuzione calcolata precedentemente\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                # Calcoliamo il costo medio dei campioni secondo la funzione state_cost, si tratta di calcolare\n",
    "                # l'expected value della formula per la policy\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "                # print(\"entropy: \" + str(f.entropy()))\n",
    "                # print(\"next state: \" + str(next_state))\n",
    "                # print(\"cost: \" + str(cost))\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())\n",
    "\n",
    "                # la log_DKL è uguale, secondo formulazione, a np.exp(-DKL-costoatteso), il costo atteso lo abbiamo calcolato\n",
    "                # al punto precedente, mentre la DKL(f||g), dato che g è uniforme, diventa semplicemente l'entropia con un termine \n",
    "                # log(q) derivante da calcoli algebrici\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "\n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "obs_points = np.array(np.mat('0.5 0.9 0.9; 0.75 0.55 0.20; 0 0 0' ))\n",
    "\n",
    "initial_conditions = [np.array(np.mat('0.7; 0.85; 0')), np.array(np.mat('1.4; 0.9; 3.14')), np.array(np.mat('0.6; 0.45; 0'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Si,D_Xi=genericSimulation(initial_conditions, goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi\n",
    "X, X_plot, U, U_plot=prepareDataForPlotting(XX,UU)\n",
    "plotTrajectory(X_plot,obs_points,goal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supponendo che 'obs_points_f' e 'weights' siano definiti\n",
    "\n",
    "# Plot dei punti caratteristici sulla griglia\n",
    "plt.figure(figsize=(8, 6))\n",
    "newWeights=-weights[0][5:]# Normalizza i pesi nell'intervallo 100-1000\n",
    "weights_normalized = (newWeights - newWeights.min()) / (newWeights.max() - newWeights.min())\n",
    "weights_mapped = 100 + (weights_normalized * 900)  # Scala il valore tra 100 e 1000\n",
    "\n",
    "# Plot dei punti caratteristici con dimensioni basate sui pesi\n",
    "plt.scatter(obs_points_f[0], obs_points_f[1], s=weights_mapped, c='red', marker='o')\n",
    "\n",
    "# Plot del testo con i pesi corrispondenti\n",
    "for i in range(len(newWeights)):\n",
    "    plt.text(obs_points_f[0, i], obs_points_f[1, i]-0.15, f'{-newWeights[i]:.2f}', fontsize=8, color='black')\n",
    "\n",
    "plt.xlabel('Asse X')\n",
    "plt.ylabel('Asse Y')\n",
    "plt.title('Punti caratteristici sulla griglia del Robotarium con pesi')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È una situazione sicuramente critica per il robot. Si fa notare che c'è bisogno di abbastanza esperimenti per ricostruire bene il costo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#TODO Riprovare a fare l'IOC con meno punti (magari tornando alle feature aggiugendo gaussiana inversa e muri), oppure in generale rifare l'IOC avendo meno simulazioni nel FOC (6-12 come range secondo me non è male)\n",
    "#TODO Inotre fare altri markdown da qui dove magari scrivere (Esperimento cluster di blocchi), oppure (Esperimento goal point tra ostacolo) e così via, più sono meglio è teoricamente, tanto si tratta semplicemente di prendere qualche configurazione\n",
    "# di sopra e fare anche l'IOC, e magari aggiungerne altre se volete\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
