{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kph1lruSgPWp"
   },
   "outputs": [],
   "source": [
    "import rps.robotarium as robotarium\n",
    "from rps.utilities.transformations import *\n",
    "from rps.utilities.barrier_certificates import *\n",
    "from rps.utilities.misc import *\n",
    "from rps.utilities.controllers import *\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzioni introduttive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eszwfUCygPWs"
   },
   "outputs": [],
   "source": [
    "#Defining the input axes\n",
    "# Note: the boundaries for the control actions are the actuation constraints imposed by the physics of the robots\n",
    "\n",
    "control_space_size = 3  # Three possible inputs for each control axis\n",
    "\n",
    "'''Lo spazio di controllo è discretizzato su 3 possibili valori, che rappresentano la direzione di movimento del robot su un determinato asse, dato che il robot può muoversi solo sul piano\n",
    "x-y (non può muoversi in altezza), rappresentano lo spostamento positivo, negativo o nullo su quel determinato asse. Dal punto di vista del codice ciò è codificato come:'''\n",
    "\n",
    "# TODO: CONTROLLARE SE SONO VELOCITA' QUI, PERCHE' DOPO NELLA FUNZIONE MODEL_STEP LE CHIAMA VELOCITIES\n",
    "'''-0.5 -> velocità lungo la direzione negativa dell'asse\n",
    "0 -> nessuna velocità lungo l'asse\n",
    "+0.5-> velocità lungo la direzione positiva dell'asse'''\n",
    "\n",
    "# Definiamo quindi lo spazio di controllo come un array di 3 elementi, che rappresentano i possibili valori che può assumere un asse di controllo, sia per l'asse delle x che per l'asse delle y\n",
    "U_space_1 = np.array(np.linspace((-0.5),(0.5),control_space_size)) \n",
    "U_space_2 = np.array(np.linspace((-0.5),(0.5),control_space_size))\n",
    "\n",
    "# La variabile time_step rappresenta l'intervallo di tempo tra due istanti successivi della simulazione robotarium. In particolare, dalla documentazione,\n",
    "# il codice viene eseguito ogni 0.033 secondi,\n",
    "time_step = 0.033 # Robotarium time-step (from the documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Nonostante per il controllo data driven non sia necessario conoscere il modello del sistema, è necessario conoscerlo per simularlo, questa funzione è utilizzata\n",
    "semplicemente per calcolare il prossimo stato del robot, dato lo stato attuale e l'azione che si vuole compiere, in questo caso l'azione è rappresentata da un vettore di velocità come\n",
    "spiegato precedentemente '''\n",
    "# This function performs a \"model\" step using the documented dynamics\n",
    "# Note: from the viewpoint of the controller the dynamics is not necesarily known\n",
    "def model_step(x,velocities,time_step):\n",
    "    poses = np.zeros((2,1))\n",
    "    # Update pose of the robots\n",
    "    poses[0] = x[0] + time_step*velocities[0]\n",
    "    poses[1] = x[1] + time_step*velocities[1]\n",
    "    return(poses)\n",
    "\n",
    "# Get the value of a Gaussian pf at a given point *****?\n",
    "# This function is used to evaluate the pf at a given point (x,y) given the mean and covariance of the Gaussian \n",
    "def my_logpdf(x, u, covar):\n",
    "    k = len(x)  # dimension\n",
    "    a = np.transpose(x - u)\n",
    "    b = np.linalg.inv(covar)\n",
    "    c = x - u\n",
    "    d = np.matmul(a, b)\n",
    "    e = np.matmul(d, c)\n",
    "    numer = np.exp(-0.5 * e)\n",
    "    f = (2 * np.pi)**k\n",
    "    g = np.linalg.det(covar)\n",
    "    denom = np.sqrt(f * g)\n",
    "    pdf = numer / denom\n",
    "    return pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione my_logpdf calcola il valore della pdf di una gaussiana multivariata, dato un punto (x,y), la media e la covarianza della gaussiana. In questo caso specifico la covarianza\n",
    "è fissata, come si può vedere successivamente nel codice, al valore: covar = np.diag(v), dove v = np.array([0.02, 0.02], dtype=np.float32). \n",
    "Questo significa che la gaussiana è isotropa con varianza 0.02 su entrambi gli assi, ovvero la covarianza è definibile come:\n",
    "\n",
    "$$\\sum = \\sigma^2I$$ \n",
    "\n",
    "$I$ rappresenta la matrice identità, mentre $\\sigma$ è la varianza scalare.\n",
    "\n",
    "Per quanto riguarda la modellazione dell'ostacolo, l'isotropia della gaussiana implica che la varianza della distribuzione è la stessa su entrambi gli assi. Ciò significa che l'ostacolo è considerato sferico, con la stessa estensione in tutte le direzioni (per tale motivo, successivamente, si fa anche l'assunzione che la visualizzazione degli ostacoli come dei rettangoli sia un mero artificio di visualizzazione, piuttosto che una rappresentazione fidata dell'ostacolo dato il tipo di modellazione scelta). In questo caso la funzione è utilizzata per calcolare la distanza tra il punto (x,y), che rappresenta lo stato attuale del robot, e un generico ostacolo.\n",
    "\n",
    "Riferimento per [l'isotropia della gaussiana](https://magic-with-latents.github.io/latent/posts/ddpms/part2/#:~:text=Isotropic%20Gaussian,-An%20isotropic%20Gaussian&text=(4)%20represents%20a%20diagonal%20matrix,Gaussian%20is%20circular%20or%20spherical)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP0\n",
    "Prima di introdurre ulteriormente il codice, per supporto all'analisi del codice e delle scelte progettuali già fatte all'interno del codice fornito, e quelle compiute dal gruppo, si fa riferimento alla formalizzazione del problema di controllo effettuato nella relazione in allegato al codice del progetto. In particolare si riporta la formula semplificata la per la risoluzione del $\\bold {FOC}$ nel caso in cui la $q_{0:N}$ è uniforme:\n",
    "$${p^{(u)}_{k|k-1}}^* = \\frac{exp(\\mathbb{E_{p_{k+1|k}^{(x)}}}[ln(p_{k+1|k}^{(x)})+ \\overline c_{k}(X_k)])}{\\sum_{u_k}exp(\\mathbb{E_{p_{k+1|k}^{(x)}}}[ln(p_{k+1|k}^{(x)})+ \\overline c_{k}(X_k)])} \\space \\space \\bold{(1)}$$\n",
    "e ci riconduciamo al caso greedy in cui:\n",
    "$$\\overline c_{k}(X_k) = c_k(X_k)$$\n",
    "ovvero il cost-to-go è semplicemente il costo instantaneo.\n",
    "Inoltre indichiamo, per semplicità di notazione\n",
    "$$\\mathbb{E_{p_{k+1|k}^{(x)}}}[ln(p_{k+1|k}^{(x)})] = p_{k+1|k}^{(x)}.entropy()\\space \\space\\bold{(2)}$$\n",
    "e infine:\n",
    "$$\\mathbb{E_{p_{k+1|k}^{(x)}}}[c_{k}(X_k)] \\space \\space \\bold{(3)}$$\n",
    "così da poter meglio esplicitare le scelte progettuali del seguito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW7iQ2FfgPWv"
   },
   "outputs": [],
   "source": [
    "##### WP0: formalize the control problem #####\n",
    "\n",
    "# Task: reverse engineer the cost function used by the robots. What is the problem formulation? \n",
    "#      Is the one below a good cost for the task? Create a heatmap to visualize the cost \n",
    "\n",
    "# TODO: Verificare se ci sono altre situazioni in cui il robot potrebbe non comportarsi in maniera ottimale\n",
    "''' Questa funzione calcola il costo dello stato attuale, passato come parametro, rispetto al goal point e agli ostacoli, anche questi passati come parametri, di conseguenza è una funzione\n",
    "generica che può essere utilizzata per calcolare il costo per qualsiasi enviroment limitato al caso robotarium (in cui lo spazio di task può andare da -1.5 a 1.5 per l'asse x \n",
    "e da -1 a 1 per l'asse y). Il costo è calcolato come somma di tre macro termini, il primo rappresenta la distanza dal goal point:\n",
    "\n",
    "        30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2)\n",
    "\n",
    "Il secondo rappresenta la distanza dagli ostacoli, in particolare è una somma di gaussiane centrate negli ostacoli, la cui struttura è stata ampiamente descritta precedentemente:\n",
    "\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "Il terzo rappresenta la distanza dai bordi dell'ambiente robotarium, in particolare è una somma di quattro gaussiane centrate nei bordi dell'ambiente:\n",
    "\n",
    "        10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "        + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "\n",
    "in questo caso è una gaussiana molto stretta, è serve per evitare che il robot si avvicini troppo ai bordi dell'ambiente, in quanto potrebbe andare fuori dallo spazio di task, ma è un\n",
    "termine che pesa poco rispetto agli altri due, in quanto la gaussiana è molto stretta e quindi il costo è molto basso, se non in estrema prossimità dei bordi dell'ambiente.\n",
    "\n",
    "Il costo fornito racchiude in se stesso alcuni degli elementi chiave del problema di controllo, ovvero:\n",
    "    - il raggiungimento dell'obiettivo\n",
    "    - l'evitamento degli ostacoli\n",
    "    - l'evitamento dei bordi dell'ambiente\n",
    "tutto ciò che è necessario per la risoluzione del problema di controllo. Nonostante ciò, da una breve analisi sui termini del costo, è possibile commentare alcuni aspetti critici:\n",
    "    - da un punto di vista analitico, il contributo massimo che un singolo ostacolo da al costo è 159.15, se il robot si trovasse esattamente sopra l'ostacolo, mentre in un intorno di 0.1 dal centro\n",
    "    dell'ostacolo il contributo è nel range [96.53; 123.95];\n",
    "    - da un punto di vista analitico, il contributo massimo che un bordo da al costo è 199.47, se il robot si trovasse esattamente sul bordo, mentre in un intorno di 0.1 dal bordo, il valore è \n",
    "    estremamente basso, nell'ordine di 10^-5.\n",
    "Queste analisi preliminari evidenziano alcune situazioni in cui il robot potrebbe non comportarsi in maniera ottimale, in particolare:\n",
    "    - se l'ostacolo è molto vicino al goal point, il robot potrebbe non raggiungere mai il goal point, in quanto nell'intorno dell'ostacolo il costo è comunque alto, \n",
    "    il che può portare il robot a scegliere di non avvicinarsi all'ostacolo e di conseguenza al goal point;\n",
    "    - se uno o più ostacoli sono posti nei pressi delle pareti del robotarium, e il robot è posizionato tra le pareti e gli ostacoli, il robot potrebbe decidere di non avvicinarsi agli ostacoli,\n",
    "    ma piuttosto di avvicinarsi alle pareti, in quanto il costo è più basso, e di conseguenza potrebbe rimanere intrappolato tra ostacoli e pareti o addirittura andare fuori dall'ambiente descritto\n",
    "    dal robotarium;\n",
    "    - ALTRO?\n",
    "\n",
    "Infine, è evidenziabile anche un comportamento indesiderato del robot, non dovuto in questo caso al valore specifico dei coefficienti del costo, ovvero:\n",
    "- potrebbe capitare che, a causa dell'allineamento del robot rispetto al goal point, in caso di presenza di ostacolo tra il robot e il goal point, il robot continui a militare nell'\n",
    "intorno dell'ostacolo poichè il costo assume valori simili in entrambe le direzioni ortogonali all'asse di congiunzione, e il robot potrebbe continuare a scegliere direzioni opposte in passi\n",
    "successivi dell'algoritmo, senza mai superare l'ostacolo. \n",
    "\n",
    "Date queste considerazioni, è possibile affermare che il costo fornito, potrebbe essere migliorato, in particolare, verrà proposto un nuovo costo in seguito, come richiesto da work package\n",
    "successivi nel progetto'''\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar) # Questo dipende dalle gaussiane mediate negli ostacoli,\n",
    "        # come se avessimo che più ci avviciniamo all'ostacolo più aumenti il posto\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP1: fill-in the code for the function below.\n",
    "#         The function needs to return the optimal action sampled from the optimal policy.\n",
    "#         The action is used in the simulation loop #####\n",
    "\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "\n",
    "                '''\n",
    "                Il calcolo della policy descritta nel markdown (1) è valutata per ogni possibile azione, e per questo motivo, è necessario ciclare su tutte le possibili azioni, che in questo caso sono le possibili\n",
    "                combinazioni di velocità lungo l'asse x e lungo l'asse y, 9 in totale.\n",
    "                '''\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                # TODO: Da controllare il commento sotto\n",
    "                '''\n",
    "                Queste tre righe di codice servono per modellare i sensori rumorosi del sistema, in particolare, la funzione model_step calcola il prossimo stato del robot a cui viene iniettato del rumore gaussiano\n",
    "                con media nulla e covarianza 0.001 sulla x e 0.001 sulla y. Inoltre, il rumore gaussiano è necessario per la risoluzione del problema di controllo, in quanto, se non fosse presente, il robot potrebbe rimanere\n",
    "                intrappolato in un minimo locale del costo, in quanto il costo è una funzione continua e derivabile, e quindi potrebbe capitare che il robot non riesca a raggiungere il goal point. \n",
    "                '''\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                \n",
    "                '''\n",
    "                Queste due righe di codice servono per campionare la gaussiana dello stato, in modo da ottenere un numero di campioni pari a N_samples (in questo caso pari a 20), che rappresentano i possibili stati\n",
    "                successivi del robot. In particolare, la funzione rvs(N_samples) campiona la gaussiana N_samples volte, e restituisce un array di dimensione N_samples*2, in cui ogni riga rappresenta un campione.\n",
    "                '''\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost(next_sample[k,:],goal_points,obs_points)/N_samples\n",
    "                '''\n",
    "                Queste tre righe invece, servono a computare il costo dello stato successivo, espresso come valore atteso, indicato nella formula (1) nel markdown nella cella precedente. In particolare, il costo\n",
    "                viene calcolato come somma dei costi di ogni campione, diviso il numero di campioni, andando ad ottene il valore atteso del costo.\n",
    "                '''\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())*target_pf\n",
    "                '''\n",
    "                Come descritto nel markdown, la policy è ottenibile dalla formula (1), in particolare abbiamo al numeratore l'esponenziale della somma di due termini: il valore atteso del costo (3) e l'entropia della policy (2)\n",
    "                '''\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        \n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "\n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        '''\n",
    "        La policy ottima sarà di dimensione 3x3, in quanto abbiamo discretizzato lo spazio di controllo su 3 possibili valori per ogni asse, in cui ogni elemento rappresenta la probabilità di scegliere quell'azione.\n",
    "        Con il metodo flatten() è possibile trasformare la matrice in un array monodimensionale, in cui ogni elemento rappresenta la probabilità di scegliere l'azione corrispondente all'indice dell'elemento nell'array.\n",
    "        '''\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        \n",
    "        '''\n",
    "        Riprendendo ancora una volta la formula (3) nel markdown, al denominatore abbiamo la normalizzazione della policy, quindi la policy ottima, da cui campionare l'azione, è ottenuta come il rapporto tra il numeratore\n",
    "        calcolato precedentemente e il normalizzatore della stessa.\n",
    "        '''\n",
    "\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        '''\n",
    "        Infine, a partire dall'indice campionato, è possibile ottenere l'azione ottima corrispondente.\n",
    "        '''\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Questa funzione, richiesta dal WP1, serve per visualizzare il costo dello stato in funzione della posizione del robot, discretizzata come una griglia 100 x 100, dagli ostacoli e dal goal point\n",
    "'''\n",
    "def plot_heatmap(goal_points,obs_points):\n",
    "    x_min = -1.5\n",
    "    x_max = 1.5\n",
    "    y_min = -1\n",
    "    y_max = 1\n",
    "    x_range = np.linspace(x_min,x_max,100)\n",
    "    y_range = np.linspace(y_min,y_max,100)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    Z = np.zeros((100,100))\n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            Z[i,j] = state_cost(np.array([X[i,j],Y[i,j]]),goal_points,obs_points)\n",
    "    plt.pcolormesh(X,Y,Z)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(goal_points[0],goal_points[1],c='r')\n",
    "    plt.scatter(obs_points[0,:],obs_points[1,:],c='k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wy2b_CxogPWy"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In questa cella viene inizializzato l'enviroment del task di controllo, in particolar modo gli ostacoli e il goal point. \n",
    "In seguito viene chiamata la funzione plot_heatmap per visualizzare il costo dello stato per questo particolare\n",
    "enviroment, che verrà commentato nella relazione allegata al progetto.\n",
    "'''\n",
    "\n",
    "# Define goal and obstacle points\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0')) # Da traccia\n",
    "# goal_points = np.array(np.mat('0; 0; 0')) # test\n",
    "\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "# Plot the heatmap of the cost function\n",
    "plot_heatmap(goal_points,obs_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WP2: Simulate (4 experiments) and visualize each robot's trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WsfTaVW4gPW0",
    "outputId": "40848e0e-6a4c-4ddc-b80e-b576acbbff2b"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In questa cella viene effettuata la simulazione del robot, in particolare, per un singolo robot, vengono effettuati 4 esperimenti, in cui il robot parte da 4 posizioni diverse. \n",
    "Nello specifico, è stato fornito un set di condizioni iniziali di esempio, che sono state utilizzate per effettuare la simulazione.\n",
    "Innanzitutto viene inizializzato l'enviroment robotarium e creato il mapping tra il sistema unicycle del robot e il sistema single integrator. Tralasciamo la descrizione del modello unicycle, ampiamente descritta\n",
    "nella documentazione del robotarium, e ci concentriamo sul modello single integrator, che è quello che interessa per la simulazione, non è necessario conoscerlo per la risoluzione del problema di controllo. Successivamente\n",
    "viene effettuato un esperimento alla volta, il quale prevede:\n",
    "- il recupero della posa del robot a cui viene iniettato del rumore per simulare gli eventuali errori di misura del sensore di posizione del robot;\n",
    "- viene effettuato il passo di controllo attraverso la funzione Control_step che restituirà l'azione ottima come descritto in precedenza;\n",
    "- viene effettuata la conversione dell'azione ottima in velocità del robot, attraverso la funzione si_to_uni_dyn;\n",
    "- vengono assegnate le velocità al robot;\n",
    "- viene effettuato il passo di simulazione.\n",
    "'''\n",
    "\n",
    "# Instantiate Robotarium object\n",
    "N = 1 #Amount of robots per simulation\n",
    "# Initial conditions of the robot for 4 experiments\n",
    "initial_conditions = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))] #Initial pose of the robots\n",
    "N_experiment = 4\n",
    "# X_si is going to be two-dimensional state history\n",
    "X_Si = [0]*N_experiment\n",
    "# D_Xi is going to be two-dimensional inputs history\n",
    "D_Xi = [0]*N_experiment\n",
    "\n",
    "# This first for loop creates the initial conditions\n",
    "for I in range(N_experiment):\n",
    "\n",
    "    X_si = []\n",
    "    D_xi = []\n",
    "\n",
    "    r = robotarium.Robotarium(number_of_robots=N, show_figure=True, initial_conditions=initial_conditions[I], sim_in_real_time=False)\n",
    "\n",
    "    # Create mapping from the control inputs to the actual velocity commands to the unicycle\n",
    "    # Note: this is a very practical situation (robots often provide transformation functions to low level commands)\n",
    "    si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion() #Converts single integrator inputs to unicycle inputs (low-level controller)\n",
    "    _, uni_to_si_states = create_si_to_uni_mapping()\n",
    "    \n",
    "    # define x initially\n",
    "    x = r.get_poses()\n",
    "    x_si = uni_to_si_states(x)\n",
    "\n",
    "    # Plotting Parameters\n",
    "    CM = np.random.rand(N+10,3) # Random Colors\n",
    "    goal_marker_size_m = 0.15\n",
    "    obs_marker_size_m = 0.15\n",
    "    marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "    marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "    font_size = determine_font_size(r,0.1)\n",
    "    line_width = 5\n",
    "\n",
    "    # Create Goal Point Markers\n",
    "    #Text with goal identification\n",
    "    goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "    #Plot text for caption\n",
    "    goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "    goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "\n",
    "    #Text with goal identification\n",
    "    obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "    #Plot text for caption\n",
    "    obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "    obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "\n",
    "    r.step()\n",
    "\n",
    "    # While the robot is away from the objective ...\n",
    "    while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N):\n",
    "\n",
    "        # Get poses of agents\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        #Add to the dataset\n",
    "        X_si.append(x_si)\n",
    "\n",
    "        # The lines below define the pdf of the robot \n",
    "        cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "        x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "        x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "        # This is about plotting\n",
    "        for j in range(goal_points.shape[1]):\n",
    "            goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "        for j in range(obs_points.shape[1]):\n",
    "            obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "        # Task: compute the action from the policy. Call the variable dxi: \n",
    "        # this is the action sampled from the optimal solution to the control problem\n",
    "        dxi = Control_step(x_sample,U_space_1,U_space_2,goal_points,obs_points) \n",
    "\n",
    "        D_xi.append(dxi)\n",
    "\n",
    "        # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "        dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "        # Set the velocities inputs\n",
    "        r.set_velocities(np.arange(N), dxu)\n",
    "        # Iterate the simulation\n",
    "        r.step()\n",
    "\n",
    "    D_Xi[I] = D_xi\n",
    "    X_Si[I] = X_si\n",
    "\n",
    "    #Call at end of script to print debug information and for your script to run on the Robotarium server properly\n",
    "    r.call_at_scripts_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ass2XqjRgPW3"
   },
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyRxll4KgPW5"
   },
   "outputs": [],
   "source": [
    "#Prepare data for plotting\n",
    "X = []\n",
    "X_plot = []\n",
    "U = []\n",
    "U_plot = []\n",
    "\n",
    "for i in range(len(XX)):\n",
    "    X.append(np.array(XX[i]))\n",
    "    X_plot.append(np.array(XX[i]))\n",
    "\n",
    "X = np.concatenate(X, axis=0)\n",
    "X = np.reshape(X, (-1, 2))\n",
    "\n",
    "U = []\n",
    "for i in range(len(UU)):\n",
    "    U.append(np.array(UU[i]))\n",
    "    U_plot.append(np.array(UU[i]))\n",
    "\n",
    "U = np.concatenate(U, axis=0)\n",
    "U = np.reshape(U, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "PqEl3OXpgPW_",
    "outputId": "a710f7af-4b2e-486e-908b-063e24924946"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "\n",
    "#Task: plot trajectories with different colors\n",
    "plt.figure()\n",
    "\n",
    "for i in range(len(X_plot)):\n",
    "    plt.plot(X_plot[i][:, 0], X_plot[i][:, 1], label=f'Traiettoria {i+1}')\n",
    "    plt.plot(X_plot[i][0, 0],X_plot[i][0, 1],'*',color='black',markersize=10)\n",
    "\n",
    "'''\n",
    "Le linee di codice precedenti servono per visualizzare le traiettorie dei robot, in particolare, per ogni esperimento viene visualizzata la traiettoria del robot, mappandola con un diverso colore aggiungendo\n",
    "un marker alla posizione iniziale del robot.\n",
    "\n",
    "NOTA: nelle successive linee di codice, vengono plottati i goal point e gli ostacoli, ma non rappresentano in maniera fedele la realtà, in quanto sono stati plottati in un ambiente 2D e rappresentati come rettangoli, mentre,\n",
    "come già discusso in precedenza, gli ostacoli dovrebbero essere rappresentati più come delle sfere, a causa della natura gaussiana multivariata che rappresenta la distanza.\n",
    "'''\n",
    "#Draw obstacles\n",
    "square1 = plt.Rectangle((-1.6,-1), 0.4, 0.4, fc='green',ec=\"black\")\n",
    "square3 = plt.Rectangle((-0.2,-1), 0.4, 0.4, fc='red',ec=\"black\")\n",
    "square2 = plt.Rectangle((-0.2,0), 0.4, 0.8, fc='red',ec=\"black\")\n",
    "plt.gca().add_patch(square2)\n",
    "plt.gca().add_patch(square1)\n",
    "plt.gca().add_patch(square3)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "plt.savefig('Training_Trajectories.jpg',dpi=1000,bbox_inches ='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP3: Reverse engineer the features and visualize them #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjLf-AbTgPXB"
   },
   "outputs": [],
   "source": [
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XXOIr-DgPXD"
   },
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1\n",
    "\n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2))\n",
    "\n",
    "    return features\n",
    "\n",
    "'''\n",
    "Le feature proposte dal docente sono 16, la prima rappresenta la distanza rispetto al goal point, mentre le altre 15 rappresentano la distanza rispetto a dei punti fissi, che sono posizionati in maniera tale da\n",
    "ricoprire l'intero spazio di task. Questo set di feature, mappa in maniera fedele il costo dello stato relativo alla distanza dal goal point e dagli ostacoli, infatti ogni punto di feature è posizionato in un punto\n",
    "dell'ambiente e, in base al relativo peso, esso rappresentarà la distanza da eventuali ostacoli presenti in quell'area dell'ambiente.\n",
    "Data la natura del set di feature proposto, una prima analisi critica mette alla luce qualche problema: il numero di punti della griglia robotarium di riferimento sono in numero limitato, \n",
    "questa \"discretizzazione\" della griglia potrebbe portare a una perdita di informazione, in quanto non è detto che è possibile ricavare tutte le informazioni riguardanti il costo dello stato a causa del numero ridotto di simulazioni,\n",
    "e queste, anche se aumentassero in numero, potrebbero non coprire tutte le casistiche possibili. Per tale motivo una prima analisi critica porterebbe all'aumento del numero di punti della griglia robotarium, in modo da avere più informazioni\n",
    "riguardo il costo dello stato, e quindi avere una migliore approssimazione del costo dello stato. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAi2q4NvgPXE"
   },
   "outputs": [],
   "source": [
    "##### WP4: using the previously defined features solve the inverse optimal control problem. \n",
    "#          Plot the estimated cost. \n",
    "#          Verify that the estimated cost allows the robot to complete the task #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di introdurre ulteriormente il codice, per supporto all'analisi dello stesso e delle scelte progettuali già fatte all'interno del codice fornito, e quelle compiute dal gruppo, si fa riferimento alla formalizzazione del problema di controllo inverso effettuato nella relazione in allegato al codice del progetto. In particolare, si riporta la formula semplificata la per la risoluzione dell'$\\bold {IOC}$ nel caso in cui la $q_{0:N}$ è uniforme:\n",
    "$$argmin_w\\{\\sum^M_{k=1}(\\mathbb{E_{p(x_k|\\hat x_{k-1},\\hat u_k)}}[w_k^Th(x_k)]+ln(\\sum_{u_k}exp(\\mathbb{E_{p(x_k|\\hat x_{k-1},u_k)}}[-ln(p(x_k|\\hat x_{k-1},u_k))+w_k^Th(x_k)])))\\} \\space \\space \\bold{(4)}$$\n",
    "\n",
    "Inoltre indichiamo, per semplicità di notazione\n",
    "$$exp(\\mathbb{E_{p(x_k|\\hat x_{k-1},u_k)}}[-ln(p(x_k|\\hat x_{k-1},u_k))]) = -p(x_k|\\hat x_{k-1},u_k).entropy()\\space \\space\\bold{(5)}$$\n",
    "e infine:\n",
    "$$\\mathbb{E_{p(x_k|\\hat x_{k-1},u_k)}}[w_k^Th(x_k)] \\space \\space \\bold{(6)}$$\n",
    "così da poter meglio esplicitare le scelte progettuali del seguito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7shmt6xgPXF"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1\n",
    "w = cp.Variable((1,N_feature))\n",
    "constraints = [w >= 0]\n",
    "R = np.zeros((99,1))\n",
    "L = []\n",
    "\n",
    "f_expect = np.zeros((2,20))\n",
    "feature_sampled = np.zeros((N_feature,M))\n",
    "PF = np.zeros((control_space_size,control_space_size,M))\n",
    "\n",
    "for i in range(M):\n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size))\n",
    "    state = np.array(X[i,:]) #Get the state\n",
    "\n",
    "    x0 = state.reshape(-1,1)\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            next_sample = f.mean\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples)\n",
    "            feature_sample = np.zeros((N_feature,N_samples))\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1)\n",
    "\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy()))\n",
    "            '''\n",
    "            Questo riga rappresenta il termine (5) descritto nel markdown, in particolare rappresenta l'esponenziale dell'entropia cambiata di segno.\n",
    "            '''\n",
    "\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # N features x 9\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step)\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov)\n",
    "    next_samples_f1 = f1.rvs(N_samples)\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    tempPF = np.reshape(PF,(control_space_size**2,M)) # N features x 9\n",
    "\n",
    "    l =-(w @ feature_sampled[:,i])+cp.log_sum_exp(cp.reshape(w@features[:,:],(9,))+cp.log(tempPF[:,i]))\n",
    "    \n",
    "    '''\n",
    "    Ogni termine l, rappresenta il singolo termine della sommatoria (4) descritta nel markdown, in particolare, dato che il codice pre-esistente già calcolava il termine (5) e il termine (6), lo scopo di questa parte di codice\n",
    "    è quello di configurare le dimensionalità dei vari termini, effettuando un reshape della PF calcolata, portandola da una dimensionalità (N feature x 3 x 3), a una dimensionalità (N x 9) per essere gestita nella somma con il prodotto dei pesi con le features.\n",
    "    Inoltre, dato che stiamo risolvendo un problema di LSE tramite cvx, dobbiamo fornirgli in input il valore atteso del prodotto tra pesi e feature, e il valore atteso della f cambiata di segno, rappresentato dall'entropia,\n",
    "    ma dato che ci viene già fornito dal codice l'esponenziale dell'entropia, cambiata di segno, dobbiamo sommare il logaritmo di questa quantità in modo da riportarci nella forma originale del problema (4).\n",
    "    '''\n",
    "    \n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    L.append(l)\n",
    "\n",
    "    '''\n",
    "    Con queste linee di codice creiamo l'intera sommatoria su M esperimenti.\n",
    "    '''\n",
    "\n",
    "    # (iii) solve the problem \n",
    "objective = cp.Minimize(cp.sum(L))\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = False)\n",
    "\n",
    "'''\n",
    "Infine risolviamo il problema, facendo uso di cvx, minimizzando la sommatoria dei termini l, ottenendo i pesi w ottimi delle feature scelte.\n",
    "'''\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EY1orFxPgPXH",
    "outputId": "24a7b313-560d-4e31-d3f1-49d9a25a0543"
   },
   "outputs": [],
   "source": [
    "# Show the values: critically discuss if these weights make sense\n",
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)\n",
    "\n",
    "''' \n",
    "A termine dell'ottimizazzione vengono visualizzati i pesi calcolati dal problema. In questo caso particolare notiamo che i pesi relativi al mapping dello spazio assumono valori più alti, in segno negativo, più vicini sono\n",
    "agli ostacoli. Ovviamente questo ha senso, poichè il costo, è combinazione lineare di queste feature cambiate di segno e pesate per i relativi pesi, e riesce a rappresentare in maniera fedele il costo dello stato, \n",
    "poichè è più alto in vicinanza dei punti in cui sono concentrati più ostacoli. Inoltre anche il peso della feature che mappa la distanza dal goal point è negativo e di modulo alto, \n",
    "e questo ha senso in quanto il costo dello stato è tanto più alto quanto più il robot è lontano dal goal point.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QgxBdrNgPXI",
    "outputId": "699171d0-3d2f-4195-af1c-fdbe5032e7af"
   },
   "outputs": [],
   "source": [
    "# Check the status of the optimization problem: did the optimization go well?\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)\n",
    "\n",
    "'''\n",
    "Come descritto anche in precedenza, l'ottimizzazione è andata a buon fine e il valore dei pesi calcolati è ragionevole in relazione allo specifico task attuato.\n",
    "Il fatto che lo status sia optimal indica che l'ottmizzazione ha raggiunto con successo la soluzione ottimale, trovando il miglior valore possibile rispetto alla funzione obiettivo.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Xs5LG7IgPXJ"
   },
   "outputs": [],
   "source": [
    "# Reformatting the original cost map (just for checking and plotting purposes)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "#obs_points = np.array(np.mat('0 0 0 0 0 0;0 0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0 0'))\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost(state,goal_points,obs_points)\n",
    "\n",
    "Coat_Map = pd.DataFrame(Cost_Map,index=list(X_axis),columns=Y_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXBeF23UgPXL"
   },
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "I7poUkevgPXM",
    "outputId": "e4e9bc4c-b6a7-422e-a08b-0fa3a0652535"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transpose the data array to rotate the heatmap\n",
    "#data_rotated = np.transpose(Coat_Map) Costo effettivo\n",
    "data_rotated = np.transpose(Cost_Map)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting the pcolormesh for the data\n",
    "plt.pcolormesh(X_axis, Y_axis, data_rotated, cmap='viridis', alpha=0.92)\n",
    "plt.colorbar()\n",
    "\n",
    "# Define contour levels to create 6 regions\n",
    "contour_levels = np.linspace(data_rotated.min(), data_rotated.max(), 7)  # 7 levels for 6 regions\n",
    "\n",
    "# Get colors based on the viridis colormap for the given contour levels\n",
    "viridis_colors = plt.cm.viridis(np.linspace(0, 1, len(contour_levels)))\n",
    "\n",
    "for i, level in enumerate(contour_levels):\n",
    "    plt.contour(X_axis, Y_axis, data_rotated, levels=[level], colors=[viridis_colors[i]], linewidths=2.5, linestyles='dashed')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "In questo pezzo di codice viene visualizzato il costo dello stato calcolato con i pesi ottenuti dall'ottimizzazione, ovvero il costo stimato. In particolare, è rappresentato come una heatmap analogamente a quanto accaduto\n",
    "per il costo definito nel problema di FOC. Inoltre, sono state anche disegnate delle linee tratteggiate che rappresentano i livelli di costo.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIo_AnGpgPXT"
   },
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "\n",
    "'''\n",
    "La funzione ha la sintassi e il significato analogo a quella definita per il problema di FOC, con la sola differenza che il costo dello stato viene calcolato con i pesi ottenuti dall'ottimizzazione,\n",
    "e quindi il costo è quello stimato dal problema IOC.\n",
    "'''\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "        ###\n",
    "        # Perform a control step given the fact that the target pf is uniform.\n",
    "        # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "        \n",
    "        target_pf = 1/control_space_size**2 # Uniform pf\n",
    "        time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "        for i in range(control_space_size):\n",
    "            for j in range(control_space_size):\n",
    "                # Task: what do the next three lines do?\n",
    "                next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "\n",
    "                # Queste tre linee di codice calcolano il prossimo stato, a partire da una delle 9 azioni scandite\n",
    "                # dai cicli for, e creano una multivariata normale centrata nel prossimo stato con covarianza data\n",
    "\n",
    "                # Task: what do the next two lines do?\n",
    "                N_samples = 20\n",
    "                next_sample = f.rvs(N_samples)\n",
    "                # Queste due linee di codice campionano 20 campioni dalla distribuzione calcolata precedentemente\n",
    "\n",
    "                # Task: what do the next three lines do?\n",
    "                cost=0\n",
    "                for k in range(N_samples):\n",
    "                    cost+=state_cost_estimated(next_sample[k,:],goal_points,obs_points,weights)/N_samples\n",
    "                # Calcoliamo il costo medio dei campioni secondo la funzione state_cost, si tratta di calcolare\n",
    "                # l'expected value della formula per la policy\n",
    "\n",
    "                # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "                # print(\"entropy: \" + str(f.entropy()))\n",
    "                # print(\"next state: \" + str(next_state))\n",
    "                # print(\"cost: \" + str(cost))\n",
    "\n",
    "                log_DKL = np.exp(-cost+f.entropy())*target_pf\n",
    "\n",
    "                # la log_DKL è uguale, secondo formulazione, a np.exp(-DKL-costoatteso), il costo atteso lo abbiamo calcolato\n",
    "                # al punto precedente, mentre la DKL(f||g), dato che g è uniforme, diventa semplicemente l'entropia con un termine \n",
    "                # log(q) derivante da calcoli algebrici\n",
    "                \n",
    "                pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "        # Task: obtain the normalizer for the policy, call it S2\n",
    "        S2 = np.sum(pf)\n",
    "\n",
    "        # Task: obtain the normalized pf (call the variable pf)\n",
    "        pf = pf/S2\n",
    "\n",
    "        # This is a trick to properly sample from the multi-dimensional pf\n",
    "        flat = pf.flatten()\n",
    "\n",
    "        sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "\n",
    "        # Take this index and adjust it so it matches the original array\n",
    "        adjusted_index = np.unravel_index(sample_index, pf.shape)\n",
    "        #Get the action\n",
    "        action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "\n",
    "        return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uLNguEgFgPXU",
    "outputId": "24679b38-d525-492f-e678-8799b8a28ff6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Anche questo pezzo di codice, come in precedenza, è analogo a quello scritto per il problema di FOC, con la sola differenza che viene utilizzata la policy con il costo stimato, e non quello definito nel problema di FOC.\n",
    "Il codice è esattamente lo stesso, ma viene effettuata una chiamata alla funzione Control_step con i parametri aggiornati, ovvero il costo stimato e non quello definito nel problema di FOC.\n",
    "'''\n",
    "# Instantiate Robotarium object (start the robots from different initial conditions than the 4 experiments above)\n",
    "N = 1\n",
    "initial_conditions = [np.array(np.mat('-1.4;0.9; 0')),np.array(np.mat('1;0.9; 0')),np.array(np.mat('1;-0.25; 0'))]\n",
    "N_experiment = 3\n",
    "# Definitions as above...\n",
    "X_Si = [0]*N_experiment\n",
    "D_Xi = [0]*N_experiment\n",
    "\n",
    "for I in range(N_experiment):\n",
    "\n",
    "    X_si = []\n",
    "    D_xi = []\n",
    "\n",
    "    r = robotarium.Robotarium(number_of_robots=N, show_figure=True, initial_conditions=initial_conditions[I], sim_in_real_time=False)\n",
    "\n",
    "    si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion()\n",
    "\n",
    "    x = r.get_poses()\n",
    "    x_si = uni_to_si_states(x)\n",
    "\n",
    "    CM = np.random.rand(N+10,3) \n",
    "    goal_marker_size_m = 0.15\n",
    "    obs_marker_size_m = 0.15\n",
    "    marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "    marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "    font_size = determine_font_size(r,0.1)\n",
    "    line_width = 5\n",
    "\n",
    "    goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "    goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "    goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "\n",
    "    obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "    obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "    obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "\n",
    "    r.step()\n",
    "    # Task: re-implement the simulation loop this time using the policy with the estimated cost\n",
    "    while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N):\n",
    "\n",
    "        \n",
    "        # Get poses of agents\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        #Add to the dataset\n",
    "        X_si.append(x_si)\n",
    "\n",
    "        # The lines below define the pdf of the robot \n",
    "        cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "        x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "        x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "        # This is about plotting\n",
    "        for j in range(goal_points.shape[1]):\n",
    "            goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "        for j in range(obs_points.shape[1]):\n",
    "            obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "        # Task: compute the action from the policy. Call the variable dxi: \n",
    "        # this is the action sampled from the optimal solution to the control problem\n",
    "        dxi = Control_step(x_sample,U_space_1,U_space_2,goal_points,obs_points) \n",
    "\n",
    "        D_xi.append(dxi)\n",
    "\n",
    "        # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "        dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "        # Set the velocities inputs\n",
    "        r.set_velocities(np.arange(N), dxu)\n",
    "        # Iterate the simulation\n",
    "        r.step()\n",
    "\n",
    "    D_Xi[I] = D_xi\n",
    "    X_Si[I] = X_si\n",
    "\n",
    "    r.call_at_scripts_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2gUBs9HgPXW"
   },
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zc26PNAzgPXX"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "X_plot = []\n",
    "U = []\n",
    "U_plot = []\n",
    "\n",
    "for i in range(len(XX)):\n",
    "    X.append(np.array(XX[i]))\n",
    "    X_plot.append(np.array(XX[i]))\n",
    "\n",
    "X = np.concatenate(X, axis=0)\n",
    "X = np.reshape(X, (-1, 2))\n",
    "\n",
    "U = []\n",
    "for i in range(len(UU)):\n",
    "    U.append(np.array(UU[i]))\n",
    "    U_plot.append(np.array(UU[i]))\n",
    "\n",
    "U = np.concatenate(U, axis=0)\n",
    "U = np.reshape(U, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Sq2vsBLMgPXY",
    "outputId": "c6e65995-63e3-47ac-fb97-7d930abc5887"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Infine, ancora una volta come nel FOC, plottiamo i risultati degli esperimenti. Effettivamente, per le condizioni iniziali scelte da traccia, il robot riesce a raggiungere il goal point,\n",
    "ma non è detto che questo accada sempre, infatti se si cambiano le condizioni iniziali, il robot potrebbe non raggiungere il goal point, e alcuni casi di ciò sono riportati nella relazione allegata al progetto.\n",
    "Proprio per tale motivo si è deciso di modellare una nuova funzione di costo e un nuovo set di feature, così come richiesto dal work package.\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "\n",
    "# Task: Plot robot trajectories (when the policy uses the reconstructed cost)\n",
    "plt.figure()\n",
    "\n",
    "for i in range(len(X_plot)):\n",
    "    plt.plot(X_plot[i][:, 0], X_plot[i][:, 1], label=f'Traiettoria {i+1}')\n",
    "    plt.plot(X_plot[i][0, 0],X_plot[i][0, 1],'*',color='black',markersize=10)\n",
    "\n",
    "\n",
    "#Draw obstacles\n",
    "square1 = plt.Rectangle((-1.6,-1), 0.4, 0.4, fc='green',ec=\"black\")\n",
    "square3 = plt.Rectangle((-0.2,-1), 0.4, 0.4, fc='red',ec=\"black\")\n",
    "square2 = plt.Rectangle((-0.2,0), 0.4, 0.8, fc='red',ec=\"black\")\n",
    "plt.gca().add_patch(square2)\n",
    "plt.gca().add_patch(square1)\n",
    "plt.gca().add_patch(square3)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "Xgg5hhMogPXQ",
    "outputId": "b8c54575-1e46-441a-991d-9561ed668256"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Infine, prima di passare alla modellazione di una nuova funzione di costo e di un nuovo set di feature, viene visualizzato il set di feature utilizzato per il problema di IOC.\n",
    "In particolare, i punti caratteristici sono rappresentati come dei cerchi rossi, e la dimensione del cerchio è proporzionale al peso associato alla feature, in particolare, più il peso è alto, più il cerchio sarà grande. \n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supponendo che 'obs_points_f' e 'weights' siano definiti\n",
    "\n",
    "# Plot dei punti caratteristici sulla griglia\n",
    "plt.figure(figsize=(8, 6))\n",
    "newWeights=-weights[0][1:]# Normalizza i pesi nell'intervallo 100-1000\n",
    "weights_normalized = (newWeights - newWeights.min()) / (newWeights.max() - newWeights.min())\n",
    "weights_mapped = 100 + (weights_normalized * 900)  # Scala il valore tra 100 e 1000\n",
    "\n",
    "# Plot dei punti caratteristici con dimensioni basate sui pesi\n",
    "plt.scatter(obs_points_f[0], obs_points_f[1], s=weights_mapped, c='red', marker='o')\n",
    "\n",
    "# Plot del testo con i pesi corrispondenti\n",
    "for i in range(len(newWeights)):\n",
    "    plt.text(obs_points_f[0, i], obs_points_f[1, i]-0.15, f'{-newWeights[i]:.2f}', fontsize=8, color='black')\n",
    "\n",
    "plt.xlabel('Asse X')\n",
    "plt.ylabel('Asse Y')\n",
    "plt.title('Punti caratteristici sulla griglia del Robotarium con pesi')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment the results you observe in the figure generated by the above cell\n",
    "\n",
    "'''\n",
    "Come enunciato già in precedenza, alla visualizzazione non grafica, ma analitica dei pesi, notiamo che i pesi relativi al mapping dello spazio assumono valori più alti, in segno negativo, più vicini sono\n",
    "agli ostacoli. Ovviamente questo ha senso, poichè il costo, combinazione lineare di queste feature, riesce a rappresentare in maniera fedele il costo dello stato, poichè è più alto in vicinanza dei punti in cui sono concentrati\n",
    "più ostacoli. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUOVE PROPOSTE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
